{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "iCF0qoUDMqtA"
      },
      "outputs": [],
      "source": [
        "#Load dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "df = pd.read_csv('merge.csv')\n",
        "df.sort_values('Area Code (FAO)')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "gwk2eADxMqtD",
        "outputId": "630d3acc-9c97-4b51-b76e-b93eac737fb4",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-fc794eec-346c-4088-ae03-ed836870c031\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Area Code (FAO)</th>\n",
              "      <th>Year</th>\n",
              "      <th>population</th>\n",
              "      <th>yield</th>\n",
              "      <th>harvested</th>\n",
              "      <th>Value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>1961</td>\n",
              "      <td>8790.140</td>\n",
              "      <td>10220</td>\n",
              "      <td>2230000.0</td>\n",
              "      <td>2279000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1962</td>\n",
              "      <td>8969.047</td>\n",
              "      <td>9735</td>\n",
              "      <td>2341000.0</td>\n",
              "      <td>2279000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1963</td>\n",
              "      <td>9157.465</td>\n",
              "      <td>8317</td>\n",
              "      <td>2341000.0</td>\n",
              "      <td>1947000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>1964</td>\n",
              "      <td>9355.514</td>\n",
              "      <td>9510</td>\n",
              "      <td>2345000.0</td>\n",
              "      <td>2230000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>1965</td>\n",
              "      <td>9565.147</td>\n",
              "      <td>9723</td>\n",
              "      <td>2347000.0</td>\n",
              "      <td>2282000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6608</th>\n",
              "      <td>181</td>\n",
              "      <td>2016</td>\n",
              "      <td>14452.704</td>\n",
              "      <td>19013</td>\n",
              "      <td>22094.0</td>\n",
              "      <td>42008.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6609</th>\n",
              "      <td>181</td>\n",
              "      <td>2017</td>\n",
              "      <td>14751.101</td>\n",
              "      <td>17542</td>\n",
              "      <td>22070.0</td>\n",
              "      <td>38715.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6610</th>\n",
              "      <td>181</td>\n",
              "      <td>2018</td>\n",
              "      <td>15052.184</td>\n",
              "      <td>16206</td>\n",
              "      <td>27767.0</td>\n",
              "      <td>45000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6611</th>\n",
              "      <td>181</td>\n",
              "      <td>2019</td>\n",
              "      <td>15354.608</td>\n",
              "      <td>18278</td>\n",
              "      <td>43769.0</td>\n",
              "      <td>80000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6612</th>\n",
              "      <td>181</td>\n",
              "      <td>2020</td>\n",
              "      <td>15669.666</td>\n",
              "      <td>18278</td>\n",
              "      <td>82068.0</td>\n",
              "      <td>150000.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4980 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fc794eec-346c-4088-ae03-ed836870c031')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fc794eec-346c-4088-ae03-ed836870c031 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fc794eec-346c-4088-ae03-ed836870c031');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      Area Code (FAO)  Year  population  yield  harvested      Value\n",
              "0                   2  1961    8790.140  10220  2230000.0  2279000.0\n",
              "1                   2  1962    8969.047   9735  2341000.0  2279000.0\n",
              "2                   2  1963    9157.465   8317  2341000.0  1947000.0\n",
              "3                   2  1964    9355.514   9510  2345000.0  2230000.0\n",
              "4                   2  1965    9565.147   9723  2347000.0  2282000.0\n",
              "...               ...   ...         ...    ...        ...        ...\n",
              "6608              181  2016   14452.704  19013    22094.0    42008.0\n",
              "6609              181  2017   14751.101  17542    22070.0    38715.0\n",
              "6610              181  2018   15052.184  16206    27767.0    45000.0\n",
              "6611              181  2019   15354.608  18278    43769.0    80000.0\n",
              "6612              181  2020   15669.666  18278    82068.0   150000.0\n",
              "\n",
              "[4980 rows x 6 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#clear rows whithout 60 years\n",
        "d=(df.groupby('Area Code (FAO)').count()==60)[['Year']]\n",
        "d=list(d[d['Year']==True].reset_index()['Area Code (FAO)'])\n",
        "for i in range(len(df)):\n",
        "    if df['Area Code (FAO)'][i] not in d:\n",
        "        df.drop(i,axis=0,inplace=True)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VndkxGHoMqtD",
        "outputId": "ac21abbf-cd8f-45cc-ee0d-979f38c960b9",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(83, 1, 60)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(df.groupby('Area Code (FAO)').count()==60).sum()\n",
        "Y=df['Value']\n",
        "Y=np.array(Y)\n",
        "Y=Y.reshape(83,1,60)\n",
        "Y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1tuul89MqtE",
        "outputId": "9fbeb83a-da36-45aa-f035-c70f19452e18",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UptWigV6MqtE",
        "outputId": "81251c24-696d-4f93-e359-e000cdaeee53",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 8790.14   8969.047  9157.465 ... 36686.784 37769.499 38972.23 ]\n",
            " [ 1769.079  1828.232  1888.302 ...  2877.013  2873.883  2866.849]\n",
            " [11598.608 11778.26  11969.451 ... 41927.007 42705.368 43451.666]\n",
            " ...\n",
            " [ 5646.668  5753.386  5860.197 ... 30790.513 31546.691 32284.046]\n",
            " [ 3219.451  3323.427  3431.381 ... 17835.893 18380.477 18927.715]\n",
            " [ 3925.952  4049.778  4177.931 ... 15052.184 15354.608 15669.666]]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[[8.7901400e+03, 8.9690470e+03, 9.1574650e+03, ...,\n",
              "         3.6686784e+04, 3.7769499e+04, 3.8972230e+04],\n",
              "        [1.0220000e+04, 9.7350000e+03, 8.3170000e+03, ...,\n",
              "         2.2100000e+04, 2.0951000e+04, 1.9434000e+04],\n",
              "        [2.2300000e+06, 2.3410000e+06, 2.3410000e+06, ...,\n",
              "         1.6350000e+06, 2.3340000e+06, 2.6680000e+06]],\n",
              "\n",
              "       [[1.7690790e+03, 1.8282320e+03, 1.8883020e+03, ...,\n",
              "         2.8770130e+03, 2.8738830e+03, 2.8668490e+03],\n",
              "        [7.7310000e+03, 1.0522000e+04, 7.1270000e+03, ...,\n",
              "         3.6927000e+04, 4.0680000e+04, 4.3271000e+04],\n",
              "        [1.2650000e+05, 1.3914400e+05, 8.6660000e+04, ...,\n",
              "         6.5072000e+04, 5.7330000e+04, 5.3946000e+04]],\n",
              "\n",
              "       [[1.1598608e+04, 1.1778260e+04, 1.1969451e+04, ...,\n",
              "         4.1927007e+04, 4.2705368e+04, 4.3451666e+04],\n",
              "        [4.0600000e+03, 8.0450000e+03, 8.3260000e+03, ...,\n",
              "         2.0433000e+04, 1.9630000e+04, 1.6811000e+04],\n",
              "        [1.6890640e+06, 1.8733000e+06, 1.9092030e+06, ...,\n",
              "         1.9484020e+06, 1.9749870e+06, 1.8480830e+06]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[5.6466680e+03, 5.7533860e+03, 5.8601970e+03, ...,\n",
              "         3.0790513e+04, 3.1546691e+04, 3.2284046e+04],\n",
              "        [1.3077000e+04, 1.2963000e+04, 1.2982000e+04, ...,\n",
              "         1.4332000e+04, 1.7459000e+04, 1.7627000e+04],\n",
              "        [2.6000000e+04, 2.7000000e+04, 2.8500000e+04, ...,\n",
              "         6.4339000e+04, 5.7466000e+04, 5.7218000e+04]],\n",
              "\n",
              "       [[3.2194510e+03, 3.3234270e+03, 3.4313810e+03, ...,\n",
              "         1.7835893e+04, 1.8380477e+04, 1.8927715e+04],\n",
              "        [1.6000000e+04, 1.6859000e+04, 2.0140000e+04, ...,\n",
              "         5.2809000e+04, 6.6877000e+04, 7.3680000e+04],\n",
              "        [3.8000000e+02, 5.5400000e+02, 3.5600000e+02, ...,\n",
              "         2.1675000e+04, 2.2706000e+04, 2.6007000e+04]],\n",
              "\n",
              "       [[3.9259520e+03, 4.0497780e+03, 4.1779310e+03, ...,\n",
              "         1.5052184e+04, 1.5354608e+04, 1.5669666e+04],\n",
              "        [1.4673000e+04, 1.5895000e+04, 1.9530000e+04, ...,\n",
              "         1.6206000e+04, 1.8278000e+04, 1.8278000e+04],\n",
              "        [5.5000000e+02, 7.6500000e+02, 9.5700000e+02, ...,\n",
              "         2.7767000e+04, 4.3769000e+04, 8.2068000e+04]]])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "arr=np.array([])\n",
        "\n",
        "#create a 2d array for population that each rows show populations for a country\n",
        "population=df.loc[:,\"population\"]\n",
        "population=population.values.tolist()\n",
        "population=np.array(population)\n",
        "population=population.reshape(83,60)\n",
        "print(population)\n",
        "\n",
        "\n",
        "#create a 2d array for yield that each rows show yields for a country\n",
        "Yield=df.loc[:,\"yield\"]\n",
        "Yield=Yield.values.tolist()\n",
        "Yield=np.array(Yield)\n",
        "Yield=Yield.reshape(83,60)\n",
        "\n",
        "#create a 2d array for harvested that each rows show harvesteds for a country\n",
        "harvested=df.loc[:,\"harvested\"]\n",
        "harvested=harvested.values.tolist()\n",
        "harvested=np.array(harvested)\n",
        "harvested=harvested.reshape(83,60)\n",
        "\n",
        "#create a 2d array for production that each rows show productions for a country\n",
        "#production=df.loc[:,\"production\"]\n",
        "#production=production.values.tolist()\n",
        "#production=np.array(production)\n",
        "#production=production.reshape(83,60)\n",
        "\n",
        "\n",
        "#create a 1d array that we will make it to a 3d array\n",
        "for i in range(83):\n",
        "    arr=np.append(arr,population[i])\n",
        "    arr=np.append(arr,Yield[i])\n",
        "    arr=np.append(arr,harvested[i])\n",
        "    #arr=np.append(arr,production[i])\n",
        "\n",
        "#reshape 1d array to a 3d array that each dimension is for a country , culomn for years , and rows for values\n",
        "arr=arr.reshape(83,3,60)\n",
        "arr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "JMzEGg0tMqtF",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "#preproccessing dataset \n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scalers={}\n",
        "for i in range(arr.shape[1]):\n",
        "    scalers[i]=StandardScaler()\n",
        "    arr[:,i,:] = scalers[i].fit_transform(arr[:,i,:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4zU_HIJMqtF",
        "outputId": "a8246d9a-4090-474a-eacc-217acda82c55",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(66, 3, 60) (17, 3, 60) (66, 1, 60) (17, 1, 60)\n"
          ]
        }
      ],
      "source": [
        "#split dataset into train and test parts\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(arr,Y, test_size=0.2)\n",
        "print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKPLy72EMqtG",
        "outputId": "6481f9e1-ca06-4eef-ecc6-05e7b39abec8",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((66, 3, 60, 1), (17, 3, 60, 1))"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Reshape X_train and X_test\n",
        "X_train = X_train.reshape(X_train.shape[0], 3, 60, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 3, 60, 1)\n",
        "\n",
        "X_train.shape, X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uK6buJZpMqtG",
        "outputId": "989c51f1-8547-4c97-b131-9725af7bafe8",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.7/135.7 KB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install keras-tuner -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_dhrsICAMqtH",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras.layers import Flatten, Dense, Conv2D, MaxPooling2D,Input\n",
        "from keras import layers, Model\n",
        "from keras_tuner.tuners import RandomSearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDj7HRPGMqtH",
        "outputId": "78808214-05c4-449c-d4d6-c0f88b95da29",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "66/66 [==============================] - 2s 11ms/step - loss: 98.6685 - mean_absolute_percentage_error: 98.6685 - val_loss: 95.9568 - val_mean_absolute_percentage_error: 95.9568\n",
            "Epoch 2/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 97.6462 - mean_absolute_percentage_error: 97.6462 - val_loss: 98.8531 - val_mean_absolute_percentage_error: 98.8531\n",
            "Epoch 3/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 97.3080 - mean_absolute_percentage_error: 97.3080 - val_loss: 97.6022 - val_mean_absolute_percentage_error: 97.6022\n",
            "Epoch 4/1000\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 96.0737 - mean_absolute_percentage_error: 96.0737 - val_loss: 96.6537 - val_mean_absolute_percentage_error: 96.6537\n",
            "Epoch 5/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 96.8171 - mean_absolute_percentage_error: 96.8171 - val_loss: 96.7424 - val_mean_absolute_percentage_error: 96.7424\n",
            "Epoch 6/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 98.1353 - mean_absolute_percentage_error: 98.1353 - val_loss: 98.2332 - val_mean_absolute_percentage_error: 98.2332\n",
            "Epoch 7/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 96.1818 - mean_absolute_percentage_error: 96.1818 - val_loss: 96.5980 - val_mean_absolute_percentage_error: 96.5980\n",
            "Epoch 8/1000\n",
            "66/66 [==============================] - 1s 14ms/step - loss: 95.9977 - mean_absolute_percentage_error: 95.9977 - val_loss: 96.9542 - val_mean_absolute_percentage_error: 96.9542\n",
            "Epoch 9/1000\n",
            "66/66 [==============================] - 1s 15ms/step - loss: 95.6057 - mean_absolute_percentage_error: 95.6057 - val_loss: 97.0044 - val_mean_absolute_percentage_error: 97.0044\n",
            "Epoch 10/1000\n",
            "66/66 [==============================] - 1s 15ms/step - loss: 95.4844 - mean_absolute_percentage_error: 95.4844 - val_loss: 96.7267 - val_mean_absolute_percentage_error: 96.7267\n",
            "Epoch 11/1000\n",
            "66/66 [==============================] - 1s 15ms/step - loss: 95.4598 - mean_absolute_percentage_error: 95.4598 - val_loss: 96.9569 - val_mean_absolute_percentage_error: 96.9569\n",
            "Epoch 12/1000\n",
            "66/66 [==============================] - 1s 14ms/step - loss: 95.6186 - mean_absolute_percentage_error: 95.6186 - val_loss: 97.0899 - val_mean_absolute_percentage_error: 97.0899\n",
            "Epoch 13/1000\n",
            "66/66 [==============================] - 1s 15ms/step - loss: 95.1166 - mean_absolute_percentage_error: 95.1166 - val_loss: 96.8222 - val_mean_absolute_percentage_error: 96.8222\n",
            "Epoch 14/1000\n",
            "66/66 [==============================] - 1s 14ms/step - loss: 95.4446 - mean_absolute_percentage_error: 95.4446 - val_loss: 97.5814 - val_mean_absolute_percentage_error: 97.5814\n",
            "Epoch 15/1000\n",
            "66/66 [==============================] - 1s 15ms/step - loss: 96.7295 - mean_absolute_percentage_error: 96.7295 - val_loss: 96.8812 - val_mean_absolute_percentage_error: 96.8812\n",
            "Epoch 16/1000\n",
            "66/66 [==============================] - 1s 14ms/step - loss: 94.7266 - mean_absolute_percentage_error: 94.7266 - val_loss: 96.4172 - val_mean_absolute_percentage_error: 96.4172\n",
            "Epoch 17/1000\n",
            "66/66 [==============================] - 1s 13ms/step - loss: 95.4533 - mean_absolute_percentage_error: 95.4533 - val_loss: 97.0350 - val_mean_absolute_percentage_error: 97.0350\n",
            "Epoch 18/1000\n",
            "66/66 [==============================] - 1s 15ms/step - loss: 94.3223 - mean_absolute_percentage_error: 94.3223 - val_loss: 96.6560 - val_mean_absolute_percentage_error: 96.6560\n",
            "Epoch 19/1000\n",
            "66/66 [==============================] - 1s 15ms/step - loss: 94.4676 - mean_absolute_percentage_error: 94.4676 - val_loss: 96.6179 - val_mean_absolute_percentage_error: 96.6179\n",
            "Epoch 20/1000\n",
            "66/66 [==============================] - 1s 13ms/step - loss: 94.6048 - mean_absolute_percentage_error: 94.6048 - val_loss: 96.2731 - val_mean_absolute_percentage_error: 96.2731\n",
            "Epoch 21/1000\n",
            "66/66 [==============================] - 1s 15ms/step - loss: 93.9494 - mean_absolute_percentage_error: 93.9494 - val_loss: 96.4698 - val_mean_absolute_percentage_error: 96.4698\n",
            "Epoch 22/1000\n",
            "66/66 [==============================] - 1s 14ms/step - loss: 93.5788 - mean_absolute_percentage_error: 93.5788 - val_loss: 96.3072 - val_mean_absolute_percentage_error: 96.3072\n",
            "Epoch 23/1000\n",
            "66/66 [==============================] - 1s 14ms/step - loss: 93.8759 - mean_absolute_percentage_error: 93.8759 - val_loss: 96.2247 - val_mean_absolute_percentage_error: 96.2247\n",
            "Epoch 24/1000\n",
            "66/66 [==============================] - 1s 14ms/step - loss: 94.3987 - mean_absolute_percentage_error: 94.3987 - val_loss: 96.5675 - val_mean_absolute_percentage_error: 96.5675\n",
            "Epoch 25/1000\n",
            "66/66 [==============================] - 1s 13ms/step - loss: 94.6824 - mean_absolute_percentage_error: 94.6824 - val_loss: 96.2575 - val_mean_absolute_percentage_error: 96.2575\n",
            "Epoch 26/1000\n",
            "66/66 [==============================] - 1s 14ms/step - loss: 93.2103 - mean_absolute_percentage_error: 93.2103 - val_loss: 96.6479 - val_mean_absolute_percentage_error: 96.6479\n",
            "Epoch 27/1000\n",
            "66/66 [==============================] - 1s 13ms/step - loss: 94.7594 - mean_absolute_percentage_error: 94.7594 - val_loss: 96.0467 - val_mean_absolute_percentage_error: 96.0467\n",
            "Epoch 28/1000\n",
            "66/66 [==============================] - 1s 14ms/step - loss: 94.6425 - mean_absolute_percentage_error: 94.6425 - val_loss: 96.3507 - val_mean_absolute_percentage_error: 96.3507\n",
            "Epoch 29/1000\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 93.3129 - mean_absolute_percentage_error: 93.3129 - val_loss: 96.4707 - val_mean_absolute_percentage_error: 96.4707\n",
            "Epoch 30/1000\n",
            "66/66 [==============================] - 1s 14ms/step - loss: 93.5854 - mean_absolute_percentage_error: 93.5854 - val_loss: 95.9755 - val_mean_absolute_percentage_error: 95.9755\n",
            "Epoch 31/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 93.8857 - mean_absolute_percentage_error: 93.8857 - val_loss: 96.1567 - val_mean_absolute_percentage_error: 96.1567\n",
            "Epoch 32/1000\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 95.3658 - mean_absolute_percentage_error: 95.3658 - val_loss: 97.1174 - val_mean_absolute_percentage_error: 97.1174\n",
            "Epoch 33/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 93.5853 - mean_absolute_percentage_error: 93.5853 - val_loss: 96.5652 - val_mean_absolute_percentage_error: 96.5652\n",
            "Epoch 34/1000\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 93.6189 - mean_absolute_percentage_error: 93.6189 - val_loss: 95.9318 - val_mean_absolute_percentage_error: 95.9318\n",
            "Epoch 35/1000\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 93.2530 - mean_absolute_percentage_error: 93.2530 - val_loss: 96.5189 - val_mean_absolute_percentage_error: 96.5189\n",
            "Epoch 36/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 93.2849 - mean_absolute_percentage_error: 93.2849 - val_loss: 96.1898 - val_mean_absolute_percentage_error: 96.1898\n",
            "Epoch 37/1000\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 94.5693 - mean_absolute_percentage_error: 94.5693 - val_loss: 96.2768 - val_mean_absolute_percentage_error: 96.2768\n",
            "Epoch 38/1000\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 92.5756 - mean_absolute_percentage_error: 92.5756 - val_loss: 96.1537 - val_mean_absolute_percentage_error: 96.1537\n",
            "Epoch 39/1000\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 93.8130 - mean_absolute_percentage_error: 93.8130 - val_loss: 96.2227 - val_mean_absolute_percentage_error: 96.2227\n",
            "Epoch 40/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 92.4922 - mean_absolute_percentage_error: 92.4922 - val_loss: 96.3362 - val_mean_absolute_percentage_error: 96.3362\n",
            "Epoch 41/1000\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 92.8305 - mean_absolute_percentage_error: 92.8305 - val_loss: 96.1856 - val_mean_absolute_percentage_error: 96.1856\n",
            "Epoch 42/1000\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 93.1323 - mean_absolute_percentage_error: 93.1323 - val_loss: 96.3542 - val_mean_absolute_percentage_error: 96.3542\n",
            "Epoch 43/1000\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 94.3702 - mean_absolute_percentage_error: 94.3702 - val_loss: 96.8980 - val_mean_absolute_percentage_error: 96.8980\n",
            "Epoch 44/1000\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 93.5101 - mean_absolute_percentage_error: 93.5101 - val_loss: 96.3607 - val_mean_absolute_percentage_error: 96.3607\n",
            "Epoch 45/1000\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 93.1529 - mean_absolute_percentage_error: 93.1529 - val_loss: 96.2558 - val_mean_absolute_percentage_error: 96.2558\n",
            "Epoch 46/1000\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 92.8265 - mean_absolute_percentage_error: 92.8265 - val_loss: 95.9854 - val_mean_absolute_percentage_error: 95.9854\n",
            "Epoch 47/1000\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 93.0762 - mean_absolute_percentage_error: 93.0762 - val_loss: 96.3734 - val_mean_absolute_percentage_error: 96.3734\n",
            "Epoch 48/1000\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 92.5145 - mean_absolute_percentage_error: 92.5145 - val_loss: 96.2884 - val_mean_absolute_percentage_error: 96.2884\n",
            "Epoch 49/1000\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 92.2869 - mean_absolute_percentage_error: 92.2869 - val_loss: 97.2642 - val_mean_absolute_percentage_error: 97.2642\n",
            "Epoch 50/1000\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 94.2213 - mean_absolute_percentage_error: 94.2213 - val_loss: 96.3536 - val_mean_absolute_percentage_error: 96.3536\n",
            "Epoch 51/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 93.2252 - mean_absolute_percentage_error: 93.2252 - val_loss: 96.2723 - val_mean_absolute_percentage_error: 96.2723\n",
            "Epoch 52/1000\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 92.1888 - mean_absolute_percentage_error: 92.1888 - val_loss: 96.5772 - val_mean_absolute_percentage_error: 96.5772\n",
            "Epoch 53/1000\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 92.5498 - mean_absolute_percentage_error: 92.5498 - val_loss: 95.9990 - val_mean_absolute_percentage_error: 95.9990\n",
            "Epoch 54/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 92.5014 - mean_absolute_percentage_error: 92.5014 - val_loss: 96.3605 - val_mean_absolute_percentage_error: 96.3605\n",
            "Epoch 55/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 91.9585 - mean_absolute_percentage_error: 91.9585 - val_loss: 96.1076 - val_mean_absolute_percentage_error: 96.1076\n",
            "Epoch 56/1000\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 92.8176 - mean_absolute_percentage_error: 92.8176 - val_loss: 96.5188 - val_mean_absolute_percentage_error: 96.5188\n",
            "Epoch 57/1000\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 93.1189 - mean_absolute_percentage_error: 93.1189 - val_loss: 96.3676 - val_mean_absolute_percentage_error: 96.3676\n",
            "Epoch 58/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 92.2339 - mean_absolute_percentage_error: 92.2339 - val_loss: 96.2035 - val_mean_absolute_percentage_error: 96.2035\n",
            "Epoch 59/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 92.1302 - mean_absolute_percentage_error: 92.1302 - val_loss: 96.3265 - val_mean_absolute_percentage_error: 96.3265\n",
            "Epoch 60/1000\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 91.9434 - mean_absolute_percentage_error: 91.9434 - val_loss: 96.1730 - val_mean_absolute_percentage_error: 96.1730\n",
            "Epoch 61/1000\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 91.7690 - mean_absolute_percentage_error: 91.7690 - val_loss: 96.3791 - val_mean_absolute_percentage_error: 96.3791\n",
            "Epoch 62/1000\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 92.0557 - mean_absolute_percentage_error: 92.0557 - val_loss: 95.8838 - val_mean_absolute_percentage_error: 95.8838\n",
            "Epoch 63/1000\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 92.6254 - mean_absolute_percentage_error: 92.6254 - val_loss: 96.3422 - val_mean_absolute_percentage_error: 96.3422\n",
            "Epoch 64/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 93.0095 - mean_absolute_percentage_error: 93.0095 - val_loss: 95.9714 - val_mean_absolute_percentage_error: 95.9714\n",
            "Epoch 65/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 91.4331 - mean_absolute_percentage_error: 91.4331 - val_loss: 96.3694 - val_mean_absolute_percentage_error: 96.3694\n",
            "Epoch 66/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 92.2690 - mean_absolute_percentage_error: 92.2690 - val_loss: 96.2891 - val_mean_absolute_percentage_error: 96.2891\n",
            "Epoch 67/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 92.4336 - mean_absolute_percentage_error: 92.4336 - val_loss: 96.2490 - val_mean_absolute_percentage_error: 96.2490\n",
            "Epoch 68/1000\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 91.5903 - mean_absolute_percentage_error: 91.5903 - val_loss: 95.9984 - val_mean_absolute_percentage_error: 95.9984\n",
            "Epoch 69/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 91.2649 - mean_absolute_percentage_error: 91.2649 - val_loss: 96.1455 - val_mean_absolute_percentage_error: 96.1455\n",
            "Epoch 70/1000\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 91.9901 - mean_absolute_percentage_error: 91.9901 - val_loss: 96.0205 - val_mean_absolute_percentage_error: 96.0205\n",
            "Epoch 71/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 92.5856 - mean_absolute_percentage_error: 92.5856 - val_loss: 96.1773 - val_mean_absolute_percentage_error: 96.1773\n",
            "Epoch 72/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 91.0383 - mean_absolute_percentage_error: 91.0383 - val_loss: 96.1700 - val_mean_absolute_percentage_error: 96.1700\n",
            "Epoch 73/1000\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 91.9467 - mean_absolute_percentage_error: 91.9467 - val_loss: 96.2476 - val_mean_absolute_percentage_error: 96.2476\n",
            "Epoch 74/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 90.9096 - mean_absolute_percentage_error: 90.9096 - val_loss: 96.1884 - val_mean_absolute_percentage_error: 96.1884\n",
            "Epoch 75/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 91.2667 - mean_absolute_percentage_error: 91.2667 - val_loss: 96.1537 - val_mean_absolute_percentage_error: 96.1537\n",
            "Epoch 76/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 91.5854 - mean_absolute_percentage_error: 91.5854 - val_loss: 96.0870 - val_mean_absolute_percentage_error: 96.0870\n",
            "Epoch 77/1000\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 92.0865 - mean_absolute_percentage_error: 92.0865 - val_loss: 96.0333 - val_mean_absolute_percentage_error: 96.0333\n",
            "Epoch 78/1000\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 90.7490 - mean_absolute_percentage_error: 90.7490 - val_loss: 96.2266 - val_mean_absolute_percentage_error: 96.2266\n",
            "Epoch 79/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 91.3080 - mean_absolute_percentage_error: 91.3080 - val_loss: 95.9471 - val_mean_absolute_percentage_error: 95.9471\n",
            "Epoch 80/1000\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 91.8042 - mean_absolute_percentage_error: 91.8042 - val_loss: 96.2786 - val_mean_absolute_percentage_error: 96.2786\n",
            "Epoch 81/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 91.7052 - mean_absolute_percentage_error: 91.7052 - val_loss: 96.2951 - val_mean_absolute_percentage_error: 96.2951\n",
            "Epoch 82/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 91.7939 - mean_absolute_percentage_error: 91.7939 - val_loss: 96.1659 - val_mean_absolute_percentage_error: 96.1659\n",
            "Epoch 83/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 91.5113 - mean_absolute_percentage_error: 91.5113 - val_loss: 96.2882 - val_mean_absolute_percentage_error: 96.2882\n",
            "Epoch 84/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 91.3018 - mean_absolute_percentage_error: 91.3018 - val_loss: 96.2858 - val_mean_absolute_percentage_error: 96.2858\n",
            "Epoch 85/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 91.0869 - mean_absolute_percentage_error: 91.0869 - val_loss: 96.2934 - val_mean_absolute_percentage_error: 96.2934\n",
            "Epoch 86/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 91.5784 - mean_absolute_percentage_error: 91.5784 - val_loss: 96.0331 - val_mean_absolute_percentage_error: 96.0331\n",
            "Epoch 87/1000\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 90.8125 - mean_absolute_percentage_error: 90.8125 - val_loss: 96.4057 - val_mean_absolute_percentage_error: 96.4057\n",
            "Epoch 88/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 91.3654 - mean_absolute_percentage_error: 91.3654 - val_loss: 96.3513 - val_mean_absolute_percentage_error: 96.3513\n",
            "Epoch 89/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 91.6752 - mean_absolute_percentage_error: 91.6752 - val_loss: 96.0886 - val_mean_absolute_percentage_error: 96.0886\n",
            "Epoch 90/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 91.0517 - mean_absolute_percentage_error: 91.0517 - val_loss: 96.6824 - val_mean_absolute_percentage_error: 96.6824\n",
            "Epoch 91/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 91.5136 - mean_absolute_percentage_error: 91.5136 - val_loss: 96.4935 - val_mean_absolute_percentage_error: 96.4935\n",
            "Epoch 92/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 91.2556 - mean_absolute_percentage_error: 91.2556 - val_loss: 96.4481 - val_mean_absolute_percentage_error: 96.4481\n",
            "Epoch 93/1000\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 91.1880 - mean_absolute_percentage_error: 91.1880 - val_loss: 96.2437 - val_mean_absolute_percentage_error: 96.2437\n",
            "Epoch 94/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 90.8997 - mean_absolute_percentage_error: 90.8997 - val_loss: 96.2750 - val_mean_absolute_percentage_error: 96.2750\n",
            "Epoch 95/1000\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 90.3890 - mean_absolute_percentage_error: 90.3890 - val_loss: 96.3499 - val_mean_absolute_percentage_error: 96.3499\n",
            "Epoch 96/1000\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 91.1135 - mean_absolute_percentage_error: 91.1135 - val_loss: 96.2501 - val_mean_absolute_percentage_error: 96.2501\n",
            "Epoch 97/1000\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 91.3038 - mean_absolute_percentage_error: 91.3038 - val_loss: 96.8581 - val_mean_absolute_percentage_error: 96.8581\n",
            "Epoch 98/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 91.9829 - mean_absolute_percentage_error: 91.9829 - val_loss: 96.1921 - val_mean_absolute_percentage_error: 96.1921\n",
            "Epoch 99/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 91.7340 - mean_absolute_percentage_error: 91.7340 - val_loss: 96.1499 - val_mean_absolute_percentage_error: 96.1499\n",
            "Epoch 100/1000\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 90.4234 - mean_absolute_percentage_error: 90.4234 - val_loss: 96.2527 - val_mean_absolute_percentage_error: 96.2527\n",
            "Epoch 101/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 90.1381 - mean_absolute_percentage_error: 90.1381 - val_loss: 96.6542 - val_mean_absolute_percentage_error: 96.6542\n",
            "Epoch 102/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 90.8742 - mean_absolute_percentage_error: 90.8742 - val_loss: 96.1517 - val_mean_absolute_percentage_error: 96.1517\n",
            "Epoch 103/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 90.1014 - mean_absolute_percentage_error: 90.1014 - val_loss: 96.2425 - val_mean_absolute_percentage_error: 96.2425\n",
            "Epoch 104/1000\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 91.2734 - mean_absolute_percentage_error: 91.2734 - val_loss: 96.1433 - val_mean_absolute_percentage_error: 96.1433\n",
            "Epoch 105/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 90.9355 - mean_absolute_percentage_error: 90.9355 - val_loss: 96.0912 - val_mean_absolute_percentage_error: 96.0912\n",
            "Epoch 106/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 90.3838 - mean_absolute_percentage_error: 90.3838 - val_loss: 96.9574 - val_mean_absolute_percentage_error: 96.9574\n",
            "Epoch 107/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 91.4457 - mean_absolute_percentage_error: 91.4457 - val_loss: 96.3687 - val_mean_absolute_percentage_error: 96.3687\n",
            "Epoch 108/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 90.4816 - mean_absolute_percentage_error: 90.4816 - val_loss: 96.8028 - val_mean_absolute_percentage_error: 96.8028\n",
            "Epoch 109/1000\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 90.9654 - mean_absolute_percentage_error: 90.9654 - val_loss: 96.1729 - val_mean_absolute_percentage_error: 96.1729\n",
            "Epoch 110/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 90.2875 - mean_absolute_percentage_error: 90.2875 - val_loss: 96.0572 - val_mean_absolute_percentage_error: 96.0572\n",
            "Epoch 111/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 89.9182 - mean_absolute_percentage_error: 89.9182 - val_loss: 96.3212 - val_mean_absolute_percentage_error: 96.3212\n",
            "Epoch 112/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 89.5828 - mean_absolute_percentage_error: 89.5828 - val_loss: 96.2344 - val_mean_absolute_percentage_error: 96.2344\n",
            "Epoch 113/1000\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 90.2916 - mean_absolute_percentage_error: 90.2916 - val_loss: 96.0316 - val_mean_absolute_percentage_error: 96.0316\n",
            "Epoch 114/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 90.6670 - mean_absolute_percentage_error: 90.6670 - val_loss: 96.1627 - val_mean_absolute_percentage_error: 96.1627\n",
            "Epoch 115/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 90.1307 - mean_absolute_percentage_error: 90.1307 - val_loss: 96.0503 - val_mean_absolute_percentage_error: 96.0503\n",
            "Epoch 116/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 90.2155 - mean_absolute_percentage_error: 90.2155 - val_loss: 96.4401 - val_mean_absolute_percentage_error: 96.4401\n",
            "Epoch 117/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 90.6707 - mean_absolute_percentage_error: 90.6707 - val_loss: 96.3423 - val_mean_absolute_percentage_error: 96.3423\n",
            "Epoch 118/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 90.6657 - mean_absolute_percentage_error: 90.6657 - val_loss: 96.4528 - val_mean_absolute_percentage_error: 96.4528\n",
            "Epoch 119/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 89.6079 - mean_absolute_percentage_error: 89.6079 - val_loss: 96.0269 - val_mean_absolute_percentage_error: 96.0269\n",
            "Epoch 120/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 89.7780 - mean_absolute_percentage_error: 89.7780 - val_loss: 96.5373 - val_mean_absolute_percentage_error: 96.5373\n",
            "Epoch 121/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 89.6935 - mean_absolute_percentage_error: 89.6935 - val_loss: 96.9748 - val_mean_absolute_percentage_error: 96.9748\n",
            "Epoch 122/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 89.5589 - mean_absolute_percentage_error: 89.5589 - val_loss: 95.8567 - val_mean_absolute_percentage_error: 95.8567\n",
            "Epoch 123/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 90.7312 - mean_absolute_percentage_error: 90.7312 - val_loss: 96.3108 - val_mean_absolute_percentage_error: 96.3108\n",
            "Epoch 124/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 89.5464 - mean_absolute_percentage_error: 89.5464 - val_loss: 95.8135 - val_mean_absolute_percentage_error: 95.8135\n",
            "Epoch 125/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 89.7059 - mean_absolute_percentage_error: 89.7059 - val_loss: 96.1357 - val_mean_absolute_percentage_error: 96.1357\n",
            "Epoch 126/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 91.0709 - mean_absolute_percentage_error: 91.0709 - val_loss: 96.4285 - val_mean_absolute_percentage_error: 96.4285\n",
            "Epoch 127/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 90.4865 - mean_absolute_percentage_error: 90.4865 - val_loss: 96.3255 - val_mean_absolute_percentage_error: 96.3255\n",
            "Epoch 128/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 89.4947 - mean_absolute_percentage_error: 89.4947 - val_loss: 96.3156 - val_mean_absolute_percentage_error: 96.3156\n",
            "Epoch 129/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 89.7086 - mean_absolute_percentage_error: 89.7086 - val_loss: 95.9261 - val_mean_absolute_percentage_error: 95.9261\n",
            "Epoch 130/1000\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 90.1495 - mean_absolute_percentage_error: 90.1495 - val_loss: 96.4593 - val_mean_absolute_percentage_error: 96.4593\n",
            "Epoch 131/1000\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 89.1708 - mean_absolute_percentage_error: 89.1708 - val_loss: 95.9513 - val_mean_absolute_percentage_error: 95.9513\n",
            "Epoch 132/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 89.3893 - mean_absolute_percentage_error: 89.3893 - val_loss: 96.1295 - val_mean_absolute_percentage_error: 96.1295\n",
            "Epoch 133/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 90.6719 - mean_absolute_percentage_error: 90.6719 - val_loss: 96.2800 - val_mean_absolute_percentage_error: 96.2800\n",
            "Epoch 134/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 90.0254 - mean_absolute_percentage_error: 90.0254 - val_loss: 96.3805 - val_mean_absolute_percentage_error: 96.3805\n",
            "Epoch 135/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 89.1067 - mean_absolute_percentage_error: 89.1067 - val_loss: 96.2637 - val_mean_absolute_percentage_error: 96.2637\n",
            "Epoch 136/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 90.1589 - mean_absolute_percentage_error: 90.1589 - val_loss: 97.3158 - val_mean_absolute_percentage_error: 97.3158\n",
            "Epoch 137/1000\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 89.7672 - mean_absolute_percentage_error: 89.7672 - val_loss: 96.5718 - val_mean_absolute_percentage_error: 96.5718\n",
            "Epoch 138/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 89.0327 - mean_absolute_percentage_error: 89.0327 - val_loss: 96.8898 - val_mean_absolute_percentage_error: 96.8898\n",
            "Epoch 139/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 90.5330 - mean_absolute_percentage_error: 90.5330 - val_loss: 96.0023 - val_mean_absolute_percentage_error: 96.0023\n",
            "Epoch 140/1000\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 89.2798 - mean_absolute_percentage_error: 89.2798 - val_loss: 96.6870 - val_mean_absolute_percentage_error: 96.6870\n",
            "Epoch 141/1000\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 89.8818 - mean_absolute_percentage_error: 89.8818 - val_loss: 96.1639 - val_mean_absolute_percentage_error: 96.1639\n",
            "Epoch 142/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 89.1952 - mean_absolute_percentage_error: 89.1952 - val_loss: 95.7009 - val_mean_absolute_percentage_error: 95.7009\n",
            "Epoch 143/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 90.7626 - mean_absolute_percentage_error: 90.7626 - val_loss: 96.7790 - val_mean_absolute_percentage_error: 96.7790\n",
            "Epoch 144/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 89.7593 - mean_absolute_percentage_error: 89.7593 - val_loss: 96.2666 - val_mean_absolute_percentage_error: 96.2666\n",
            "Epoch 145/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 89.0970 - mean_absolute_percentage_error: 89.0970 - val_loss: 97.1220 - val_mean_absolute_percentage_error: 97.1220\n",
            "Epoch 146/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 89.7958 - mean_absolute_percentage_error: 89.7958 - val_loss: 96.3357 - val_mean_absolute_percentage_error: 96.3357\n",
            "Epoch 147/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 89.6204 - mean_absolute_percentage_error: 89.6204 - val_loss: 96.4211 - val_mean_absolute_percentage_error: 96.4211\n",
            "Epoch 148/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 88.7852 - mean_absolute_percentage_error: 88.7852 - val_loss: 97.0325 - val_mean_absolute_percentage_error: 97.0325\n",
            "Epoch 149/1000\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 89.2807 - mean_absolute_percentage_error: 89.2807 - val_loss: 96.3071 - val_mean_absolute_percentage_error: 96.3071\n",
            "Epoch 150/1000\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 89.3880 - mean_absolute_percentage_error: 89.3880 - val_loss: 96.2715 - val_mean_absolute_percentage_error: 96.2715\n",
            "Epoch 151/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 88.5822 - mean_absolute_percentage_error: 88.5822 - val_loss: 96.1695 - val_mean_absolute_percentage_error: 96.1695\n",
            "Epoch 152/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 89.1343 - mean_absolute_percentage_error: 89.1343 - val_loss: 96.9658 - val_mean_absolute_percentage_error: 96.9658\n",
            "Epoch 153/1000\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 89.3046 - mean_absolute_percentage_error: 89.3046 - val_loss: 96.1553 - val_mean_absolute_percentage_error: 96.1553\n",
            "Epoch 154/1000\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 89.8230 - mean_absolute_percentage_error: 89.8230 - val_loss: 96.5002 - val_mean_absolute_percentage_error: 96.5002\n",
            "Epoch 155/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 89.0480 - mean_absolute_percentage_error: 89.0480 - val_loss: 96.7335 - val_mean_absolute_percentage_error: 96.7335\n",
            "Epoch 156/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 88.6519 - mean_absolute_percentage_error: 88.6519 - val_loss: 97.8513 - val_mean_absolute_percentage_error: 97.8513\n",
            "Epoch 157/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 88.3321 - mean_absolute_percentage_error: 88.3321 - val_loss: 97.2017 - val_mean_absolute_percentage_error: 97.2017\n",
            "Epoch 158/1000\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 88.5327 - mean_absolute_percentage_error: 88.5327 - val_loss: 96.6554 - val_mean_absolute_percentage_error: 96.6554\n",
            "Epoch 159/1000\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 88.8166 - mean_absolute_percentage_error: 88.8166 - val_loss: 96.3553 - val_mean_absolute_percentage_error: 96.3553\n",
            "Epoch 160/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 88.4017 - mean_absolute_percentage_error: 88.4017 - val_loss: 99.1771 - val_mean_absolute_percentage_error: 99.1771\n",
            "Epoch 161/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 88.7999 - mean_absolute_percentage_error: 88.7999 - val_loss: 96.0142 - val_mean_absolute_percentage_error: 96.0142\n",
            "Epoch 162/1000\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 89.6453 - mean_absolute_percentage_error: 89.6453 - val_loss: 96.8886 - val_mean_absolute_percentage_error: 96.8886\n",
            "Epoch 163/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 89.2187 - mean_absolute_percentage_error: 89.2187 - val_loss: 96.4754 - val_mean_absolute_percentage_error: 96.4754\n",
            "Epoch 164/1000\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 89.0373 - mean_absolute_percentage_error: 89.0373 - val_loss: 97.0316 - val_mean_absolute_percentage_error: 97.0316\n",
            "Epoch 165/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 88.6323 - mean_absolute_percentage_error: 88.6323 - val_loss: 96.9908 - val_mean_absolute_percentage_error: 96.9908\n",
            "Epoch 166/1000\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 88.9013 - mean_absolute_percentage_error: 88.9013 - val_loss: 97.1767 - val_mean_absolute_percentage_error: 97.1767\n",
            "Epoch 167/1000\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 88.1780 - mean_absolute_percentage_error: 88.1780 - val_loss: 96.6700 - val_mean_absolute_percentage_error: 96.6700\n",
            "Epoch 168/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 88.4907 - mean_absolute_percentage_error: 88.4907 - val_loss: 97.1091 - val_mean_absolute_percentage_error: 97.1091\n",
            "Epoch 169/1000\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 87.9853 - mean_absolute_percentage_error: 87.9853 - val_loss: 96.6732 - val_mean_absolute_percentage_error: 96.6732\n",
            "Epoch 170/1000\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 88.8741 - mean_absolute_percentage_error: 88.8741 - val_loss: 96.6702 - val_mean_absolute_percentage_error: 96.6702\n",
            "Epoch 171/1000\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 88.1914 - mean_absolute_percentage_error: 88.1914 - val_loss: 98.4754 - val_mean_absolute_percentage_error: 98.4754\n",
            "Epoch 172/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 88.5428 - mean_absolute_percentage_error: 88.5428 - val_loss: 97.9855 - val_mean_absolute_percentage_error: 97.9855\n",
            "Epoch 173/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 88.4730 - mean_absolute_percentage_error: 88.4730 - val_loss: 96.8694 - val_mean_absolute_percentage_error: 96.8694\n",
            "Epoch 174/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 88.2957 - mean_absolute_percentage_error: 88.2957 - val_loss: 97.2944 - val_mean_absolute_percentage_error: 97.2944\n",
            "Epoch 175/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 88.0317 - mean_absolute_percentage_error: 88.0317 - val_loss: 97.3694 - val_mean_absolute_percentage_error: 97.3694\n",
            "Epoch 176/1000\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 87.6554 - mean_absolute_percentage_error: 87.6554 - val_loss: 96.8019 - val_mean_absolute_percentage_error: 96.8019\n",
            "Epoch 177/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 88.1539 - mean_absolute_percentage_error: 88.1539 - val_loss: 98.0322 - val_mean_absolute_percentage_error: 98.0322\n",
            "Epoch 178/1000\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 87.6296 - mean_absolute_percentage_error: 87.6296 - val_loss: 98.1674 - val_mean_absolute_percentage_error: 98.1674\n",
            "Epoch 179/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 87.1157 - mean_absolute_percentage_error: 87.1157 - val_loss: 99.1545 - val_mean_absolute_percentage_error: 99.1545\n",
            "Epoch 180/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 88.6120 - mean_absolute_percentage_error: 88.6120 - val_loss: 97.1903 - val_mean_absolute_percentage_error: 97.1903\n",
            "Epoch 181/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 87.9141 - mean_absolute_percentage_error: 87.9141 - val_loss: 99.6878 - val_mean_absolute_percentage_error: 99.6878\n",
            "Epoch 182/1000\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 88.5903 - mean_absolute_percentage_error: 88.5903 - val_loss: 97.4784 - val_mean_absolute_percentage_error: 97.4784\n",
            "Epoch 183/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 87.8889 - mean_absolute_percentage_error: 87.8889 - val_loss: 98.1096 - val_mean_absolute_percentage_error: 98.1096\n",
            "Epoch 184/1000\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 88.2503 - mean_absolute_percentage_error: 88.2503 - val_loss: 97.7601 - val_mean_absolute_percentage_error: 97.7601\n",
            "Epoch 185/1000\n",
            "66/66 [==============================] - 1s 14ms/step - loss: 87.7445 - mean_absolute_percentage_error: 87.7445 - val_loss: 97.3245 - val_mean_absolute_percentage_error: 97.3245\n",
            "Epoch 186/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 87.8221 - mean_absolute_percentage_error: 87.8221 - val_loss: 98.6365 - val_mean_absolute_percentage_error: 98.6365\n",
            "Epoch 187/1000\n",
            "66/66 [==============================] - 1s 13ms/step - loss: 87.7246 - mean_absolute_percentage_error: 87.7246 - val_loss: 99.1504 - val_mean_absolute_percentage_error: 99.1504\n",
            "Epoch 188/1000\n",
            "66/66 [==============================] - 1s 14ms/step - loss: 88.5163 - mean_absolute_percentage_error: 88.5163 - val_loss: 98.2953 - val_mean_absolute_percentage_error: 98.2953\n",
            "Epoch 189/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 88.0551 - mean_absolute_percentage_error: 88.0551 - val_loss: 99.1098 - val_mean_absolute_percentage_error: 99.1098\n",
            "Epoch 190/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 87.3950 - mean_absolute_percentage_error: 87.3950 - val_loss: 97.8099 - val_mean_absolute_percentage_error: 97.8099\n",
            "Epoch 191/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 87.6630 - mean_absolute_percentage_error: 87.6630 - val_loss: 98.9921 - val_mean_absolute_percentage_error: 98.9921\n",
            "Epoch 192/1000\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 86.9103 - mean_absolute_percentage_error: 86.9103 - val_loss: 100.5616 - val_mean_absolute_percentage_error: 100.5616\n",
            "Epoch 193/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 88.9324 - mean_absolute_percentage_error: 88.9324 - val_loss: 99.2995 - val_mean_absolute_percentage_error: 99.2995\n",
            "Epoch 194/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 87.1626 - mean_absolute_percentage_error: 87.1626 - val_loss: 98.7590 - val_mean_absolute_percentage_error: 98.7590\n",
            "Epoch 195/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 86.9035 - mean_absolute_percentage_error: 86.9035 - val_loss: 99.5807 - val_mean_absolute_percentage_error: 99.5807\n",
            "Epoch 196/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 87.2440 - mean_absolute_percentage_error: 87.2440 - val_loss: 99.2419 - val_mean_absolute_percentage_error: 99.2419\n",
            "Epoch 197/1000\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 87.7784 - mean_absolute_percentage_error: 87.7784 - val_loss: 98.8887 - val_mean_absolute_percentage_error: 98.8887\n",
            "Epoch 198/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 86.5292 - mean_absolute_percentage_error: 86.5292 - val_loss: 98.9800 - val_mean_absolute_percentage_error: 98.9800\n",
            "Epoch 199/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 87.7299 - mean_absolute_percentage_error: 87.7299 - val_loss: 100.6431 - val_mean_absolute_percentage_error: 100.6431\n",
            "Epoch 200/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 87.9113 - mean_absolute_percentage_error: 87.9113 - val_loss: 98.6539 - val_mean_absolute_percentage_error: 98.6539\n",
            "Epoch 201/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 86.7502 - mean_absolute_percentage_error: 86.7502 - val_loss: 99.6078 - val_mean_absolute_percentage_error: 99.6078\n",
            "Epoch 202/1000\n",
            "66/66 [==============================] - 1s 14ms/step - loss: 87.3055 - mean_absolute_percentage_error: 87.3055 - val_loss: 98.2889 - val_mean_absolute_percentage_error: 98.2889\n",
            "Epoch 203/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 87.8363 - mean_absolute_percentage_error: 87.8363 - val_loss: 98.5530 - val_mean_absolute_percentage_error: 98.5530\n",
            "Epoch 204/1000\n",
            "66/66 [==============================] - 1s 13ms/step - loss: 87.7325 - mean_absolute_percentage_error: 87.7325 - val_loss: 99.8760 - val_mean_absolute_percentage_error: 99.8760\n",
            "Epoch 205/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 88.4159 - mean_absolute_percentage_error: 88.4159 - val_loss: 99.3402 - val_mean_absolute_percentage_error: 99.3402\n",
            "Epoch 206/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 86.3255 - mean_absolute_percentage_error: 86.3255 - val_loss: 99.0600 - val_mean_absolute_percentage_error: 99.0600\n",
            "Epoch 207/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 86.7153 - mean_absolute_percentage_error: 86.7153 - val_loss: 99.3654 - val_mean_absolute_percentage_error: 99.3654\n",
            "Epoch 208/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 86.4839 - mean_absolute_percentage_error: 86.4839 - val_loss: 100.9754 - val_mean_absolute_percentage_error: 100.9754\n",
            "Epoch 209/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 86.5522 - mean_absolute_percentage_error: 86.5522 - val_loss: 100.0928 - val_mean_absolute_percentage_error: 100.0928\n",
            "Epoch 210/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 86.4507 - mean_absolute_percentage_error: 86.4507 - val_loss: 99.5482 - val_mean_absolute_percentage_error: 99.5482\n",
            "Epoch 211/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 86.8891 - mean_absolute_percentage_error: 86.8891 - val_loss: 98.2485 - val_mean_absolute_percentage_error: 98.2485\n",
            "Epoch 212/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 87.0593 - mean_absolute_percentage_error: 87.0593 - val_loss: 100.2869 - val_mean_absolute_percentage_error: 100.2869\n",
            "Epoch 213/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 87.0679 - mean_absolute_percentage_error: 87.0679 - val_loss: 98.5830 - val_mean_absolute_percentage_error: 98.5830\n",
            "Epoch 214/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 86.9931 - mean_absolute_percentage_error: 86.9931 - val_loss: 99.8550 - val_mean_absolute_percentage_error: 99.8550\n",
            "Epoch 215/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 85.9224 - mean_absolute_percentage_error: 85.9224 - val_loss: 100.6553 - val_mean_absolute_percentage_error: 100.6553\n",
            "Epoch 216/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 85.9053 - mean_absolute_percentage_error: 85.9053 - val_loss: 99.3420 - val_mean_absolute_percentage_error: 99.3420\n",
            "Epoch 217/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 89.5794 - mean_absolute_percentage_error: 89.5794 - val_loss: 98.9707 - val_mean_absolute_percentage_error: 98.9707\n",
            "Epoch 218/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 87.9381 - mean_absolute_percentage_error: 87.9381 - val_loss: 99.0586 - val_mean_absolute_percentage_error: 99.0586\n",
            "Epoch 219/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 85.3309 - mean_absolute_percentage_error: 85.3309 - val_loss: 100.3170 - val_mean_absolute_percentage_error: 100.3170\n",
            "Epoch 220/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 85.0612 - mean_absolute_percentage_error: 85.0612 - val_loss: 101.2846 - val_mean_absolute_percentage_error: 101.2846\n",
            "Epoch 221/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 86.0078 - mean_absolute_percentage_error: 86.0078 - val_loss: 100.9411 - val_mean_absolute_percentage_error: 100.9411\n",
            "Epoch 222/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 86.4426 - mean_absolute_percentage_error: 86.4426 - val_loss: 100.1811 - val_mean_absolute_percentage_error: 100.1811\n",
            "Epoch 223/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 85.6988 - mean_absolute_percentage_error: 85.6988 - val_loss: 101.7618 - val_mean_absolute_percentage_error: 101.7618\n",
            "Epoch 224/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 85.7811 - mean_absolute_percentage_error: 85.7811 - val_loss: 100.8689 - val_mean_absolute_percentage_error: 100.8689\n",
            "Epoch 225/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 85.4472 - mean_absolute_percentage_error: 85.4472 - val_loss: 104.0069 - val_mean_absolute_percentage_error: 104.0069\n",
            "Epoch 226/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 85.9555 - mean_absolute_percentage_error: 85.9555 - val_loss: 101.0542 - val_mean_absolute_percentage_error: 101.0542\n",
            "Epoch 227/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 84.8095 - mean_absolute_percentage_error: 84.8095 - val_loss: 101.5589 - val_mean_absolute_percentage_error: 101.5589\n",
            "Epoch 228/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 85.6240 - mean_absolute_percentage_error: 85.6240 - val_loss: 100.3813 - val_mean_absolute_percentage_error: 100.3813\n",
            "Epoch 229/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 84.9633 - mean_absolute_percentage_error: 84.9633 - val_loss: 103.2231 - val_mean_absolute_percentage_error: 103.2231\n",
            "Epoch 230/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 85.9073 - mean_absolute_percentage_error: 85.9073 - val_loss: 101.0243 - val_mean_absolute_percentage_error: 101.0243\n",
            "Epoch 231/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 85.4949 - mean_absolute_percentage_error: 85.4949 - val_loss: 99.7505 - val_mean_absolute_percentage_error: 99.7505\n",
            "Epoch 232/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 85.2468 - mean_absolute_percentage_error: 85.2468 - val_loss: 100.2815 - val_mean_absolute_percentage_error: 100.2815\n",
            "Epoch 233/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 85.5956 - mean_absolute_percentage_error: 85.5956 - val_loss: 101.5202 - val_mean_absolute_percentage_error: 101.5202\n",
            "Epoch 234/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 85.9609 - mean_absolute_percentage_error: 85.9609 - val_loss: 101.9078 - val_mean_absolute_percentage_error: 101.9078\n",
            "Epoch 235/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 84.3100 - mean_absolute_percentage_error: 84.3100 - val_loss: 103.9361 - val_mean_absolute_percentage_error: 103.9361\n",
            "Epoch 236/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 85.5772 - mean_absolute_percentage_error: 85.5772 - val_loss: 101.3452 - val_mean_absolute_percentage_error: 101.3452\n",
            "Epoch 237/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 84.8988 - mean_absolute_percentage_error: 84.8988 - val_loss: 101.8644 - val_mean_absolute_percentage_error: 101.8644\n",
            "Epoch 238/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 84.6732 - mean_absolute_percentage_error: 84.6732 - val_loss: 101.6666 - val_mean_absolute_percentage_error: 101.6666\n",
            "Epoch 239/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 84.6211 - mean_absolute_percentage_error: 84.6211 - val_loss: 107.3044 - val_mean_absolute_percentage_error: 107.3044\n",
            "Epoch 240/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 86.2194 - mean_absolute_percentage_error: 86.2194 - val_loss: 100.6013 - val_mean_absolute_percentage_error: 100.6013\n",
            "Epoch 241/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 85.4550 - mean_absolute_percentage_error: 85.4550 - val_loss: 99.4343 - val_mean_absolute_percentage_error: 99.4343\n",
            "Epoch 242/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 84.8932 - mean_absolute_percentage_error: 84.8932 - val_loss: 101.6940 - val_mean_absolute_percentage_error: 101.6940\n",
            "Epoch 243/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 84.6442 - mean_absolute_percentage_error: 84.6442 - val_loss: 105.1854 - val_mean_absolute_percentage_error: 105.1854\n",
            "Epoch 244/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 84.4864 - mean_absolute_percentage_error: 84.4864 - val_loss: 103.8059 - val_mean_absolute_percentage_error: 103.8059\n",
            "Epoch 245/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 84.3330 - mean_absolute_percentage_error: 84.3330 - val_loss: 102.5584 - val_mean_absolute_percentage_error: 102.5584\n",
            "Epoch 246/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 85.0579 - mean_absolute_percentage_error: 85.0579 - val_loss: 101.6543 - val_mean_absolute_percentage_error: 101.6543\n",
            "Epoch 247/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 84.7670 - mean_absolute_percentage_error: 84.7670 - val_loss: 100.8309 - val_mean_absolute_percentage_error: 100.8309\n",
            "Epoch 248/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 84.5792 - mean_absolute_percentage_error: 84.5792 - val_loss: 103.8555 - val_mean_absolute_percentage_error: 103.8555\n",
            "Epoch 249/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 85.2067 - mean_absolute_percentage_error: 85.2067 - val_loss: 102.3766 - val_mean_absolute_percentage_error: 102.3766\n",
            "Epoch 250/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 84.0189 - mean_absolute_percentage_error: 84.0189 - val_loss: 104.8769 - val_mean_absolute_percentage_error: 104.8769\n",
            "Epoch 251/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 84.7195 - mean_absolute_percentage_error: 84.7195 - val_loss: 105.3933 - val_mean_absolute_percentage_error: 105.3933\n",
            "Epoch 252/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 84.7624 - mean_absolute_percentage_error: 84.7624 - val_loss: 105.9409 - val_mean_absolute_percentage_error: 105.9409\n",
            "Epoch 253/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 85.4713 - mean_absolute_percentage_error: 85.4713 - val_loss: 103.3446 - val_mean_absolute_percentage_error: 103.3446\n",
            "Epoch 254/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 83.8864 - mean_absolute_percentage_error: 83.8864 - val_loss: 104.9841 - val_mean_absolute_percentage_error: 104.9841\n",
            "Epoch 255/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 85.0896 - mean_absolute_percentage_error: 85.0896 - val_loss: 102.9804 - val_mean_absolute_percentage_error: 102.9804\n",
            "Epoch 256/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 83.7691 - mean_absolute_percentage_error: 83.7691 - val_loss: 106.3614 - val_mean_absolute_percentage_error: 106.3614\n",
            "Epoch 257/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 84.3946 - mean_absolute_percentage_error: 84.3946 - val_loss: 102.7486 - val_mean_absolute_percentage_error: 102.7486\n",
            "Epoch 258/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 84.3719 - mean_absolute_percentage_error: 84.3719 - val_loss: 104.3494 - val_mean_absolute_percentage_error: 104.3494\n",
            "Epoch 259/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 84.6830 - mean_absolute_percentage_error: 84.6830 - val_loss: 103.3670 - val_mean_absolute_percentage_error: 103.3670\n",
            "Epoch 260/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 83.6688 - mean_absolute_percentage_error: 83.6688 - val_loss: 104.3219 - val_mean_absolute_percentage_error: 104.3219\n",
            "Epoch 261/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 83.7861 - mean_absolute_percentage_error: 83.7861 - val_loss: 105.8185 - val_mean_absolute_percentage_error: 105.8185\n",
            "Epoch 262/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 83.1286 - mean_absolute_percentage_error: 83.1286 - val_loss: 102.9170 - val_mean_absolute_percentage_error: 102.9170\n",
            "Epoch 263/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 83.9250 - mean_absolute_percentage_error: 83.9250 - val_loss: 103.4512 - val_mean_absolute_percentage_error: 103.4512\n",
            "Epoch 264/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 84.0335 - mean_absolute_percentage_error: 84.0335 - val_loss: 106.6645 - val_mean_absolute_percentage_error: 106.6645\n",
            "Epoch 265/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 84.4790 - mean_absolute_percentage_error: 84.4790 - val_loss: 102.4996 - val_mean_absolute_percentage_error: 102.4996\n",
            "Epoch 266/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 83.5168 - mean_absolute_percentage_error: 83.5168 - val_loss: 104.5444 - val_mean_absolute_percentage_error: 104.5444\n",
            "Epoch 267/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 83.5607 - mean_absolute_percentage_error: 83.5607 - val_loss: 105.8101 - val_mean_absolute_percentage_error: 105.8101\n",
            "Epoch 268/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 83.4656 - mean_absolute_percentage_error: 83.4656 - val_loss: 104.6612 - val_mean_absolute_percentage_error: 104.6612\n",
            "Epoch 269/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 83.9017 - mean_absolute_percentage_error: 83.9017 - val_loss: 103.6914 - val_mean_absolute_percentage_error: 103.6914\n",
            "Epoch 270/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 83.6283 - mean_absolute_percentage_error: 83.6283 - val_loss: 106.9396 - val_mean_absolute_percentage_error: 106.9396\n",
            "Epoch 271/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 85.7188 - mean_absolute_percentage_error: 85.7188 - val_loss: 101.6480 - val_mean_absolute_percentage_error: 101.6480\n",
            "Epoch 272/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 83.6690 - mean_absolute_percentage_error: 83.6690 - val_loss: 102.4483 - val_mean_absolute_percentage_error: 102.4483\n",
            "Epoch 273/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 84.1818 - mean_absolute_percentage_error: 84.1818 - val_loss: 103.7897 - val_mean_absolute_percentage_error: 103.7897\n",
            "Epoch 274/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 83.9051 - mean_absolute_percentage_error: 83.9051 - val_loss: 103.2609 - val_mean_absolute_percentage_error: 103.2609\n",
            "Epoch 275/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 84.1633 - mean_absolute_percentage_error: 84.1633 - val_loss: 101.9595 - val_mean_absolute_percentage_error: 101.9595\n",
            "Epoch 276/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 83.3073 - mean_absolute_percentage_error: 83.3073 - val_loss: 103.7208 - val_mean_absolute_percentage_error: 103.7208\n",
            "Epoch 277/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 83.0181 - mean_absolute_percentage_error: 83.0181 - val_loss: 103.7273 - val_mean_absolute_percentage_error: 103.7273\n",
            "Epoch 278/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 83.5878 - mean_absolute_percentage_error: 83.5878 - val_loss: 104.5643 - val_mean_absolute_percentage_error: 104.5643\n",
            "Epoch 279/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 83.8282 - mean_absolute_percentage_error: 83.8282 - val_loss: 105.6267 - val_mean_absolute_percentage_error: 105.6267\n",
            "Epoch 280/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 83.7618 - mean_absolute_percentage_error: 83.7618 - val_loss: 104.6093 - val_mean_absolute_percentage_error: 104.6093\n",
            "Epoch 281/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 83.3226 - mean_absolute_percentage_error: 83.3226 - val_loss: 109.3113 - val_mean_absolute_percentage_error: 109.3113\n",
            "Epoch 282/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 83.2700 - mean_absolute_percentage_error: 83.2700 - val_loss: 107.3389 - val_mean_absolute_percentage_error: 107.3389\n",
            "Epoch 283/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 85.0336 - mean_absolute_percentage_error: 85.0336 - val_loss: 104.3308 - val_mean_absolute_percentage_error: 104.3308\n",
            "Epoch 284/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 82.8970 - mean_absolute_percentage_error: 82.8970 - val_loss: 103.3589 - val_mean_absolute_percentage_error: 103.3589\n",
            "Epoch 285/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 83.1809 - mean_absolute_percentage_error: 83.1809 - val_loss: 108.1868 - val_mean_absolute_percentage_error: 108.1868\n",
            "Epoch 286/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 83.2903 - mean_absolute_percentage_error: 83.2903 - val_loss: 104.0171 - val_mean_absolute_percentage_error: 104.0171\n",
            "Epoch 287/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 82.5602 - mean_absolute_percentage_error: 82.5602 - val_loss: 104.8970 - val_mean_absolute_percentage_error: 104.8970\n",
            "Epoch 288/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 83.0240 - mean_absolute_percentage_error: 83.0240 - val_loss: 107.6588 - val_mean_absolute_percentage_error: 107.6588\n",
            "Epoch 289/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 82.9371 - mean_absolute_percentage_error: 82.9371 - val_loss: 105.0629 - val_mean_absolute_percentage_error: 105.0629\n",
            "Epoch 290/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 82.9031 - mean_absolute_percentage_error: 82.9031 - val_loss: 106.3090 - val_mean_absolute_percentage_error: 106.3090\n",
            "Epoch 291/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 83.6820 - mean_absolute_percentage_error: 83.6820 - val_loss: 107.0213 - val_mean_absolute_percentage_error: 107.0213\n",
            "Epoch 292/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 83.6172 - mean_absolute_percentage_error: 83.6172 - val_loss: 105.0193 - val_mean_absolute_percentage_error: 105.0193\n",
            "Epoch 293/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 83.1015 - mean_absolute_percentage_error: 83.1015 - val_loss: 106.0338 - val_mean_absolute_percentage_error: 106.0338\n",
            "Epoch 294/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 82.8313 - mean_absolute_percentage_error: 82.8313 - val_loss: 106.1093 - val_mean_absolute_percentage_error: 106.1093\n",
            "Epoch 295/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 83.0725 - mean_absolute_percentage_error: 83.0725 - val_loss: 104.2371 - val_mean_absolute_percentage_error: 104.2371\n",
            "Epoch 296/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 83.1036 - mean_absolute_percentage_error: 83.1036 - val_loss: 106.7638 - val_mean_absolute_percentage_error: 106.7638\n",
            "Epoch 297/1000\n",
            "66/66 [==============================] - 1s 13ms/step - loss: 83.2518 - mean_absolute_percentage_error: 83.2518 - val_loss: 105.5818 - val_mean_absolute_percentage_error: 105.5818\n",
            "Epoch 298/1000\n",
            "66/66 [==============================] - 1s 13ms/step - loss: 82.6074 - mean_absolute_percentage_error: 82.6074 - val_loss: 106.8531 - val_mean_absolute_percentage_error: 106.8531\n",
            "Epoch 299/1000\n",
            "66/66 [==============================] - 1s 13ms/step - loss: 82.5943 - mean_absolute_percentage_error: 82.5943 - val_loss: 103.4411 - val_mean_absolute_percentage_error: 103.4411\n",
            "Epoch 300/1000\n",
            "66/66 [==============================] - 1s 14ms/step - loss: 81.9397 - mean_absolute_percentage_error: 81.9397 - val_loss: 105.9031 - val_mean_absolute_percentage_error: 105.9031\n",
            "Epoch 301/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 82.4987 - mean_absolute_percentage_error: 82.4987 - val_loss: 110.4939 - val_mean_absolute_percentage_error: 110.4939\n",
            "Epoch 302/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 83.5751 - mean_absolute_percentage_error: 83.5751 - val_loss: 104.8681 - val_mean_absolute_percentage_error: 104.8681\n",
            "Epoch 303/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 83.4553 - mean_absolute_percentage_error: 83.4553 - val_loss: 105.7597 - val_mean_absolute_percentage_error: 105.7597\n",
            "Epoch 304/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 82.8238 - mean_absolute_percentage_error: 82.8238 - val_loss: 104.7742 - val_mean_absolute_percentage_error: 104.7742\n",
            "Epoch 305/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 82.5911 - mean_absolute_percentage_error: 82.5911 - val_loss: 107.5924 - val_mean_absolute_percentage_error: 107.5924\n",
            "Epoch 306/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 83.3298 - mean_absolute_percentage_error: 83.3298 - val_loss: 107.4256 - val_mean_absolute_percentage_error: 107.4256\n",
            "Epoch 307/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 82.5677 - mean_absolute_percentage_error: 82.5677 - val_loss: 104.4330 - val_mean_absolute_percentage_error: 104.4330\n",
            "Epoch 308/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 82.7181 - mean_absolute_percentage_error: 82.7181 - val_loss: 106.7695 - val_mean_absolute_percentage_error: 106.7695\n",
            "Epoch 309/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 81.8024 - mean_absolute_percentage_error: 81.8024 - val_loss: 105.8650 - val_mean_absolute_percentage_error: 105.8650\n",
            "Epoch 310/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 82.2152 - mean_absolute_percentage_error: 82.2152 - val_loss: 106.7532 - val_mean_absolute_percentage_error: 106.7532\n",
            "Epoch 311/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 82.2319 - mean_absolute_percentage_error: 82.2319 - val_loss: 104.8289 - val_mean_absolute_percentage_error: 104.8289\n",
            "Epoch 312/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 83.3269 - mean_absolute_percentage_error: 83.3269 - val_loss: 103.5250 - val_mean_absolute_percentage_error: 103.5250\n",
            "Epoch 313/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 84.7870 - mean_absolute_percentage_error: 84.7870 - val_loss: 104.4387 - val_mean_absolute_percentage_error: 104.4387\n",
            "Epoch 314/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 84.4870 - mean_absolute_percentage_error: 84.4870 - val_loss: 105.3086 - val_mean_absolute_percentage_error: 105.3086\n",
            "Epoch 315/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 83.7456 - mean_absolute_percentage_error: 83.7456 - val_loss: 108.1535 - val_mean_absolute_percentage_error: 108.1535\n",
            "Epoch 316/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 82.6044 - mean_absolute_percentage_error: 82.6044 - val_loss: 104.3890 - val_mean_absolute_percentage_error: 104.3890\n",
            "Epoch 317/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 82.1210 - mean_absolute_percentage_error: 82.1210 - val_loss: 104.9712 - val_mean_absolute_percentage_error: 104.9712\n",
            "Epoch 318/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 83.0812 - mean_absolute_percentage_error: 83.0812 - val_loss: 105.6984 - val_mean_absolute_percentage_error: 105.6984\n",
            "Epoch 319/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 82.4917 - mean_absolute_percentage_error: 82.4917 - val_loss: 107.8628 - val_mean_absolute_percentage_error: 107.8628\n",
            "Epoch 320/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 82.9721 - mean_absolute_percentage_error: 82.9721 - val_loss: 105.8111 - val_mean_absolute_percentage_error: 105.8111\n",
            "Epoch 321/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 82.9066 - mean_absolute_percentage_error: 82.9066 - val_loss: 105.7602 - val_mean_absolute_percentage_error: 105.7602\n",
            "Epoch 322/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 82.5006 - mean_absolute_percentage_error: 82.5006 - val_loss: 106.8784 - val_mean_absolute_percentage_error: 106.8784\n",
            "Epoch 323/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 83.1581 - mean_absolute_percentage_error: 83.1581 - val_loss: 104.5507 - val_mean_absolute_percentage_error: 104.5507\n",
            "Epoch 324/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 82.7872 - mean_absolute_percentage_error: 82.7872 - val_loss: 102.6678 - val_mean_absolute_percentage_error: 102.6678\n",
            "Epoch 325/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 83.2128 - mean_absolute_percentage_error: 83.2128 - val_loss: 108.1091 - val_mean_absolute_percentage_error: 108.1091\n",
            "Epoch 326/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 81.8610 - mean_absolute_percentage_error: 81.8610 - val_loss: 106.4128 - val_mean_absolute_percentage_error: 106.4128\n",
            "Epoch 327/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 82.7405 - mean_absolute_percentage_error: 82.7405 - val_loss: 111.2977 - val_mean_absolute_percentage_error: 111.2977\n",
            "Epoch 328/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 83.5261 - mean_absolute_percentage_error: 83.5261 - val_loss: 107.8146 - val_mean_absolute_percentage_error: 107.8146\n",
            "Epoch 329/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 83.4828 - mean_absolute_percentage_error: 83.4828 - val_loss: 106.5904 - val_mean_absolute_percentage_error: 106.5904\n",
            "Epoch 330/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 81.9399 - mean_absolute_percentage_error: 81.9399 - val_loss: 105.0883 - val_mean_absolute_percentage_error: 105.0883\n",
            "Epoch 331/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 82.1701 - mean_absolute_percentage_error: 82.1701 - val_loss: 108.2087 - val_mean_absolute_percentage_error: 108.2087\n",
            "Epoch 332/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 81.4844 - mean_absolute_percentage_error: 81.4844 - val_loss: 106.3110 - val_mean_absolute_percentage_error: 106.3110\n",
            "Epoch 333/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 82.2909 - mean_absolute_percentage_error: 82.2909 - val_loss: 108.0171 - val_mean_absolute_percentage_error: 108.0171\n",
            "Epoch 334/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 81.3700 - mean_absolute_percentage_error: 81.3700 - val_loss: 104.0568 - val_mean_absolute_percentage_error: 104.0568\n",
            "Epoch 335/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 81.8596 - mean_absolute_percentage_error: 81.8596 - val_loss: 107.7524 - val_mean_absolute_percentage_error: 107.7524\n",
            "Epoch 336/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 81.4528 - mean_absolute_percentage_error: 81.4528 - val_loss: 105.3739 - val_mean_absolute_percentage_error: 105.3739\n",
            "Epoch 337/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 82.1937 - mean_absolute_percentage_error: 82.1937 - val_loss: 110.1357 - val_mean_absolute_percentage_error: 110.1357\n",
            "Epoch 338/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 83.0518 - mean_absolute_percentage_error: 83.0518 - val_loss: 105.3976 - val_mean_absolute_percentage_error: 105.3976\n",
            "Epoch 339/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 82.3544 - mean_absolute_percentage_error: 82.3544 - val_loss: 106.2350 - val_mean_absolute_percentage_error: 106.2350\n",
            "Epoch 340/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 82.5877 - mean_absolute_percentage_error: 82.5877 - val_loss: 105.4313 - val_mean_absolute_percentage_error: 105.4313\n",
            "Epoch 341/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 81.9256 - mean_absolute_percentage_error: 81.9256 - val_loss: 110.7012 - val_mean_absolute_percentage_error: 110.7012\n",
            "Epoch 342/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 82.0223 - mean_absolute_percentage_error: 82.0223 - val_loss: 107.2247 - val_mean_absolute_percentage_error: 107.2247\n",
            "Epoch 343/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 81.8084 - mean_absolute_percentage_error: 81.8084 - val_loss: 105.2585 - val_mean_absolute_percentage_error: 105.2585\n",
            "Epoch 344/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 81.7437 - mean_absolute_percentage_error: 81.7437 - val_loss: 106.5424 - val_mean_absolute_percentage_error: 106.5424\n",
            "Epoch 345/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 81.6923 - mean_absolute_percentage_error: 81.6923 - val_loss: 107.9159 - val_mean_absolute_percentage_error: 107.9159\n",
            "Epoch 346/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 82.3150 - mean_absolute_percentage_error: 82.3150 - val_loss: 107.2318 - val_mean_absolute_percentage_error: 107.2318\n",
            "Epoch 347/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 81.6567 - mean_absolute_percentage_error: 81.6567 - val_loss: 106.3952 - val_mean_absolute_percentage_error: 106.3952\n",
            "Epoch 348/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 81.9767 - mean_absolute_percentage_error: 81.9767 - val_loss: 104.8495 - val_mean_absolute_percentage_error: 104.8495\n",
            "Epoch 349/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 81.9675 - mean_absolute_percentage_error: 81.9675 - val_loss: 108.6955 - val_mean_absolute_percentage_error: 108.6955\n",
            "Epoch 350/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 81.7147 - mean_absolute_percentage_error: 81.7147 - val_loss: 108.1042 - val_mean_absolute_percentage_error: 108.1042\n",
            "Epoch 351/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 81.7144 - mean_absolute_percentage_error: 81.7144 - val_loss: 107.4835 - val_mean_absolute_percentage_error: 107.4835\n",
            "Epoch 352/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 82.0569 - mean_absolute_percentage_error: 82.0569 - val_loss: 106.6407 - val_mean_absolute_percentage_error: 106.6407\n",
            "Epoch 353/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 82.0719 - mean_absolute_percentage_error: 82.0719 - val_loss: 107.3360 - val_mean_absolute_percentage_error: 107.3360\n",
            "Epoch 354/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 81.8861 - mean_absolute_percentage_error: 81.8861 - val_loss: 108.7656 - val_mean_absolute_percentage_error: 108.7656\n",
            "Epoch 355/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 81.2878 - mean_absolute_percentage_error: 81.2878 - val_loss: 109.4228 - val_mean_absolute_percentage_error: 109.4228\n",
            "Epoch 356/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 82.1413 - mean_absolute_percentage_error: 82.1413 - val_loss: 106.8751 - val_mean_absolute_percentage_error: 106.8751\n",
            "Epoch 357/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 81.1727 - mean_absolute_percentage_error: 81.1727 - val_loss: 108.6815 - val_mean_absolute_percentage_error: 108.6815\n",
            "Epoch 358/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 81.5668 - mean_absolute_percentage_error: 81.5668 - val_loss: 108.4891 - val_mean_absolute_percentage_error: 108.4891\n",
            "Epoch 359/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 81.9052 - mean_absolute_percentage_error: 81.9052 - val_loss: 108.0824 - val_mean_absolute_percentage_error: 108.0824\n",
            "Epoch 360/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 81.9036 - mean_absolute_percentage_error: 81.9036 - val_loss: 104.9111 - val_mean_absolute_percentage_error: 104.9111\n",
            "Epoch 361/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 82.8730 - mean_absolute_percentage_error: 82.8730 - val_loss: 110.6950 - val_mean_absolute_percentage_error: 110.6950\n",
            "Epoch 362/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 82.1788 - mean_absolute_percentage_error: 82.1788 - val_loss: 105.7286 - val_mean_absolute_percentage_error: 105.7286\n",
            "Epoch 363/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 81.9301 - mean_absolute_percentage_error: 81.9301 - val_loss: 109.3189 - val_mean_absolute_percentage_error: 109.3189\n",
            "Epoch 364/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 81.7755 - mean_absolute_percentage_error: 81.7755 - val_loss: 109.5722 - val_mean_absolute_percentage_error: 109.5722\n",
            "Epoch 365/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 81.7567 - mean_absolute_percentage_error: 81.7567 - val_loss: 104.8933 - val_mean_absolute_percentage_error: 104.8933\n",
            "Epoch 366/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 81.8818 - mean_absolute_percentage_error: 81.8818 - val_loss: 107.8170 - val_mean_absolute_percentage_error: 107.8170\n",
            "Epoch 367/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 81.2385 - mean_absolute_percentage_error: 81.2385 - val_loss: 109.8960 - val_mean_absolute_percentage_error: 109.8960\n",
            "Epoch 368/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 81.1255 - mean_absolute_percentage_error: 81.1255 - val_loss: 108.4728 - val_mean_absolute_percentage_error: 108.4728\n",
            "Epoch 369/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 81.1645 - mean_absolute_percentage_error: 81.1645 - val_loss: 107.7722 - val_mean_absolute_percentage_error: 107.7722\n",
            "Epoch 370/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 81.2375 - mean_absolute_percentage_error: 81.2375 - val_loss: 107.0685 - val_mean_absolute_percentage_error: 107.0685\n",
            "Epoch 371/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 81.4629 - mean_absolute_percentage_error: 81.4629 - val_loss: 108.6625 - val_mean_absolute_percentage_error: 108.6625\n",
            "Epoch 372/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 81.3489 - mean_absolute_percentage_error: 81.3489 - val_loss: 107.3853 - val_mean_absolute_percentage_error: 107.3853\n",
            "Epoch 373/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 80.8127 - mean_absolute_percentage_error: 80.8127 - val_loss: 109.1339 - val_mean_absolute_percentage_error: 109.1339\n",
            "Epoch 374/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 80.8549 - mean_absolute_percentage_error: 80.8549 - val_loss: 108.9082 - val_mean_absolute_percentage_error: 108.9082\n",
            "Epoch 375/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 81.1910 - mean_absolute_percentage_error: 81.1910 - val_loss: 110.3963 - val_mean_absolute_percentage_error: 110.3963\n",
            "Epoch 376/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 81.1803 - mean_absolute_percentage_error: 81.1803 - val_loss: 109.7075 - val_mean_absolute_percentage_error: 109.7075\n",
            "Epoch 377/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 82.6603 - mean_absolute_percentage_error: 82.6603 - val_loss: 105.3335 - val_mean_absolute_percentage_error: 105.3335\n",
            "Epoch 378/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 82.6087 - mean_absolute_percentage_error: 82.6087 - val_loss: 107.6790 - val_mean_absolute_percentage_error: 107.6790\n",
            "Epoch 379/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 82.7232 - mean_absolute_percentage_error: 82.7232 - val_loss: 108.9251 - val_mean_absolute_percentage_error: 108.9251\n",
            "Epoch 380/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 82.5039 - mean_absolute_percentage_error: 82.5039 - val_loss: 107.6058 - val_mean_absolute_percentage_error: 107.6058\n",
            "Epoch 381/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 81.3332 - mean_absolute_percentage_error: 81.3332 - val_loss: 108.1259 - val_mean_absolute_percentage_error: 108.1259\n",
            "Epoch 382/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 81.0243 - mean_absolute_percentage_error: 81.0243 - val_loss: 108.7545 - val_mean_absolute_percentage_error: 108.7545\n",
            "Epoch 383/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 81.8997 - mean_absolute_percentage_error: 81.8997 - val_loss: 110.1914 - val_mean_absolute_percentage_error: 110.1914\n",
            "Epoch 384/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 81.6830 - mean_absolute_percentage_error: 81.6830 - val_loss: 109.8719 - val_mean_absolute_percentage_error: 109.8719\n",
            "Epoch 385/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 80.8282 - mean_absolute_percentage_error: 80.8282 - val_loss: 107.6696 - val_mean_absolute_percentage_error: 107.6696\n",
            "Epoch 386/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 80.8774 - mean_absolute_percentage_error: 80.8774 - val_loss: 107.5178 - val_mean_absolute_percentage_error: 107.5178\n",
            "Epoch 387/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 81.0725 - mean_absolute_percentage_error: 81.0725 - val_loss: 107.4000 - val_mean_absolute_percentage_error: 107.4000\n",
            "Epoch 388/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 81.8026 - mean_absolute_percentage_error: 81.8026 - val_loss: 108.6123 - val_mean_absolute_percentage_error: 108.6123\n",
            "Epoch 389/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 80.9554 - mean_absolute_percentage_error: 80.9554 - val_loss: 107.1807 - val_mean_absolute_percentage_error: 107.1807\n",
            "Epoch 390/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 81.2645 - mean_absolute_percentage_error: 81.2645 - val_loss: 107.3715 - val_mean_absolute_percentage_error: 107.3715\n",
            "Epoch 391/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 81.5656 - mean_absolute_percentage_error: 81.5656 - val_loss: 107.2915 - val_mean_absolute_percentage_error: 107.2915\n",
            "Epoch 392/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 81.5301 - mean_absolute_percentage_error: 81.5301 - val_loss: 103.8268 - val_mean_absolute_percentage_error: 103.8268\n",
            "Epoch 393/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 81.6064 - mean_absolute_percentage_error: 81.6064 - val_loss: 107.3591 - val_mean_absolute_percentage_error: 107.3591\n",
            "Epoch 394/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 81.0599 - mean_absolute_percentage_error: 81.0599 - val_loss: 110.3883 - val_mean_absolute_percentage_error: 110.3883\n",
            "Epoch 395/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 80.5969 - mean_absolute_percentage_error: 80.5969 - val_loss: 106.6398 - val_mean_absolute_percentage_error: 106.6398\n",
            "Epoch 396/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 80.8079 - mean_absolute_percentage_error: 80.8079 - val_loss: 109.0048 - val_mean_absolute_percentage_error: 109.0048\n",
            "Epoch 397/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 80.3836 - mean_absolute_percentage_error: 80.3836 - val_loss: 108.3784 - val_mean_absolute_percentage_error: 108.3784\n",
            "Epoch 398/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 81.8099 - mean_absolute_percentage_error: 81.8099 - val_loss: 110.4861 - val_mean_absolute_percentage_error: 110.4861\n",
            "Epoch 399/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 83.0308 - mean_absolute_percentage_error: 83.0308 - val_loss: 108.8529 - val_mean_absolute_percentage_error: 108.8529\n",
            "Epoch 400/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 80.9754 - mean_absolute_percentage_error: 80.9754 - val_loss: 108.1327 - val_mean_absolute_percentage_error: 108.1327\n",
            "Epoch 401/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 80.6543 - mean_absolute_percentage_error: 80.6543 - val_loss: 110.3003 - val_mean_absolute_percentage_error: 110.3003\n",
            "Epoch 402/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 80.9885 - mean_absolute_percentage_error: 80.9885 - val_loss: 108.5150 - val_mean_absolute_percentage_error: 108.5150\n",
            "Epoch 403/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 80.4735 - mean_absolute_percentage_error: 80.4735 - val_loss: 110.6653 - val_mean_absolute_percentage_error: 110.6653\n",
            "Epoch 404/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 81.1222 - mean_absolute_percentage_error: 81.1222 - val_loss: 110.5563 - val_mean_absolute_percentage_error: 110.5563\n",
            "Epoch 405/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 80.9245 - mean_absolute_percentage_error: 80.9245 - val_loss: 108.4766 - val_mean_absolute_percentage_error: 108.4766\n",
            "Epoch 406/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 81.0566 - mean_absolute_percentage_error: 81.0566 - val_loss: 109.5728 - val_mean_absolute_percentage_error: 109.5728\n",
            "Epoch 407/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 80.2486 - mean_absolute_percentage_error: 80.2486 - val_loss: 108.9109 - val_mean_absolute_percentage_error: 108.9109\n",
            "Epoch 408/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 80.8785 - mean_absolute_percentage_error: 80.8785 - val_loss: 113.0803 - val_mean_absolute_percentage_error: 113.0803\n",
            "Epoch 409/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 80.1868 - mean_absolute_percentage_error: 80.1868 - val_loss: 109.6604 - val_mean_absolute_percentage_error: 109.6604\n",
            "Epoch 410/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 81.2200 - mean_absolute_percentage_error: 81.2200 - val_loss: 109.4254 - val_mean_absolute_percentage_error: 109.4254\n",
            "Epoch 411/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 81.5544 - mean_absolute_percentage_error: 81.5544 - val_loss: 106.0561 - val_mean_absolute_percentage_error: 106.0561\n",
            "Epoch 412/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 81.1230 - mean_absolute_percentage_error: 81.1230 - val_loss: 109.5031 - val_mean_absolute_percentage_error: 109.5031\n",
            "Epoch 413/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 79.9881 - mean_absolute_percentage_error: 79.9881 - val_loss: 112.4745 - val_mean_absolute_percentage_error: 112.4745\n",
            "Epoch 414/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 80.2549 - mean_absolute_percentage_error: 80.2549 - val_loss: 109.6065 - val_mean_absolute_percentage_error: 109.6065\n",
            "Epoch 415/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 80.6689 - mean_absolute_percentage_error: 80.6689 - val_loss: 110.1934 - val_mean_absolute_percentage_error: 110.1934\n",
            "Epoch 416/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 80.5706 - mean_absolute_percentage_error: 80.5706 - val_loss: 110.1751 - val_mean_absolute_percentage_error: 110.1751\n",
            "Epoch 417/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 81.5643 - mean_absolute_percentage_error: 81.5643 - val_loss: 109.0701 - val_mean_absolute_percentage_error: 109.0701\n",
            "Epoch 418/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 80.9927 - mean_absolute_percentage_error: 80.9927 - val_loss: 109.5699 - val_mean_absolute_percentage_error: 109.5699\n",
            "Epoch 419/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 79.8891 - mean_absolute_percentage_error: 79.8891 - val_loss: 107.4477 - val_mean_absolute_percentage_error: 107.4477\n",
            "Epoch 420/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 80.3657 - mean_absolute_percentage_error: 80.3657 - val_loss: 107.3357 - val_mean_absolute_percentage_error: 107.3357\n",
            "Epoch 421/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 80.2201 - mean_absolute_percentage_error: 80.2201 - val_loss: 108.8735 - val_mean_absolute_percentage_error: 108.8735\n",
            "Epoch 422/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 80.0695 - mean_absolute_percentage_error: 80.0695 - val_loss: 109.8753 - val_mean_absolute_percentage_error: 109.8753\n",
            "Epoch 423/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 80.1212 - mean_absolute_percentage_error: 80.1212 - val_loss: 110.0778 - val_mean_absolute_percentage_error: 110.0778\n",
            "Epoch 424/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 79.8224 - mean_absolute_percentage_error: 79.8224 - val_loss: 108.1712 - val_mean_absolute_percentage_error: 108.1712\n",
            "Epoch 425/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 80.6035 - mean_absolute_percentage_error: 80.6035 - val_loss: 110.3743 - val_mean_absolute_percentage_error: 110.3743\n",
            "Epoch 426/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 80.2203 - mean_absolute_percentage_error: 80.2203 - val_loss: 111.0540 - val_mean_absolute_percentage_error: 111.0540\n",
            "Epoch 427/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 80.5226 - mean_absolute_percentage_error: 80.5226 - val_loss: 108.9739 - val_mean_absolute_percentage_error: 108.9739\n",
            "Epoch 428/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 81.1514 - mean_absolute_percentage_error: 81.1514 - val_loss: 109.9104 - val_mean_absolute_percentage_error: 109.9104\n",
            "Epoch 429/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 80.4733 - mean_absolute_percentage_error: 80.4733 - val_loss: 112.5964 - val_mean_absolute_percentage_error: 112.5964\n",
            "Epoch 430/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 81.2371 - mean_absolute_percentage_error: 81.2371 - val_loss: 109.6809 - val_mean_absolute_percentage_error: 109.6809\n",
            "Epoch 431/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 80.0169 - mean_absolute_percentage_error: 80.0169 - val_loss: 109.6528 - val_mean_absolute_percentage_error: 109.6528\n",
            "Epoch 432/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 80.2568 - mean_absolute_percentage_error: 80.2568 - val_loss: 112.8672 - val_mean_absolute_percentage_error: 112.8672\n",
            "Epoch 433/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 79.8030 - mean_absolute_percentage_error: 79.8030 - val_loss: 111.4763 - val_mean_absolute_percentage_error: 111.4763\n",
            "Epoch 434/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 79.9074 - mean_absolute_percentage_error: 79.9074 - val_loss: 108.9838 - val_mean_absolute_percentage_error: 108.9838\n",
            "Epoch 435/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 80.2549 - mean_absolute_percentage_error: 80.2549 - val_loss: 109.8179 - val_mean_absolute_percentage_error: 109.8179\n",
            "Epoch 436/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 80.4594 - mean_absolute_percentage_error: 80.4594 - val_loss: 110.3776 - val_mean_absolute_percentage_error: 110.3776\n",
            "Epoch 437/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 79.8857 - mean_absolute_percentage_error: 79.8857 - val_loss: 109.7070 - val_mean_absolute_percentage_error: 109.7070\n",
            "Epoch 438/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 79.8063 - mean_absolute_percentage_error: 79.8063 - val_loss: 111.1759 - val_mean_absolute_percentage_error: 111.1759\n",
            "Epoch 439/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 79.6763 - mean_absolute_percentage_error: 79.6763 - val_loss: 110.6801 - val_mean_absolute_percentage_error: 110.6801\n",
            "Epoch 440/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 80.3596 - mean_absolute_percentage_error: 80.3596 - val_loss: 112.1383 - val_mean_absolute_percentage_error: 112.1383\n",
            "Epoch 441/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 79.5720 - mean_absolute_percentage_error: 79.5720 - val_loss: 110.0038 - val_mean_absolute_percentage_error: 110.0038\n",
            "Epoch 442/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 80.0268 - mean_absolute_percentage_error: 80.0268 - val_loss: 108.2426 - val_mean_absolute_percentage_error: 108.2426\n",
            "Epoch 443/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 80.0526 - mean_absolute_percentage_error: 80.0526 - val_loss: 110.8992 - val_mean_absolute_percentage_error: 110.8992\n",
            "Epoch 444/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 80.7957 - mean_absolute_percentage_error: 80.7957 - val_loss: 112.9163 - val_mean_absolute_percentage_error: 112.9163\n",
            "Epoch 445/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 80.2917 - mean_absolute_percentage_error: 80.2917 - val_loss: 111.2272 - val_mean_absolute_percentage_error: 111.2272\n",
            "Epoch 446/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 79.5343 - mean_absolute_percentage_error: 79.5343 - val_loss: 114.4639 - val_mean_absolute_percentage_error: 114.4639\n",
            "Epoch 447/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 80.1778 - mean_absolute_percentage_error: 80.1778 - val_loss: 110.5293 - val_mean_absolute_percentage_error: 110.5293\n",
            "Epoch 448/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 80.6399 - mean_absolute_percentage_error: 80.6399 - val_loss: 111.1994 - val_mean_absolute_percentage_error: 111.1994\n",
            "Epoch 449/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 80.4950 - mean_absolute_percentage_error: 80.4950 - val_loss: 109.3468 - val_mean_absolute_percentage_error: 109.3468\n",
            "Epoch 450/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 79.2391 - mean_absolute_percentage_error: 79.2391 - val_loss: 113.0692 - val_mean_absolute_percentage_error: 113.0692\n",
            "Epoch 451/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 80.9310 - mean_absolute_percentage_error: 80.9310 - val_loss: 109.2082 - val_mean_absolute_percentage_error: 109.2082\n",
            "Epoch 452/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 79.4502 - mean_absolute_percentage_error: 79.4502 - val_loss: 111.6795 - val_mean_absolute_percentage_error: 111.6795\n",
            "Epoch 453/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 80.3562 - mean_absolute_percentage_error: 80.3562 - val_loss: 110.1236 - val_mean_absolute_percentage_error: 110.1236\n",
            "Epoch 454/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 80.2750 - mean_absolute_percentage_error: 80.2750 - val_loss: 108.0952 - val_mean_absolute_percentage_error: 108.0952\n",
            "Epoch 455/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 80.0527 - mean_absolute_percentage_error: 80.0527 - val_loss: 111.8952 - val_mean_absolute_percentage_error: 111.8952\n",
            "Epoch 456/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 79.3049 - mean_absolute_percentage_error: 79.3049 - val_loss: 110.8370 - val_mean_absolute_percentage_error: 110.8370\n",
            "Epoch 457/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 79.8634 - mean_absolute_percentage_error: 79.8634 - val_loss: 109.6795 - val_mean_absolute_percentage_error: 109.6795\n",
            "Epoch 458/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 79.9789 - mean_absolute_percentage_error: 79.9789 - val_loss: 110.7971 - val_mean_absolute_percentage_error: 110.7971\n",
            "Epoch 459/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 80.6435 - mean_absolute_percentage_error: 80.6435 - val_loss: 110.7492 - val_mean_absolute_percentage_error: 110.7492\n",
            "Epoch 460/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 80.1432 - mean_absolute_percentage_error: 80.1432 - val_loss: 107.6247 - val_mean_absolute_percentage_error: 107.6247\n",
            "Epoch 461/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 79.7760 - mean_absolute_percentage_error: 79.7760 - val_loss: 110.8836 - val_mean_absolute_percentage_error: 110.8836\n",
            "Epoch 462/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 79.6116 - mean_absolute_percentage_error: 79.6116 - val_loss: 113.7735 - val_mean_absolute_percentage_error: 113.7735\n",
            "Epoch 463/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 81.8820 - mean_absolute_percentage_error: 81.8820 - val_loss: 110.4916 - val_mean_absolute_percentage_error: 110.4916\n",
            "Epoch 464/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 80.4068 - mean_absolute_percentage_error: 80.4068 - val_loss: 107.5710 - val_mean_absolute_percentage_error: 107.5710\n",
            "Epoch 465/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 80.9322 - mean_absolute_percentage_error: 80.9322 - val_loss: 112.2501 - val_mean_absolute_percentage_error: 112.2501\n",
            "Epoch 466/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 79.6317 - mean_absolute_percentage_error: 79.6317 - val_loss: 111.3478 - val_mean_absolute_percentage_error: 111.3478\n",
            "Epoch 467/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 79.4527 - mean_absolute_percentage_error: 79.4527 - val_loss: 116.7220 - val_mean_absolute_percentage_error: 116.7220\n",
            "Epoch 468/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 80.0491 - mean_absolute_percentage_error: 80.0491 - val_loss: 114.0129 - val_mean_absolute_percentage_error: 114.0129\n",
            "Epoch 469/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 79.8912 - mean_absolute_percentage_error: 79.8912 - val_loss: 109.7359 - val_mean_absolute_percentage_error: 109.7359\n",
            "Epoch 470/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 79.0550 - mean_absolute_percentage_error: 79.0550 - val_loss: 111.6029 - val_mean_absolute_percentage_error: 111.6029\n",
            "Epoch 471/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 79.2706 - mean_absolute_percentage_error: 79.2706 - val_loss: 114.7948 - val_mean_absolute_percentage_error: 114.7948\n",
            "Epoch 472/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 83.3026 - mean_absolute_percentage_error: 83.3026 - val_loss: 113.0652 - val_mean_absolute_percentage_error: 113.0652\n",
            "Epoch 473/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 80.5764 - mean_absolute_percentage_error: 80.5764 - val_loss: 109.2376 - val_mean_absolute_percentage_error: 109.2376\n",
            "Epoch 474/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 79.4816 - mean_absolute_percentage_error: 79.4816 - val_loss: 109.9723 - val_mean_absolute_percentage_error: 109.9723\n",
            "Epoch 475/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 80.1541 - mean_absolute_percentage_error: 80.1541 - val_loss: 115.7708 - val_mean_absolute_percentage_error: 115.7708\n",
            "Epoch 476/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 79.7270 - mean_absolute_percentage_error: 79.7270 - val_loss: 108.9869 - val_mean_absolute_percentage_error: 108.9869\n",
            "Epoch 477/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 79.4428 - mean_absolute_percentage_error: 79.4428 - val_loss: 113.8479 - val_mean_absolute_percentage_error: 113.8479\n",
            "Epoch 478/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 80.3597 - mean_absolute_percentage_error: 80.3597 - val_loss: 110.8892 - val_mean_absolute_percentage_error: 110.8892\n",
            "Epoch 479/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 79.2369 - mean_absolute_percentage_error: 79.2369 - val_loss: 110.7808 - val_mean_absolute_percentage_error: 110.7808\n",
            "Epoch 480/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 87.4798 - mean_absolute_percentage_error: 87.4798 - val_loss: 109.4569 - val_mean_absolute_percentage_error: 109.4569\n",
            "Epoch 481/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 80.8915 - mean_absolute_percentage_error: 80.8915 - val_loss: 111.6735 - val_mean_absolute_percentage_error: 111.6735\n",
            "Epoch 482/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 79.8375 - mean_absolute_percentage_error: 79.8375 - val_loss: 114.6551 - val_mean_absolute_percentage_error: 114.6551\n",
            "Epoch 483/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 78.9757 - mean_absolute_percentage_error: 78.9757 - val_loss: 107.7215 - val_mean_absolute_percentage_error: 107.7215\n",
            "Epoch 484/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 78.9374 - mean_absolute_percentage_error: 78.9374 - val_loss: 115.1199 - val_mean_absolute_percentage_error: 115.1199\n",
            "Epoch 485/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 79.6351 - mean_absolute_percentage_error: 79.6351 - val_loss: 112.5711 - val_mean_absolute_percentage_error: 112.5711\n",
            "Epoch 486/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 79.7609 - mean_absolute_percentage_error: 79.7609 - val_loss: 109.0941 - val_mean_absolute_percentage_error: 109.0941\n",
            "Epoch 487/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 79.8044 - mean_absolute_percentage_error: 79.8044 - val_loss: 115.8395 - val_mean_absolute_percentage_error: 115.8395\n",
            "Epoch 488/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 80.5446 - mean_absolute_percentage_error: 80.5446 - val_loss: 112.4106 - val_mean_absolute_percentage_error: 112.4106\n",
            "Epoch 489/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 79.4699 - mean_absolute_percentage_error: 79.4699 - val_loss: 114.1799 - val_mean_absolute_percentage_error: 114.1799\n",
            "Epoch 490/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 80.6033 - mean_absolute_percentage_error: 80.6033 - val_loss: 110.3254 - val_mean_absolute_percentage_error: 110.3254\n",
            "Epoch 491/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 80.6230 - mean_absolute_percentage_error: 80.6230 - val_loss: 109.2676 - val_mean_absolute_percentage_error: 109.2676\n",
            "Epoch 492/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 80.0035 - mean_absolute_percentage_error: 80.0035 - val_loss: 110.2241 - val_mean_absolute_percentage_error: 110.2241\n",
            "Epoch 493/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 80.0570 - mean_absolute_percentage_error: 80.0570 - val_loss: 109.9803 - val_mean_absolute_percentage_error: 109.9803\n",
            "Epoch 494/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 78.6328 - mean_absolute_percentage_error: 78.6328 - val_loss: 115.3208 - val_mean_absolute_percentage_error: 115.3208\n",
            "Epoch 495/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 80.1490 - mean_absolute_percentage_error: 80.1490 - val_loss: 112.4802 - val_mean_absolute_percentage_error: 112.4802\n",
            "Epoch 496/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 78.1628 - mean_absolute_percentage_error: 78.1628 - val_loss: 112.5984 - val_mean_absolute_percentage_error: 112.5984\n",
            "Epoch 497/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 79.0737 - mean_absolute_percentage_error: 79.0737 - val_loss: 111.6854 - val_mean_absolute_percentage_error: 111.6854\n",
            "Epoch 498/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 78.3900 - mean_absolute_percentage_error: 78.3900 - val_loss: 113.2362 - val_mean_absolute_percentage_error: 113.2362\n",
            "Epoch 499/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 78.4469 - mean_absolute_percentage_error: 78.4469 - val_loss: 116.7454 - val_mean_absolute_percentage_error: 116.7454\n",
            "Epoch 500/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 79.5693 - mean_absolute_percentage_error: 79.5693 - val_loss: 113.9218 - val_mean_absolute_percentage_error: 113.9218\n",
            "Epoch 501/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 79.0767 - mean_absolute_percentage_error: 79.0767 - val_loss: 112.6818 - val_mean_absolute_percentage_error: 112.6818\n",
            "Epoch 502/1000\n",
            "66/66 [==============================] - 1s 15ms/step - loss: 78.7417 - mean_absolute_percentage_error: 78.7417 - val_loss: 113.5299 - val_mean_absolute_percentage_error: 113.5299\n",
            "Epoch 503/1000\n",
            "66/66 [==============================] - 1s 14ms/step - loss: 78.2594 - mean_absolute_percentage_error: 78.2594 - val_loss: 112.2432 - val_mean_absolute_percentage_error: 112.2432\n",
            "Epoch 504/1000\n",
            "66/66 [==============================] - 1s 13ms/step - loss: 78.2562 - mean_absolute_percentage_error: 78.2562 - val_loss: 113.6463 - val_mean_absolute_percentage_error: 113.6463\n",
            "Epoch 505/1000\n",
            "66/66 [==============================] - 1s 14ms/step - loss: 77.9874 - mean_absolute_percentage_error: 77.9874 - val_loss: 113.9713 - val_mean_absolute_percentage_error: 113.9713\n",
            "Epoch 506/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 79.3861 - mean_absolute_percentage_error: 79.3861 - val_loss: 115.0369 - val_mean_absolute_percentage_error: 115.0369\n",
            "Epoch 507/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 79.6940 - mean_absolute_percentage_error: 79.6940 - val_loss: 113.1306 - val_mean_absolute_percentage_error: 113.1306\n",
            "Epoch 508/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 78.7692 - mean_absolute_percentage_error: 78.7692 - val_loss: 114.8480 - val_mean_absolute_percentage_error: 114.8480\n",
            "Epoch 509/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 78.2844 - mean_absolute_percentage_error: 78.2844 - val_loss: 114.6127 - val_mean_absolute_percentage_error: 114.6127\n",
            "Epoch 510/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 79.8174 - mean_absolute_percentage_error: 79.8174 - val_loss: 110.2864 - val_mean_absolute_percentage_error: 110.2864\n",
            "Epoch 511/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 77.8154 - mean_absolute_percentage_error: 77.8154 - val_loss: 116.1401 - val_mean_absolute_percentage_error: 116.1401\n",
            "Epoch 512/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 79.4213 - mean_absolute_percentage_error: 79.4213 - val_loss: 113.0674 - val_mean_absolute_percentage_error: 113.0674\n",
            "Epoch 513/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 78.3392 - mean_absolute_percentage_error: 78.3392 - val_loss: 112.9369 - val_mean_absolute_percentage_error: 112.9369\n",
            "Epoch 514/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 79.1756 - mean_absolute_percentage_error: 79.1756 - val_loss: 113.5275 - val_mean_absolute_percentage_error: 113.5275\n",
            "Epoch 515/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 80.7757 - mean_absolute_percentage_error: 80.7757 - val_loss: 116.1226 - val_mean_absolute_percentage_error: 116.1226\n",
            "Epoch 516/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 79.8478 - mean_absolute_percentage_error: 79.8478 - val_loss: 112.9722 - val_mean_absolute_percentage_error: 112.9722\n",
            "Epoch 517/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 78.5246 - mean_absolute_percentage_error: 78.5246 - val_loss: 110.6895 - val_mean_absolute_percentage_error: 110.6895\n",
            "Epoch 518/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 79.0069 - mean_absolute_percentage_error: 79.0069 - val_loss: 111.4664 - val_mean_absolute_percentage_error: 111.4664\n",
            "Epoch 519/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 80.0046 - mean_absolute_percentage_error: 80.0046 - val_loss: 116.0913 - val_mean_absolute_percentage_error: 116.0913\n",
            "Epoch 520/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 79.1253 - mean_absolute_percentage_error: 79.1253 - val_loss: 113.6251 - val_mean_absolute_percentage_error: 113.6251\n",
            "Epoch 521/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 77.6264 - mean_absolute_percentage_error: 77.6264 - val_loss: 113.5783 - val_mean_absolute_percentage_error: 113.5783\n",
            "Epoch 522/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 78.0931 - mean_absolute_percentage_error: 78.0931 - val_loss: 115.2255 - val_mean_absolute_percentage_error: 115.2255\n",
            "Epoch 523/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 79.7326 - mean_absolute_percentage_error: 79.7326 - val_loss: 114.1162 - val_mean_absolute_percentage_error: 114.1162\n",
            "Epoch 524/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 79.8397 - mean_absolute_percentage_error: 79.8397 - val_loss: 115.0454 - val_mean_absolute_percentage_error: 115.0454\n",
            "Epoch 525/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 78.0372 - mean_absolute_percentage_error: 78.0372 - val_loss: 114.8251 - val_mean_absolute_percentage_error: 114.8251\n",
            "Epoch 526/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 77.3688 - mean_absolute_percentage_error: 77.3688 - val_loss: 116.9518 - val_mean_absolute_percentage_error: 116.9518\n",
            "Epoch 527/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 78.6855 - mean_absolute_percentage_error: 78.6855 - val_loss: 115.9965 - val_mean_absolute_percentage_error: 115.9965\n",
            "Epoch 528/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 77.5988 - mean_absolute_percentage_error: 77.5988 - val_loss: 116.7082 - val_mean_absolute_percentage_error: 116.7082\n",
            "Epoch 529/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 77.0040 - mean_absolute_percentage_error: 77.0040 - val_loss: 117.7023 - val_mean_absolute_percentage_error: 117.7023\n",
            "Epoch 530/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 78.1854 - mean_absolute_percentage_error: 78.1854 - val_loss: 113.2382 - val_mean_absolute_percentage_error: 113.2382\n",
            "Epoch 531/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 78.2915 - mean_absolute_percentage_error: 78.2915 - val_loss: 119.3432 - val_mean_absolute_percentage_error: 119.3432\n",
            "Epoch 532/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 78.2662 - mean_absolute_percentage_error: 78.2662 - val_loss: 116.3575 - val_mean_absolute_percentage_error: 116.3575\n",
            "Epoch 533/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 78.6846 - mean_absolute_percentage_error: 78.6846 - val_loss: 117.5044 - val_mean_absolute_percentage_error: 117.5044\n",
            "Epoch 534/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 84.0666 - mean_absolute_percentage_error: 84.0666 - val_loss: 117.0695 - val_mean_absolute_percentage_error: 117.0695\n",
            "Epoch 535/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 77.5914 - mean_absolute_percentage_error: 77.5914 - val_loss: 115.9792 - val_mean_absolute_percentage_error: 115.9792\n",
            "Epoch 536/1000\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 77.4634 - mean_absolute_percentage_error: 77.4634 - val_loss: 117.8065 - val_mean_absolute_percentage_error: 117.8065\n",
            "Epoch 537/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 77.7474 - mean_absolute_percentage_error: 77.7474 - val_loss: 119.6899 - val_mean_absolute_percentage_error: 119.6899\n",
            "Epoch 538/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 77.8121 - mean_absolute_percentage_error: 77.8121 - val_loss: 115.5382 - val_mean_absolute_percentage_error: 115.5382\n",
            "Epoch 539/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 77.0309 - mean_absolute_percentage_error: 77.0309 - val_loss: 116.8779 - val_mean_absolute_percentage_error: 116.8779\n",
            "Epoch 540/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 79.7566 - mean_absolute_percentage_error: 79.7566 - val_loss: 116.5827 - val_mean_absolute_percentage_error: 116.5827\n",
            "Epoch 541/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 78.0249 - mean_absolute_percentage_error: 78.0249 - val_loss: 117.9576 - val_mean_absolute_percentage_error: 117.9576\n",
            "Epoch 542/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 76.9444 - mean_absolute_percentage_error: 76.9444 - val_loss: 117.4649 - val_mean_absolute_percentage_error: 117.4649\n",
            "Epoch 543/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 77.2719 - mean_absolute_percentage_error: 77.2719 - val_loss: 121.9860 - val_mean_absolute_percentage_error: 121.9860\n",
            "Epoch 544/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 79.4633 - mean_absolute_percentage_error: 79.4633 - val_loss: 114.1230 - val_mean_absolute_percentage_error: 114.1230\n",
            "Epoch 545/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 77.9685 - mean_absolute_percentage_error: 77.9685 - val_loss: 121.4884 - val_mean_absolute_percentage_error: 121.4884\n",
            "Epoch 546/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 77.3447 - mean_absolute_percentage_error: 77.3447 - val_loss: 116.9902 - val_mean_absolute_percentage_error: 116.9902\n",
            "Epoch 547/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 77.7026 - mean_absolute_percentage_error: 77.7026 - val_loss: 119.1507 - val_mean_absolute_percentage_error: 119.1507\n",
            "Epoch 548/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 76.1264 - mean_absolute_percentage_error: 76.1264 - val_loss: 120.9473 - val_mean_absolute_percentage_error: 120.9473\n",
            "Epoch 549/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 77.7679 - mean_absolute_percentage_error: 77.7679 - val_loss: 116.9522 - val_mean_absolute_percentage_error: 116.9522\n",
            "Epoch 550/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 76.5826 - mean_absolute_percentage_error: 76.5826 - val_loss: 119.8893 - val_mean_absolute_percentage_error: 119.8893\n",
            "Epoch 551/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 76.7583 - mean_absolute_percentage_error: 76.7583 - val_loss: 116.7035 - val_mean_absolute_percentage_error: 116.7035\n",
            "Epoch 552/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 76.5773 - mean_absolute_percentage_error: 76.5773 - val_loss: 122.4625 - val_mean_absolute_percentage_error: 122.4625\n",
            "Epoch 553/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 81.0214 - mean_absolute_percentage_error: 81.0214 - val_loss: 115.8440 - val_mean_absolute_percentage_error: 115.8440\n",
            "Epoch 554/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 76.1920 - mean_absolute_percentage_error: 76.1920 - val_loss: 119.4171 - val_mean_absolute_percentage_error: 119.4171\n",
            "Epoch 555/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 77.2900 - mean_absolute_percentage_error: 77.2900 - val_loss: 120.2293 - val_mean_absolute_percentage_error: 120.2293\n",
            "Epoch 556/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 77.1686 - mean_absolute_percentage_error: 77.1686 - val_loss: 118.1888 - val_mean_absolute_percentage_error: 118.1888\n",
            "Epoch 557/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 77.6144 - mean_absolute_percentage_error: 77.6144 - val_loss: 122.3384 - val_mean_absolute_percentage_error: 122.3384\n",
            "Epoch 558/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 76.5391 - mean_absolute_percentage_error: 76.5391 - val_loss: 117.2338 - val_mean_absolute_percentage_error: 117.2338\n",
            "Epoch 559/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 77.0305 - mean_absolute_percentage_error: 77.0305 - val_loss: 120.7350 - val_mean_absolute_percentage_error: 120.7350\n",
            "Epoch 560/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 76.5624 - mean_absolute_percentage_error: 76.5624 - val_loss: 118.7267 - val_mean_absolute_percentage_error: 118.7267\n",
            "Epoch 561/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 77.3616 - mean_absolute_percentage_error: 77.3616 - val_loss: 120.9457 - val_mean_absolute_percentage_error: 120.9457\n",
            "Epoch 562/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 75.7663 - mean_absolute_percentage_error: 75.7663 - val_loss: 119.4618 - val_mean_absolute_percentage_error: 119.4618\n",
            "Epoch 563/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 77.1057 - mean_absolute_percentage_error: 77.1057 - val_loss: 121.5988 - val_mean_absolute_percentage_error: 121.5988\n",
            "Epoch 564/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 76.9384 - mean_absolute_percentage_error: 76.9384 - val_loss: 123.0543 - val_mean_absolute_percentage_error: 123.0543\n",
            "Epoch 565/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 75.9536 - mean_absolute_percentage_error: 75.9536 - val_loss: 117.1407 - val_mean_absolute_percentage_error: 117.1407\n",
            "Epoch 566/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 76.1039 - mean_absolute_percentage_error: 76.1039 - val_loss: 120.7584 - val_mean_absolute_percentage_error: 120.7584\n",
            "Epoch 567/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 74.6590 - mean_absolute_percentage_error: 74.6590 - val_loss: 122.4293 - val_mean_absolute_percentage_error: 122.4293\n",
            "Epoch 568/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 75.2627 - mean_absolute_percentage_error: 75.2627 - val_loss: 125.1006 - val_mean_absolute_percentage_error: 125.1006\n",
            "Epoch 569/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 75.8287 - mean_absolute_percentage_error: 75.8287 - val_loss: 120.9063 - val_mean_absolute_percentage_error: 120.9063\n",
            "Epoch 570/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 76.6249 - mean_absolute_percentage_error: 76.6249 - val_loss: 123.7368 - val_mean_absolute_percentage_error: 123.7368\n",
            "Epoch 571/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 74.5214 - mean_absolute_percentage_error: 74.5214 - val_loss: 119.1812 - val_mean_absolute_percentage_error: 119.1812\n",
            "Epoch 572/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 75.3616 - mean_absolute_percentage_error: 75.3616 - val_loss: 129.0109 - val_mean_absolute_percentage_error: 129.0109\n",
            "Epoch 573/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 77.0695 - mean_absolute_percentage_error: 77.0695 - val_loss: 120.3132 - val_mean_absolute_percentage_error: 120.3132\n",
            "Epoch 574/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 76.4285 - mean_absolute_percentage_error: 76.4285 - val_loss: 122.4825 - val_mean_absolute_percentage_error: 122.4825\n",
            "Epoch 575/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 73.9731 - mean_absolute_percentage_error: 73.9731 - val_loss: 127.4932 - val_mean_absolute_percentage_error: 127.4932\n",
            "Epoch 576/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 74.8889 - mean_absolute_percentage_error: 74.8889 - val_loss: 120.7601 - val_mean_absolute_percentage_error: 120.7601\n",
            "Epoch 577/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 75.0928 - mean_absolute_percentage_error: 75.0928 - val_loss: 127.1587 - val_mean_absolute_percentage_error: 127.1587\n",
            "Epoch 578/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 74.7012 - mean_absolute_percentage_error: 74.7012 - val_loss: 124.9468 - val_mean_absolute_percentage_error: 124.9468\n",
            "Epoch 579/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 75.0933 - mean_absolute_percentage_error: 75.0933 - val_loss: 124.7310 - val_mean_absolute_percentage_error: 124.7310\n",
            "Epoch 580/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 75.8018 - mean_absolute_percentage_error: 75.8018 - val_loss: 124.6099 - val_mean_absolute_percentage_error: 124.6099\n",
            "Epoch 581/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 74.2720 - mean_absolute_percentage_error: 74.2720 - val_loss: 124.5602 - val_mean_absolute_percentage_error: 124.5602\n",
            "Epoch 582/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 75.3381 - mean_absolute_percentage_error: 75.3381 - val_loss: 125.9823 - val_mean_absolute_percentage_error: 125.9823\n",
            "Epoch 583/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 73.2047 - mean_absolute_percentage_error: 73.2047 - val_loss: 128.5067 - val_mean_absolute_percentage_error: 128.5067\n",
            "Epoch 584/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 74.7490 - mean_absolute_percentage_error: 74.7490 - val_loss: 127.2338 - val_mean_absolute_percentage_error: 127.2338\n",
            "Epoch 585/1000\n",
            "66/66 [==============================] - 1s 14ms/step - loss: 76.6309 - mean_absolute_percentage_error: 76.6309 - val_loss: 119.4180 - val_mean_absolute_percentage_error: 119.4180\n",
            "Epoch 586/1000\n",
            "66/66 [==============================] - 1s 15ms/step - loss: 75.0755 - mean_absolute_percentage_error: 75.0755 - val_loss: 124.9198 - val_mean_absolute_percentage_error: 124.9198\n",
            "Epoch 587/1000\n",
            "66/66 [==============================] - 1s 14ms/step - loss: 73.9783 - mean_absolute_percentage_error: 73.9783 - val_loss: 124.8408 - val_mean_absolute_percentage_error: 124.8408\n",
            "Epoch 588/1000\n",
            "66/66 [==============================] - 1s 14ms/step - loss: 74.5394 - mean_absolute_percentage_error: 74.5394 - val_loss: 127.8077 - val_mean_absolute_percentage_error: 127.8077\n",
            "Epoch 589/1000\n",
            "66/66 [==============================] - 1s 16ms/step - loss: 73.2592 - mean_absolute_percentage_error: 73.2592 - val_loss: 124.2733 - val_mean_absolute_percentage_error: 124.2733\n",
            "Epoch 590/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 75.6565 - mean_absolute_percentage_error: 75.6565 - val_loss: 125.9716 - val_mean_absolute_percentage_error: 125.9716\n",
            "Epoch 591/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 73.5307 - mean_absolute_percentage_error: 73.5307 - val_loss: 128.6020 - val_mean_absolute_percentage_error: 128.6020\n",
            "Epoch 592/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 74.5583 - mean_absolute_percentage_error: 74.5583 - val_loss: 124.0163 - val_mean_absolute_percentage_error: 124.0163\n",
            "Epoch 593/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 72.3134 - mean_absolute_percentage_error: 72.3134 - val_loss: 128.2576 - val_mean_absolute_percentage_error: 128.2576\n",
            "Epoch 594/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 73.8792 - mean_absolute_percentage_error: 73.8792 - val_loss: 122.3136 - val_mean_absolute_percentage_error: 122.3136\n",
            "Epoch 595/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 72.9464 - mean_absolute_percentage_error: 72.9464 - val_loss: 130.6982 - val_mean_absolute_percentage_error: 130.6982\n",
            "Epoch 596/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 73.7361 - mean_absolute_percentage_error: 73.7361 - val_loss: 131.9210 - val_mean_absolute_percentage_error: 131.9210\n",
            "Epoch 597/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 73.2402 - mean_absolute_percentage_error: 73.2402 - val_loss: 130.5049 - val_mean_absolute_percentage_error: 130.5049\n",
            "Epoch 598/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 72.8170 - mean_absolute_percentage_error: 72.8170 - val_loss: 120.2050 - val_mean_absolute_percentage_error: 120.2050\n",
            "Epoch 599/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 72.9891 - mean_absolute_percentage_error: 72.9891 - val_loss: 125.7729 - val_mean_absolute_percentage_error: 125.7729\n",
            "Epoch 600/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 71.2913 - mean_absolute_percentage_error: 71.2913 - val_loss: 129.2603 - val_mean_absolute_percentage_error: 129.2603\n",
            "Epoch 601/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 72.0048 - mean_absolute_percentage_error: 72.0048 - val_loss: 126.4316 - val_mean_absolute_percentage_error: 126.4316\n",
            "Epoch 602/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 71.6555 - mean_absolute_percentage_error: 71.6555 - val_loss: 128.1774 - val_mean_absolute_percentage_error: 128.1774\n",
            "Epoch 603/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 72.0671 - mean_absolute_percentage_error: 72.0671 - val_loss: 130.2097 - val_mean_absolute_percentage_error: 130.2097\n",
            "Epoch 604/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 70.6999 - mean_absolute_percentage_error: 70.6999 - val_loss: 132.3777 - val_mean_absolute_percentage_error: 132.3777\n",
            "Epoch 605/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 71.4130 - mean_absolute_percentage_error: 71.4130 - val_loss: 129.8520 - val_mean_absolute_percentage_error: 129.8520\n",
            "Epoch 606/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 71.8494 - mean_absolute_percentage_error: 71.8494 - val_loss: 126.0845 - val_mean_absolute_percentage_error: 126.0845\n",
            "Epoch 607/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 72.7423 - mean_absolute_percentage_error: 72.7423 - val_loss: 115.8147 - val_mean_absolute_percentage_error: 115.8147\n",
            "Epoch 608/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 71.6493 - mean_absolute_percentage_error: 71.6493 - val_loss: 131.4932 - val_mean_absolute_percentage_error: 131.4932\n",
            "Epoch 609/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 71.1837 - mean_absolute_percentage_error: 71.1837 - val_loss: 126.6528 - val_mean_absolute_percentage_error: 126.6528\n",
            "Epoch 610/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 71.4687 - mean_absolute_percentage_error: 71.4687 - val_loss: 125.1870 - val_mean_absolute_percentage_error: 125.1870\n",
            "Epoch 611/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 70.5996 - mean_absolute_percentage_error: 70.5996 - val_loss: 127.2291 - val_mean_absolute_percentage_error: 127.2291\n",
            "Epoch 612/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 69.7389 - mean_absolute_percentage_error: 69.7389 - val_loss: 135.4676 - val_mean_absolute_percentage_error: 135.4676\n",
            "Epoch 613/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 70.8352 - mean_absolute_percentage_error: 70.8352 - val_loss: 132.8539 - val_mean_absolute_percentage_error: 132.8539\n",
            "Epoch 614/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 71.1505 - mean_absolute_percentage_error: 71.1505 - val_loss: 134.4653 - val_mean_absolute_percentage_error: 134.4653\n",
            "Epoch 615/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 69.9512 - mean_absolute_percentage_error: 69.9512 - val_loss: 126.6354 - val_mean_absolute_percentage_error: 126.6354\n",
            "Epoch 616/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 71.4347 - mean_absolute_percentage_error: 71.4347 - val_loss: 123.8453 - val_mean_absolute_percentage_error: 123.8453\n",
            "Epoch 617/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 69.2572 - mean_absolute_percentage_error: 69.2572 - val_loss: 123.2711 - val_mean_absolute_percentage_error: 123.2711\n",
            "Epoch 618/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 69.5198 - mean_absolute_percentage_error: 69.5198 - val_loss: 133.6928 - val_mean_absolute_percentage_error: 133.6928\n",
            "Epoch 619/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 69.6784 - mean_absolute_percentage_error: 69.6784 - val_loss: 132.3993 - val_mean_absolute_percentage_error: 132.3993\n",
            "Epoch 620/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 70.1603 - mean_absolute_percentage_error: 70.1603 - val_loss: 134.8515 - val_mean_absolute_percentage_error: 134.8515\n",
            "Epoch 621/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 68.8690 - mean_absolute_percentage_error: 68.8690 - val_loss: 130.1618 - val_mean_absolute_percentage_error: 130.1618\n",
            "Epoch 622/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 67.7330 - mean_absolute_percentage_error: 67.7330 - val_loss: 133.2908 - val_mean_absolute_percentage_error: 133.2908\n",
            "Epoch 623/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 67.3895 - mean_absolute_percentage_error: 67.3895 - val_loss: 132.0267 - val_mean_absolute_percentage_error: 132.0267\n",
            "Epoch 624/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 70.8244 - mean_absolute_percentage_error: 70.8244 - val_loss: 125.6998 - val_mean_absolute_percentage_error: 125.6998\n",
            "Epoch 625/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 69.6562 - mean_absolute_percentage_error: 69.6562 - val_loss: 131.3572 - val_mean_absolute_percentage_error: 131.3572\n",
            "Epoch 626/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 68.2862 - mean_absolute_percentage_error: 68.2862 - val_loss: 128.9709 - val_mean_absolute_percentage_error: 128.9709\n",
            "Epoch 627/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 65.6397 - mean_absolute_percentage_error: 65.6397 - val_loss: 130.9884 - val_mean_absolute_percentage_error: 130.9884\n",
            "Epoch 628/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 67.3555 - mean_absolute_percentage_error: 67.3555 - val_loss: 130.8194 - val_mean_absolute_percentage_error: 130.8194\n",
            "Epoch 629/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 65.7870 - mean_absolute_percentage_error: 65.7870 - val_loss: 139.7301 - val_mean_absolute_percentage_error: 139.7301\n",
            "Epoch 630/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 65.7055 - mean_absolute_percentage_error: 65.7055 - val_loss: 122.1091 - val_mean_absolute_percentage_error: 122.1091\n",
            "Epoch 631/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 65.2289 - mean_absolute_percentage_error: 65.2289 - val_loss: 125.3211 - val_mean_absolute_percentage_error: 125.3211\n",
            "Epoch 632/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 64.6616 - mean_absolute_percentage_error: 64.6616 - val_loss: 130.2386 - val_mean_absolute_percentage_error: 130.2386\n",
            "Epoch 633/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 66.3382 - mean_absolute_percentage_error: 66.3382 - val_loss: 120.7877 - val_mean_absolute_percentage_error: 120.7877\n",
            "Epoch 634/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 96.1563 - mean_absolute_percentage_error: 96.1563 - val_loss: 128.0302 - val_mean_absolute_percentage_error: 128.0302\n",
            "Epoch 635/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 68.4909 - mean_absolute_percentage_error: 68.4909 - val_loss: 126.7052 - val_mean_absolute_percentage_error: 126.7052\n",
            "Epoch 636/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 66.6378 - mean_absolute_percentage_error: 66.6378 - val_loss: 128.0004 - val_mean_absolute_percentage_error: 128.0004\n",
            "Epoch 637/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 66.3614 - mean_absolute_percentage_error: 66.3614 - val_loss: 127.7025 - val_mean_absolute_percentage_error: 127.7025\n",
            "Epoch 638/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 65.4360 - mean_absolute_percentage_error: 65.4360 - val_loss: 120.3691 - val_mean_absolute_percentage_error: 120.3691\n",
            "Epoch 639/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 64.1655 - mean_absolute_percentage_error: 64.1655 - val_loss: 130.5410 - val_mean_absolute_percentage_error: 130.5410\n",
            "Epoch 640/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 64.0529 - mean_absolute_percentage_error: 64.0529 - val_loss: 126.1977 - val_mean_absolute_percentage_error: 126.1977\n",
            "Epoch 641/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 64.2825 - mean_absolute_percentage_error: 64.2825 - val_loss: 124.8451 - val_mean_absolute_percentage_error: 124.8451\n",
            "Epoch 642/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 64.9771 - mean_absolute_percentage_error: 64.9771 - val_loss: 123.2729 - val_mean_absolute_percentage_error: 123.2729\n",
            "Epoch 643/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 63.7279 - mean_absolute_percentage_error: 63.7279 - val_loss: 115.8024 - val_mean_absolute_percentage_error: 115.8024\n",
            "Epoch 644/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 62.7721 - mean_absolute_percentage_error: 62.7721 - val_loss: 120.7391 - val_mean_absolute_percentage_error: 120.7391\n",
            "Epoch 645/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 62.1793 - mean_absolute_percentage_error: 62.1793 - val_loss: 125.3388 - val_mean_absolute_percentage_error: 125.3388\n",
            "Epoch 646/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 62.5026 - mean_absolute_percentage_error: 62.5026 - val_loss: 117.3605 - val_mean_absolute_percentage_error: 117.3605\n",
            "Epoch 647/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 62.7758 - mean_absolute_percentage_error: 62.7758 - val_loss: 123.6889 - val_mean_absolute_percentage_error: 123.6889\n",
            "Epoch 648/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 61.6607 - mean_absolute_percentage_error: 61.6607 - val_loss: 121.8890 - val_mean_absolute_percentage_error: 121.8890\n",
            "Epoch 649/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 61.9220 - mean_absolute_percentage_error: 61.9220 - val_loss: 128.6638 - val_mean_absolute_percentage_error: 128.6638\n",
            "Epoch 650/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 61.4363 - mean_absolute_percentage_error: 61.4363 - val_loss: 119.8290 - val_mean_absolute_percentage_error: 119.8290\n",
            "Epoch 651/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 61.2804 - mean_absolute_percentage_error: 61.2804 - val_loss: 120.5319 - val_mean_absolute_percentage_error: 120.5319\n",
            "Epoch 652/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 60.8560 - mean_absolute_percentage_error: 60.8560 - val_loss: 119.3916 - val_mean_absolute_percentage_error: 119.3916\n",
            "Epoch 653/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 62.0968 - mean_absolute_percentage_error: 62.0968 - val_loss: 120.9701 - val_mean_absolute_percentage_error: 120.9701\n",
            "Epoch 654/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 60.8798 - mean_absolute_percentage_error: 60.8798 - val_loss: 126.0954 - val_mean_absolute_percentage_error: 126.0954\n",
            "Epoch 655/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 63.3087 - mean_absolute_percentage_error: 63.3087 - val_loss: 117.3313 - val_mean_absolute_percentage_error: 117.3313\n",
            "Epoch 656/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 60.7059 - mean_absolute_percentage_error: 60.7059 - val_loss: 118.7362 - val_mean_absolute_percentage_error: 118.7362\n",
            "Epoch 657/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 60.4032 - mean_absolute_percentage_error: 60.4032 - val_loss: 122.5270 - val_mean_absolute_percentage_error: 122.5270\n",
            "Epoch 658/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 60.3105 - mean_absolute_percentage_error: 60.3105 - val_loss: 116.9862 - val_mean_absolute_percentage_error: 116.9862\n",
            "Epoch 659/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 59.7187 - mean_absolute_percentage_error: 59.7187 - val_loss: 122.0158 - val_mean_absolute_percentage_error: 122.0158\n",
            "Epoch 660/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 59.4527 - mean_absolute_percentage_error: 59.4527 - val_loss: 115.7036 - val_mean_absolute_percentage_error: 115.7036\n",
            "Epoch 661/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 60.3189 - mean_absolute_percentage_error: 60.3189 - val_loss: 120.5955 - val_mean_absolute_percentage_error: 120.5955\n",
            "Epoch 662/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 60.4819 - mean_absolute_percentage_error: 60.4819 - val_loss: 123.3155 - val_mean_absolute_percentage_error: 123.3155\n",
            "Epoch 663/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 60.1378 - mean_absolute_percentage_error: 60.1378 - val_loss: 119.8204 - val_mean_absolute_percentage_error: 119.8204\n",
            "Epoch 664/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 59.5665 - mean_absolute_percentage_error: 59.5665 - val_loss: 113.2803 - val_mean_absolute_percentage_error: 113.2803\n",
            "Epoch 665/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 59.8592 - mean_absolute_percentage_error: 59.8592 - val_loss: 118.1221 - val_mean_absolute_percentage_error: 118.1221\n",
            "Epoch 666/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 59.3475 - mean_absolute_percentage_error: 59.3475 - val_loss: 119.7013 - val_mean_absolute_percentage_error: 119.7013\n",
            "Epoch 667/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 58.5021 - mean_absolute_percentage_error: 58.5021 - val_loss: 122.3569 - val_mean_absolute_percentage_error: 122.3569\n",
            "Epoch 668/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 59.5331 - mean_absolute_percentage_error: 59.5331 - val_loss: 121.7408 - val_mean_absolute_percentage_error: 121.7408\n",
            "Epoch 669/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 59.2656 - mean_absolute_percentage_error: 59.2656 - val_loss: 121.5448 - val_mean_absolute_percentage_error: 121.5448\n",
            "Epoch 670/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 60.1314 - mean_absolute_percentage_error: 60.1314 - val_loss: 104.1786 - val_mean_absolute_percentage_error: 104.1786\n",
            "Epoch 671/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 59.5806 - mean_absolute_percentage_error: 59.5806 - val_loss: 115.4148 - val_mean_absolute_percentage_error: 115.4148\n",
            "Epoch 672/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 59.3169 - mean_absolute_percentage_error: 59.3169 - val_loss: 105.0870 - val_mean_absolute_percentage_error: 105.0870\n",
            "Epoch 673/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 61.0835 - mean_absolute_percentage_error: 61.0835 - val_loss: 113.2715 - val_mean_absolute_percentage_error: 113.2715\n",
            "Epoch 674/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 58.7089 - mean_absolute_percentage_error: 58.7089 - val_loss: 116.1859 - val_mean_absolute_percentage_error: 116.1859\n",
            "Epoch 675/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 60.8778 - mean_absolute_percentage_error: 60.8778 - val_loss: 118.1221 - val_mean_absolute_percentage_error: 118.1221\n",
            "Epoch 676/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 59.9340 - mean_absolute_percentage_error: 59.9340 - val_loss: 107.8213 - val_mean_absolute_percentage_error: 107.8213\n",
            "Epoch 677/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 60.8150 - mean_absolute_percentage_error: 60.8150 - val_loss: 121.2128 - val_mean_absolute_percentage_error: 121.2128\n",
            "Epoch 678/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 59.1680 - mean_absolute_percentage_error: 59.1680 - val_loss: 114.6161 - val_mean_absolute_percentage_error: 114.6161\n",
            "Epoch 679/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 59.8529 - mean_absolute_percentage_error: 59.8529 - val_loss: 109.9459 - val_mean_absolute_percentage_error: 109.9459\n",
            "Epoch 680/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 58.1506 - mean_absolute_percentage_error: 58.1506 - val_loss: 119.0001 - val_mean_absolute_percentage_error: 119.0001\n",
            "Epoch 681/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 59.6600 - mean_absolute_percentage_error: 59.6600 - val_loss: 123.1320 - val_mean_absolute_percentage_error: 123.1320\n",
            "Epoch 682/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 58.6265 - mean_absolute_percentage_error: 58.6265 - val_loss: 111.1284 - val_mean_absolute_percentage_error: 111.1284\n",
            "Epoch 683/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 59.5273 - mean_absolute_percentage_error: 59.5273 - val_loss: 118.6139 - val_mean_absolute_percentage_error: 118.6139\n",
            "Epoch 684/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 57.8530 - mean_absolute_percentage_error: 57.8530 - val_loss: 117.4831 - val_mean_absolute_percentage_error: 117.4831\n",
            "Epoch 685/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 59.3996 - mean_absolute_percentage_error: 59.3996 - val_loss: 135.4868 - val_mean_absolute_percentage_error: 135.4868\n",
            "Epoch 686/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 59.5900 - mean_absolute_percentage_error: 59.5900 - val_loss: 116.6221 - val_mean_absolute_percentage_error: 116.6221\n",
            "Epoch 687/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 60.8424 - mean_absolute_percentage_error: 60.8424 - val_loss: 114.9315 - val_mean_absolute_percentage_error: 114.9315\n",
            "Epoch 688/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 57.4562 - mean_absolute_percentage_error: 57.4562 - val_loss: 111.1011 - val_mean_absolute_percentage_error: 111.1011\n",
            "Epoch 689/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 57.3282 - mean_absolute_percentage_error: 57.3282 - val_loss: 118.2557 - val_mean_absolute_percentage_error: 118.2557\n",
            "Epoch 690/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 57.4981 - mean_absolute_percentage_error: 57.4981 - val_loss: 121.2430 - val_mean_absolute_percentage_error: 121.2430\n",
            "Epoch 691/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 57.6319 - mean_absolute_percentage_error: 57.6319 - val_loss: 119.8193 - val_mean_absolute_percentage_error: 119.8193\n",
            "Epoch 692/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 58.0348 - mean_absolute_percentage_error: 58.0348 - val_loss: 117.8550 - val_mean_absolute_percentage_error: 117.8550\n",
            "Epoch 693/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 58.1068 - mean_absolute_percentage_error: 58.1068 - val_loss: 116.4433 - val_mean_absolute_percentage_error: 116.4433\n",
            "Epoch 694/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 56.7495 - mean_absolute_percentage_error: 56.7495 - val_loss: 116.8118 - val_mean_absolute_percentage_error: 116.8118\n",
            "Epoch 695/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 58.0361 - mean_absolute_percentage_error: 58.0361 - val_loss: 117.9214 - val_mean_absolute_percentage_error: 117.9214\n",
            "Epoch 696/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 56.9072 - mean_absolute_percentage_error: 56.9072 - val_loss: 123.9484 - val_mean_absolute_percentage_error: 123.9484\n",
            "Epoch 697/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 58.2031 - mean_absolute_percentage_error: 58.2031 - val_loss: 116.9070 - val_mean_absolute_percentage_error: 116.9070\n",
            "Epoch 698/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 57.6794 - mean_absolute_percentage_error: 57.6794 - val_loss: 118.1016 - val_mean_absolute_percentage_error: 118.1016\n",
            "Epoch 699/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 58.3284 - mean_absolute_percentage_error: 58.3284 - val_loss: 108.8736 - val_mean_absolute_percentage_error: 108.8736\n",
            "Epoch 700/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 57.4410 - mean_absolute_percentage_error: 57.4410 - val_loss: 112.7774 - val_mean_absolute_percentage_error: 112.7774\n",
            "Epoch 701/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 58.4403 - mean_absolute_percentage_error: 58.4403 - val_loss: 117.0513 - val_mean_absolute_percentage_error: 117.0513\n",
            "Epoch 702/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 57.4579 - mean_absolute_percentage_error: 57.4579 - val_loss: 113.6950 - val_mean_absolute_percentage_error: 113.6950\n",
            "Epoch 703/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 56.4127 - mean_absolute_percentage_error: 56.4127 - val_loss: 120.3055 - val_mean_absolute_percentage_error: 120.3055\n",
            "Epoch 704/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 57.4214 - mean_absolute_percentage_error: 57.4214 - val_loss: 118.7576 - val_mean_absolute_percentage_error: 118.7576\n",
            "Epoch 705/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 56.8685 - mean_absolute_percentage_error: 56.8685 - val_loss: 121.3822 - val_mean_absolute_percentage_error: 121.3822\n",
            "Epoch 706/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 57.4165 - mean_absolute_percentage_error: 57.4165 - val_loss: 122.6021 - val_mean_absolute_percentage_error: 122.6021\n",
            "Epoch 707/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 57.4649 - mean_absolute_percentage_error: 57.4649 - val_loss: 116.2429 - val_mean_absolute_percentage_error: 116.2429\n",
            "Epoch 708/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 56.4923 - mean_absolute_percentage_error: 56.4923 - val_loss: 123.3748 - val_mean_absolute_percentage_error: 123.3748\n",
            "Epoch 709/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 56.3911 - mean_absolute_percentage_error: 56.3911 - val_loss: 120.1017 - val_mean_absolute_percentage_error: 120.1017\n",
            "Epoch 710/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 56.2481 - mean_absolute_percentage_error: 56.2481 - val_loss: 129.5370 - val_mean_absolute_percentage_error: 129.5370\n",
            "Epoch 711/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 61.1303 - mean_absolute_percentage_error: 61.1303 - val_loss: 114.0812 - val_mean_absolute_percentage_error: 114.0812\n",
            "Epoch 712/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 56.9198 - mean_absolute_percentage_error: 56.9198 - val_loss: 116.9526 - val_mean_absolute_percentage_error: 116.9526\n",
            "Epoch 713/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 56.2170 - mean_absolute_percentage_error: 56.2170 - val_loss: 119.5480 - val_mean_absolute_percentage_error: 119.5480\n",
            "Epoch 714/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 55.9689 - mean_absolute_percentage_error: 55.9689 - val_loss: 119.5240 - val_mean_absolute_percentage_error: 119.5240\n",
            "Epoch 715/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 57.8094 - mean_absolute_percentage_error: 57.8094 - val_loss: 118.6979 - val_mean_absolute_percentage_error: 118.6979\n",
            "Epoch 716/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 56.3001 - mean_absolute_percentage_error: 56.3001 - val_loss: 120.5717 - val_mean_absolute_percentage_error: 120.5717\n",
            "Epoch 717/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 56.5402 - mean_absolute_percentage_error: 56.5402 - val_loss: 113.5177 - val_mean_absolute_percentage_error: 113.5177\n",
            "Epoch 718/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 56.4749 - mean_absolute_percentage_error: 56.4749 - val_loss: 116.9953 - val_mean_absolute_percentage_error: 116.9953\n",
            "Epoch 719/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 56.5515 - mean_absolute_percentage_error: 56.5515 - val_loss: 120.5014 - val_mean_absolute_percentage_error: 120.5014\n",
            "Epoch 720/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 56.8699 - mean_absolute_percentage_error: 56.8699 - val_loss: 119.4799 - val_mean_absolute_percentage_error: 119.4799\n",
            "Epoch 721/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 56.3281 - mean_absolute_percentage_error: 56.3281 - val_loss: 111.7570 - val_mean_absolute_percentage_error: 111.7570\n",
            "Epoch 722/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 55.3124 - mean_absolute_percentage_error: 55.3124 - val_loss: 124.9892 - val_mean_absolute_percentage_error: 124.9892\n",
            "Epoch 723/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 57.0071 - mean_absolute_percentage_error: 57.0071 - val_loss: 114.9849 - val_mean_absolute_percentage_error: 114.9849\n",
            "Epoch 724/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 60.4937 - mean_absolute_percentage_error: 60.4937 - val_loss: 111.9770 - val_mean_absolute_percentage_error: 111.9770\n",
            "Epoch 725/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 57.7077 - mean_absolute_percentage_error: 57.7077 - val_loss: 115.1383 - val_mean_absolute_percentage_error: 115.1383\n",
            "Epoch 726/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 55.7059 - mean_absolute_percentage_error: 55.7059 - val_loss: 123.0230 - val_mean_absolute_percentage_error: 123.0230\n",
            "Epoch 727/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 57.9497 - mean_absolute_percentage_error: 57.9497 - val_loss: 118.4179 - val_mean_absolute_percentage_error: 118.4179\n",
            "Epoch 728/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 59.6853 - mean_absolute_percentage_error: 59.6853 - val_loss: 105.3227 - val_mean_absolute_percentage_error: 105.3227\n",
            "Epoch 729/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 58.9097 - mean_absolute_percentage_error: 58.9097 - val_loss: 120.2459 - val_mean_absolute_percentage_error: 120.2459\n",
            "Epoch 730/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 57.2424 - mean_absolute_percentage_error: 57.2424 - val_loss: 109.3031 - val_mean_absolute_percentage_error: 109.3031\n",
            "Epoch 731/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 56.2114 - mean_absolute_percentage_error: 56.2114 - val_loss: 118.4370 - val_mean_absolute_percentage_error: 118.4370\n",
            "Epoch 732/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 55.7832 - mean_absolute_percentage_error: 55.7832 - val_loss: 115.5555 - val_mean_absolute_percentage_error: 115.5555\n",
            "Epoch 733/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 56.3039 - mean_absolute_percentage_error: 56.3039 - val_loss: 122.7328 - val_mean_absolute_percentage_error: 122.7328\n",
            "Epoch 734/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 56.6986 - mean_absolute_percentage_error: 56.6986 - val_loss: 112.8323 - val_mean_absolute_percentage_error: 112.8323\n",
            "Epoch 735/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 55.1511 - mean_absolute_percentage_error: 55.1511 - val_loss: 111.6524 - val_mean_absolute_percentage_error: 111.6524\n",
            "Epoch 736/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 56.3471 - mean_absolute_percentage_error: 56.3471 - val_loss: 118.1181 - val_mean_absolute_percentage_error: 118.1181\n",
            "Epoch 737/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 114.0171 - mean_absolute_percentage_error: 114.0171 - val_loss: 108.6148 - val_mean_absolute_percentage_error: 108.6148\n",
            "Epoch 738/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 59.8429 - mean_absolute_percentage_error: 59.8429 - val_loss: 112.0143 - val_mean_absolute_percentage_error: 112.0143\n",
            "Epoch 739/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 56.0424 - mean_absolute_percentage_error: 56.0424 - val_loss: 122.1820 - val_mean_absolute_percentage_error: 122.1820\n",
            "Epoch 740/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 56.1946 - mean_absolute_percentage_error: 56.1946 - val_loss: 119.5886 - val_mean_absolute_percentage_error: 119.5886\n",
            "Epoch 741/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 56.2346 - mean_absolute_percentage_error: 56.2346 - val_loss: 114.4072 - val_mean_absolute_percentage_error: 114.4072\n",
            "Epoch 742/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 56.1065 - mean_absolute_percentage_error: 56.1065 - val_loss: 109.9261 - val_mean_absolute_percentage_error: 109.9261\n",
            "Epoch 743/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 56.4700 - mean_absolute_percentage_error: 56.4700 - val_loss: 115.2090 - val_mean_absolute_percentage_error: 115.2090\n",
            "Epoch 744/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 56.1121 - mean_absolute_percentage_error: 56.1121 - val_loss: 113.7129 - val_mean_absolute_percentage_error: 113.7129\n",
            "Epoch 745/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 56.1244 - mean_absolute_percentage_error: 56.1244 - val_loss: 114.0100 - val_mean_absolute_percentage_error: 114.0100\n",
            "Epoch 746/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 55.0628 - mean_absolute_percentage_error: 55.0628 - val_loss: 123.3982 - val_mean_absolute_percentage_error: 123.3982\n",
            "Epoch 747/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 55.8317 - mean_absolute_percentage_error: 55.8317 - val_loss: 115.7353 - val_mean_absolute_percentage_error: 115.7353\n",
            "Epoch 748/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 55.6787 - mean_absolute_percentage_error: 55.6787 - val_loss: 118.5941 - val_mean_absolute_percentage_error: 118.5941\n",
            "Epoch 749/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 54.7517 - mean_absolute_percentage_error: 54.7517 - val_loss: 115.8003 - val_mean_absolute_percentage_error: 115.8003\n",
            "Epoch 750/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 55.0272 - mean_absolute_percentage_error: 55.0272 - val_loss: 117.4120 - val_mean_absolute_percentage_error: 117.4120\n",
            "Epoch 751/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 54.2598 - mean_absolute_percentage_error: 54.2598 - val_loss: 124.6888 - val_mean_absolute_percentage_error: 124.6888\n",
            "Epoch 752/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 55.3145 - mean_absolute_percentage_error: 55.3145 - val_loss: 118.2719 - val_mean_absolute_percentage_error: 118.2719\n",
            "Epoch 753/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 54.6251 - mean_absolute_percentage_error: 54.6251 - val_loss: 119.4792 - val_mean_absolute_percentage_error: 119.4792\n",
            "Epoch 754/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 59.2934 - mean_absolute_percentage_error: 59.2934 - val_loss: 118.5577 - val_mean_absolute_percentage_error: 118.5577\n",
            "Epoch 755/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 55.8059 - mean_absolute_percentage_error: 55.8059 - val_loss: 117.5440 - val_mean_absolute_percentage_error: 117.5440\n",
            "Epoch 756/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 55.7802 - mean_absolute_percentage_error: 55.7802 - val_loss: 118.7105 - val_mean_absolute_percentage_error: 118.7105\n",
            "Epoch 757/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 55.2331 - mean_absolute_percentage_error: 55.2331 - val_loss: 120.6928 - val_mean_absolute_percentage_error: 120.6928\n",
            "Epoch 758/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 55.2237 - mean_absolute_percentage_error: 55.2237 - val_loss: 113.6245 - val_mean_absolute_percentage_error: 113.6245\n",
            "Epoch 759/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 55.3836 - mean_absolute_percentage_error: 55.3836 - val_loss: 117.6828 - val_mean_absolute_percentage_error: 117.6828\n",
            "Epoch 760/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 55.4695 - mean_absolute_percentage_error: 55.4695 - val_loss: 123.6228 - val_mean_absolute_percentage_error: 123.6228\n",
            "Epoch 761/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 54.8973 - mean_absolute_percentage_error: 54.8973 - val_loss: 117.4431 - val_mean_absolute_percentage_error: 117.4431\n",
            "Epoch 762/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 55.2436 - mean_absolute_percentage_error: 55.2436 - val_loss: 119.0446 - val_mean_absolute_percentage_error: 119.0446\n",
            "Epoch 763/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 55.9184 - mean_absolute_percentage_error: 55.9184 - val_loss: 114.7089 - val_mean_absolute_percentage_error: 114.7089\n",
            "Epoch 764/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 54.4199 - mean_absolute_percentage_error: 54.4199 - val_loss: 122.9790 - val_mean_absolute_percentage_error: 122.9790\n",
            "Epoch 765/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 54.2840 - mean_absolute_percentage_error: 54.2840 - val_loss: 117.5099 - val_mean_absolute_percentage_error: 117.5099\n",
            "Epoch 766/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 54.5949 - mean_absolute_percentage_error: 54.5949 - val_loss: 122.5711 - val_mean_absolute_percentage_error: 122.5711\n",
            "Epoch 767/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 54.3291 - mean_absolute_percentage_error: 54.3291 - val_loss: 111.5463 - val_mean_absolute_percentage_error: 111.5463\n",
            "Epoch 768/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 54.5566 - mean_absolute_percentage_error: 54.5566 - val_loss: 120.9172 - val_mean_absolute_percentage_error: 120.9172\n",
            "Epoch 769/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 56.4542 - mean_absolute_percentage_error: 56.4542 - val_loss: 110.4879 - val_mean_absolute_percentage_error: 110.4879\n",
            "Epoch 770/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 54.1732 - mean_absolute_percentage_error: 54.1732 - val_loss: 115.8159 - val_mean_absolute_percentage_error: 115.8159\n",
            "Epoch 771/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 54.9807 - mean_absolute_percentage_error: 54.9807 - val_loss: 117.1574 - val_mean_absolute_percentage_error: 117.1574\n",
            "Epoch 772/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 56.3708 - mean_absolute_percentage_error: 56.3708 - val_loss: 112.7029 - val_mean_absolute_percentage_error: 112.7029\n",
            "Epoch 773/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 56.1244 - mean_absolute_percentage_error: 56.1244 - val_loss: 117.3600 - val_mean_absolute_percentage_error: 117.3600\n",
            "Epoch 774/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 54.7053 - mean_absolute_percentage_error: 54.7053 - val_loss: 116.4998 - val_mean_absolute_percentage_error: 116.4998\n",
            "Epoch 775/1000\n",
            "66/66 [==============================] - 1s 14ms/step - loss: 54.4861 - mean_absolute_percentage_error: 54.4861 - val_loss: 117.4774 - val_mean_absolute_percentage_error: 117.4774\n",
            "Epoch 776/1000\n",
            "66/66 [==============================] - 1s 15ms/step - loss: 54.1589 - mean_absolute_percentage_error: 54.1589 - val_loss: 124.9102 - val_mean_absolute_percentage_error: 124.9102\n",
            "Epoch 777/1000\n",
            "66/66 [==============================] - 1s 17ms/step - loss: 53.3454 - mean_absolute_percentage_error: 53.3454 - val_loss: 118.5120 - val_mean_absolute_percentage_error: 118.5120\n",
            "Epoch 778/1000\n",
            "66/66 [==============================] - 1s 15ms/step - loss: 55.0989 - mean_absolute_percentage_error: 55.0989 - val_loss: 117.0377 - val_mean_absolute_percentage_error: 117.0377\n",
            "Epoch 779/1000\n",
            "66/66 [==============================] - 1s 14ms/step - loss: 54.7408 - mean_absolute_percentage_error: 54.7408 - val_loss: 114.2352 - val_mean_absolute_percentage_error: 114.2352\n",
            "Epoch 780/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 55.1630 - mean_absolute_percentage_error: 55.1630 - val_loss: 118.8862 - val_mean_absolute_percentage_error: 118.8862\n",
            "Epoch 781/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 55.8376 - mean_absolute_percentage_error: 55.8376 - val_loss: 114.6830 - val_mean_absolute_percentage_error: 114.6830\n",
            "Epoch 782/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 54.6586 - mean_absolute_percentage_error: 54.6586 - val_loss: 111.1962 - val_mean_absolute_percentage_error: 111.1962\n",
            "Epoch 783/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 54.4671 - mean_absolute_percentage_error: 54.4671 - val_loss: 115.3633 - val_mean_absolute_percentage_error: 115.3633\n",
            "Epoch 784/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 53.7005 - mean_absolute_percentage_error: 53.7005 - val_loss: 120.9811 - val_mean_absolute_percentage_error: 120.9811\n",
            "Epoch 785/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 53.3634 - mean_absolute_percentage_error: 53.3634 - val_loss: 120.2896 - val_mean_absolute_percentage_error: 120.2896\n",
            "Epoch 786/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 53.4231 - mean_absolute_percentage_error: 53.4231 - val_loss: 110.2455 - val_mean_absolute_percentage_error: 110.2455\n",
            "Epoch 787/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 54.9861 - mean_absolute_percentage_error: 54.9861 - val_loss: 114.4184 - val_mean_absolute_percentage_error: 114.4184\n",
            "Epoch 788/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 55.2732 - mean_absolute_percentage_error: 55.2732 - val_loss: 113.2877 - val_mean_absolute_percentage_error: 113.2877\n",
            "Epoch 789/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 55.3625 - mean_absolute_percentage_error: 55.3625 - val_loss: 111.9974 - val_mean_absolute_percentage_error: 111.9974\n",
            "Epoch 790/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 53.7705 - mean_absolute_percentage_error: 53.7705 - val_loss: 113.9160 - val_mean_absolute_percentage_error: 113.9160\n",
            "Epoch 791/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 53.7701 - mean_absolute_percentage_error: 53.7701 - val_loss: 118.2459 - val_mean_absolute_percentage_error: 118.2459\n",
            "Epoch 792/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 53.1648 - mean_absolute_percentage_error: 53.1648 - val_loss: 114.0432 - val_mean_absolute_percentage_error: 114.0432\n",
            "Epoch 793/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 53.9508 - mean_absolute_percentage_error: 53.9508 - val_loss: 117.7797 - val_mean_absolute_percentage_error: 117.7797\n",
            "Epoch 794/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 54.6957 - mean_absolute_percentage_error: 54.6957 - val_loss: 117.7354 - val_mean_absolute_percentage_error: 117.7354\n",
            "Epoch 795/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 55.3801 - mean_absolute_percentage_error: 55.3801 - val_loss: 117.7008 - val_mean_absolute_percentage_error: 117.7008\n",
            "Epoch 796/1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 54.9982 - mean_absolute_percentage_error: 54.9982 - val_loss: 123.8163 - val_mean_absolute_percentage_error: 123.8163\n",
            "Epoch 797/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 58.5741 - mean_absolute_percentage_error: 58.5741 - val_loss: 103.1585 - val_mean_absolute_percentage_error: 103.1585\n",
            "Epoch 798/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 53.8966 - mean_absolute_percentage_error: 53.8966 - val_loss: 120.4731 - val_mean_absolute_percentage_error: 120.4731\n",
            "Epoch 799/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 55.2276 - mean_absolute_percentage_error: 55.2276 - val_loss: 106.7740 - val_mean_absolute_percentage_error: 106.7740\n",
            "Epoch 800/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 54.3335 - mean_absolute_percentage_error: 54.3335 - val_loss: 115.3385 - val_mean_absolute_percentage_error: 115.3385\n",
            "Epoch 801/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 53.7883 - mean_absolute_percentage_error: 53.7883 - val_loss: 114.2822 - val_mean_absolute_percentage_error: 114.2822\n",
            "Epoch 802/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 58.2538 - mean_absolute_percentage_error: 58.2538 - val_loss: 103.0200 - val_mean_absolute_percentage_error: 103.0200\n",
            "Epoch 803/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 55.3181 - mean_absolute_percentage_error: 55.3181 - val_loss: 111.6037 - val_mean_absolute_percentage_error: 111.6037\n",
            "Epoch 804/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 52.1550 - mean_absolute_percentage_error: 52.1550 - val_loss: 125.8086 - val_mean_absolute_percentage_error: 125.8086\n",
            "Epoch 805/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 57.4497 - mean_absolute_percentage_error: 57.4497 - val_loss: 112.9141 - val_mean_absolute_percentage_error: 112.9141\n",
            "Epoch 806/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 53.6494 - mean_absolute_percentage_error: 53.6494 - val_loss: 114.0443 - val_mean_absolute_percentage_error: 114.0443\n",
            "Epoch 807/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 54.4334 - mean_absolute_percentage_error: 54.4334 - val_loss: 121.3589 - val_mean_absolute_percentage_error: 121.3589\n",
            "Epoch 808/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 54.0057 - mean_absolute_percentage_error: 54.0057 - val_loss: 121.8155 - val_mean_absolute_percentage_error: 121.8155\n",
            "Epoch 809/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 59.8171 - mean_absolute_percentage_error: 59.8171 - val_loss: 107.4188 - val_mean_absolute_percentage_error: 107.4188\n",
            "Epoch 810/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 54.8137 - mean_absolute_percentage_error: 54.8137 - val_loss: 107.9616 - val_mean_absolute_percentage_error: 107.9616\n",
            "Epoch 811/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 55.6929 - mean_absolute_percentage_error: 55.6929 - val_loss: 108.8479 - val_mean_absolute_percentage_error: 108.8479\n",
            "Epoch 812/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 52.7476 - mean_absolute_percentage_error: 52.7476 - val_loss: 113.8020 - val_mean_absolute_percentage_error: 113.8020\n",
            "Epoch 813/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 52.8329 - mean_absolute_percentage_error: 52.8329 - val_loss: 111.3003 - val_mean_absolute_percentage_error: 111.3003\n",
            "Epoch 814/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 52.5792 - mean_absolute_percentage_error: 52.5792 - val_loss: 122.4383 - val_mean_absolute_percentage_error: 122.4383\n",
            "Epoch 815/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 52.9132 - mean_absolute_percentage_error: 52.9132 - val_loss: 113.3240 - val_mean_absolute_percentage_error: 113.3240\n",
            "Epoch 816/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 53.7468 - mean_absolute_percentage_error: 53.7468 - val_loss: 110.3050 - val_mean_absolute_percentage_error: 110.3050\n",
            "Epoch 817/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 53.1641 - mean_absolute_percentage_error: 53.1641 - val_loss: 111.9221 - val_mean_absolute_percentage_error: 111.9221\n",
            "Epoch 818/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 52.5644 - mean_absolute_percentage_error: 52.5644 - val_loss: 116.4307 - val_mean_absolute_percentage_error: 116.4307\n",
            "Epoch 819/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 53.4033 - mean_absolute_percentage_error: 53.4033 - val_loss: 111.9631 - val_mean_absolute_percentage_error: 111.9631\n",
            "Epoch 820/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 52.3429 - mean_absolute_percentage_error: 52.3429 - val_loss: 118.0257 - val_mean_absolute_percentage_error: 118.0257\n",
            "Epoch 821/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 52.5357 - mean_absolute_percentage_error: 52.5357 - val_loss: 118.0945 - val_mean_absolute_percentage_error: 118.0945\n",
            "Epoch 822/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 52.4807 - mean_absolute_percentage_error: 52.4807 - val_loss: 117.2963 - val_mean_absolute_percentage_error: 117.2963\n",
            "Epoch 823/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 53.3075 - mean_absolute_percentage_error: 53.3075 - val_loss: 110.7195 - val_mean_absolute_percentage_error: 110.7195\n",
            "Epoch 824/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 53.3780 - mean_absolute_percentage_error: 53.3780 - val_loss: 114.3369 - val_mean_absolute_percentage_error: 114.3369\n",
            "Epoch 825/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 53.3618 - mean_absolute_percentage_error: 53.3618 - val_loss: 117.6018 - val_mean_absolute_percentage_error: 117.6018\n",
            "Epoch 826/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 52.4106 - mean_absolute_percentage_error: 52.4106 - val_loss: 118.3643 - val_mean_absolute_percentage_error: 118.3643\n",
            "Epoch 827/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 52.8935 - mean_absolute_percentage_error: 52.8935 - val_loss: 114.5384 - val_mean_absolute_percentage_error: 114.5384\n",
            "Epoch 828/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 52.3525 - mean_absolute_percentage_error: 52.3525 - val_loss: 119.1976 - val_mean_absolute_percentage_error: 119.1976\n",
            "Epoch 829/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 53.0850 - mean_absolute_percentage_error: 53.0850 - val_loss: 115.7481 - val_mean_absolute_percentage_error: 115.7481\n",
            "Epoch 830/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 51.9156 - mean_absolute_percentage_error: 51.9156 - val_loss: 121.9057 - val_mean_absolute_percentage_error: 121.9057\n",
            "Epoch 831/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 52.1019 - mean_absolute_percentage_error: 52.1019 - val_loss: 119.0979 - val_mean_absolute_percentage_error: 119.0979\n",
            "Epoch 832/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 51.7729 - mean_absolute_percentage_error: 51.7729 - val_loss: 116.6926 - val_mean_absolute_percentage_error: 116.6926\n",
            "Epoch 833/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 52.3908 - mean_absolute_percentage_error: 52.3908 - val_loss: 118.5623 - val_mean_absolute_percentage_error: 118.5623\n",
            "Epoch 834/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 51.3824 - mean_absolute_percentage_error: 51.3824 - val_loss: 117.9390 - val_mean_absolute_percentage_error: 117.9390\n",
            "Epoch 835/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 51.6277 - mean_absolute_percentage_error: 51.6277 - val_loss: 112.8396 - val_mean_absolute_percentage_error: 112.8396\n",
            "Epoch 836/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 51.3920 - mean_absolute_percentage_error: 51.3920 - val_loss: 117.5292 - val_mean_absolute_percentage_error: 117.5292\n",
            "Epoch 837/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 52.8191 - mean_absolute_percentage_error: 52.8191 - val_loss: 107.2118 - val_mean_absolute_percentage_error: 107.2118\n",
            "Epoch 838/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 52.3275 - mean_absolute_percentage_error: 52.3275 - val_loss: 114.5960 - val_mean_absolute_percentage_error: 114.5960\n",
            "Epoch 839/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 52.0797 - mean_absolute_percentage_error: 52.0797 - val_loss: 116.3081 - val_mean_absolute_percentage_error: 116.3081\n",
            "Epoch 840/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 53.6250 - mean_absolute_percentage_error: 53.6250 - val_loss: 105.2217 - val_mean_absolute_percentage_error: 105.2217\n",
            "Epoch 841/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 51.6464 - mean_absolute_percentage_error: 51.6464 - val_loss: 112.7211 - val_mean_absolute_percentage_error: 112.7211\n",
            "Epoch 842/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 51.7388 - mean_absolute_percentage_error: 51.7388 - val_loss: 119.9721 - val_mean_absolute_percentage_error: 119.9721\n",
            "Epoch 843/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 55.1488 - mean_absolute_percentage_error: 55.1488 - val_loss: 117.1404 - val_mean_absolute_percentage_error: 117.1404\n",
            "Epoch 844/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 58.1651 - mean_absolute_percentage_error: 58.1651 - val_loss: 110.4338 - val_mean_absolute_percentage_error: 110.4338\n",
            "Epoch 845/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 61.1605 - mean_absolute_percentage_error: 61.1605 - val_loss: 120.4256 - val_mean_absolute_percentage_error: 120.4256\n",
            "Epoch 846/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 58.7934 - mean_absolute_percentage_error: 58.7934 - val_loss: 106.2941 - val_mean_absolute_percentage_error: 106.2941\n",
            "Epoch 847/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 54.9823 - mean_absolute_percentage_error: 54.9823 - val_loss: 117.1812 - val_mean_absolute_percentage_error: 117.1812\n",
            "Epoch 848/1000\n",
            "66/66 [==============================] - 1s 14ms/step - loss: 53.2313 - mean_absolute_percentage_error: 53.2313 - val_loss: 113.8062 - val_mean_absolute_percentage_error: 113.8062\n",
            "Epoch 849/1000\n",
            "66/66 [==============================] - 1s 15ms/step - loss: 54.6390 - mean_absolute_percentage_error: 54.6390 - val_loss: 116.1604 - val_mean_absolute_percentage_error: 116.1604\n",
            "Epoch 850/1000\n",
            "66/66 [==============================] - 1s 16ms/step - loss: 52.6793 - mean_absolute_percentage_error: 52.6793 - val_loss: 112.7845 - val_mean_absolute_percentage_error: 112.7845\n",
            "Epoch 851/1000\n",
            "66/66 [==============================] - 1s 14ms/step - loss: 52.5370 - mean_absolute_percentage_error: 52.5370 - val_loss: 108.5932 - val_mean_absolute_percentage_error: 108.5932\n",
            "Epoch 852/1000\n",
            "66/66 [==============================] - 1s 15ms/step - loss: 51.6418 - mean_absolute_percentage_error: 51.6418 - val_loss: 113.5332 - val_mean_absolute_percentage_error: 113.5332\n",
            "Epoch 853/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 52.5017 - mean_absolute_percentage_error: 52.5017 - val_loss: 103.8050 - val_mean_absolute_percentage_error: 103.8050\n",
            "Epoch 854/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 51.9432 - mean_absolute_percentage_error: 51.9432 - val_loss: 111.6611 - val_mean_absolute_percentage_error: 111.6611\n",
            "Epoch 855/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 50.8788 - mean_absolute_percentage_error: 50.8788 - val_loss: 116.1266 - val_mean_absolute_percentage_error: 116.1266\n",
            "Epoch 856/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 51.3965 - mean_absolute_percentage_error: 51.3965 - val_loss: 118.0832 - val_mean_absolute_percentage_error: 118.0832\n",
            "Epoch 857/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 50.4673 - mean_absolute_percentage_error: 50.4673 - val_loss: 116.1427 - val_mean_absolute_percentage_error: 116.1427\n",
            "Epoch 858/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 50.3326 - mean_absolute_percentage_error: 50.3326 - val_loss: 113.8906 - val_mean_absolute_percentage_error: 113.8906\n",
            "Epoch 859/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 52.1946 - mean_absolute_percentage_error: 52.1946 - val_loss: 121.1340 - val_mean_absolute_percentage_error: 121.1340\n",
            "Epoch 860/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 49.9423 - mean_absolute_percentage_error: 49.9423 - val_loss: 114.0399 - val_mean_absolute_percentage_error: 114.0399\n",
            "Epoch 861/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 50.6044 - mean_absolute_percentage_error: 50.6044 - val_loss: 121.9904 - val_mean_absolute_percentage_error: 121.9904\n",
            "Epoch 862/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 51.9142 - mean_absolute_percentage_error: 51.9142 - val_loss: 113.6261 - val_mean_absolute_percentage_error: 113.6261\n",
            "Epoch 863/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 50.7051 - mean_absolute_percentage_error: 50.7051 - val_loss: 117.4468 - val_mean_absolute_percentage_error: 117.4468\n",
            "Epoch 864/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 54.6275 - mean_absolute_percentage_error: 54.6275 - val_loss: 107.5309 - val_mean_absolute_percentage_error: 107.5309\n",
            "Epoch 865/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 51.5931 - mean_absolute_percentage_error: 51.5931 - val_loss: 123.1195 - val_mean_absolute_percentage_error: 123.1195\n",
            "Epoch 866/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 57.3017 - mean_absolute_percentage_error: 57.3017 - val_loss: 110.8443 - val_mean_absolute_percentage_error: 110.8443\n",
            "Epoch 867/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 51.3765 - mean_absolute_percentage_error: 51.3765 - val_loss: 110.4121 - val_mean_absolute_percentage_error: 110.4121\n",
            "Epoch 868/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 50.6065 - mean_absolute_percentage_error: 50.6065 - val_loss: 107.1465 - val_mean_absolute_percentage_error: 107.1465\n",
            "Epoch 869/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 50.1977 - mean_absolute_percentage_error: 50.1977 - val_loss: 115.2742 - val_mean_absolute_percentage_error: 115.2742\n",
            "Epoch 870/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 50.5552 - mean_absolute_percentage_error: 50.5552 - val_loss: 108.2947 - val_mean_absolute_percentage_error: 108.2947\n",
            "Epoch 871/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 51.2361 - mean_absolute_percentage_error: 51.2361 - val_loss: 110.0794 - val_mean_absolute_percentage_error: 110.0794\n",
            "Epoch 872/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 50.9123 - mean_absolute_percentage_error: 50.9123 - val_loss: 118.6675 - val_mean_absolute_percentage_error: 118.6675\n",
            "Epoch 873/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 50.2672 - mean_absolute_percentage_error: 50.2672 - val_loss: 112.9471 - val_mean_absolute_percentage_error: 112.9471\n",
            "Epoch 874/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 50.7050 - mean_absolute_percentage_error: 50.7050 - val_loss: 110.1409 - val_mean_absolute_percentage_error: 110.1409\n",
            "Epoch 875/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 51.5543 - mean_absolute_percentage_error: 51.5543 - val_loss: 108.6210 - val_mean_absolute_percentage_error: 108.6210\n",
            "Epoch 876/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 51.3642 - mean_absolute_percentage_error: 51.3642 - val_loss: 116.0827 - val_mean_absolute_percentage_error: 116.0827\n",
            "Epoch 877/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 48.9680 - mean_absolute_percentage_error: 48.9680 - val_loss: 112.5766 - val_mean_absolute_percentage_error: 112.5766\n",
            "Epoch 878/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 50.0240 - mean_absolute_percentage_error: 50.0240 - val_loss: 110.9279 - val_mean_absolute_percentage_error: 110.9279\n",
            "Epoch 879/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 50.2582 - mean_absolute_percentage_error: 50.2582 - val_loss: 112.2400 - val_mean_absolute_percentage_error: 112.2400\n",
            "Epoch 880/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 49.6039 - mean_absolute_percentage_error: 49.6039 - val_loss: 111.4750 - val_mean_absolute_percentage_error: 111.4750\n",
            "Epoch 881/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 49.6596 - mean_absolute_percentage_error: 49.6596 - val_loss: 119.7084 - val_mean_absolute_percentage_error: 119.7084\n",
            "Epoch 882/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 49.2674 - mean_absolute_percentage_error: 49.2674 - val_loss: 103.8435 - val_mean_absolute_percentage_error: 103.8435\n",
            "Epoch 883/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 50.8034 - mean_absolute_percentage_error: 50.8034 - val_loss: 107.6394 - val_mean_absolute_percentage_error: 107.6394\n",
            "Epoch 884/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 52.6483 - mean_absolute_percentage_error: 52.6483 - val_loss: 101.7949 - val_mean_absolute_percentage_error: 101.7949\n",
            "Epoch 885/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 52.3679 - mean_absolute_percentage_error: 52.3679 - val_loss: 115.1554 - val_mean_absolute_percentage_error: 115.1554\n",
            "Epoch 886/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 53.3582 - mean_absolute_percentage_error: 53.3582 - val_loss: 109.2340 - val_mean_absolute_percentage_error: 109.2340\n",
            "Epoch 887/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 51.9669 - mean_absolute_percentage_error: 51.9669 - val_loss: 113.6082 - val_mean_absolute_percentage_error: 113.6082\n",
            "Epoch 888/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 50.8336 - mean_absolute_percentage_error: 50.8336 - val_loss: 110.4146 - val_mean_absolute_percentage_error: 110.4146\n",
            "Epoch 889/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 50.6648 - mean_absolute_percentage_error: 50.6648 - val_loss: 108.5256 - val_mean_absolute_percentage_error: 108.5256\n",
            "Epoch 890/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 49.5764 - mean_absolute_percentage_error: 49.5764 - val_loss: 115.1224 - val_mean_absolute_percentage_error: 115.1224\n",
            "Epoch 891/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 50.0767 - mean_absolute_percentage_error: 50.0767 - val_loss: 110.0459 - val_mean_absolute_percentage_error: 110.0459\n",
            "Epoch 892/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 49.4849 - mean_absolute_percentage_error: 49.4849 - val_loss: 115.0114 - val_mean_absolute_percentage_error: 115.0114\n",
            "Epoch 893/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 51.3441 - mean_absolute_percentage_error: 51.3441 - val_loss: 106.5414 - val_mean_absolute_percentage_error: 106.5414\n",
            "Epoch 894/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 48.2760 - mean_absolute_percentage_error: 48.2760 - val_loss: 114.1628 - val_mean_absolute_percentage_error: 114.1628\n",
            "Epoch 895/1000\n",
            "66/66 [==============================] - 1s 13ms/step - loss: 50.0593 - mean_absolute_percentage_error: 50.0593 - val_loss: 104.3458 - val_mean_absolute_percentage_error: 104.3458\n",
            "Epoch 896/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 49.6076 - mean_absolute_percentage_error: 49.6076 - val_loss: 123.9398 - val_mean_absolute_percentage_error: 123.9398\n",
            "Epoch 897/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 50.2381 - mean_absolute_percentage_error: 50.2381 - val_loss: 120.8616 - val_mean_absolute_percentage_error: 120.8616\n",
            "Epoch 898/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 50.9551 - mean_absolute_percentage_error: 50.9551 - val_loss: 115.4415 - val_mean_absolute_percentage_error: 115.4415\n",
            "Epoch 899/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 52.2015 - mean_absolute_percentage_error: 52.2015 - val_loss: 113.3134 - val_mean_absolute_percentage_error: 113.3134\n",
            "Epoch 900/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 70.6744 - mean_absolute_percentage_error: 70.6744 - val_loss: 107.2072 - val_mean_absolute_percentage_error: 107.2072\n",
            "Epoch 901/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 51.1316 - mean_absolute_percentage_error: 51.1316 - val_loss: 106.2023 - val_mean_absolute_percentage_error: 106.2023\n",
            "Epoch 902/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 50.9480 - mean_absolute_percentage_error: 50.9480 - val_loss: 113.5989 - val_mean_absolute_percentage_error: 113.5989\n",
            "Epoch 903/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 49.1160 - mean_absolute_percentage_error: 49.1160 - val_loss: 111.0989 - val_mean_absolute_percentage_error: 111.0989\n",
            "Epoch 904/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 51.2330 - mean_absolute_percentage_error: 51.2330 - val_loss: 106.3009 - val_mean_absolute_percentage_error: 106.3009\n",
            "Epoch 905/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 49.4642 - mean_absolute_percentage_error: 49.4642 - val_loss: 113.3753 - val_mean_absolute_percentage_error: 113.3753\n",
            "Epoch 906/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 49.6085 - mean_absolute_percentage_error: 49.6085 - val_loss: 113.2321 - val_mean_absolute_percentage_error: 113.2321\n",
            "Epoch 907/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 51.5764 - mean_absolute_percentage_error: 51.5764 - val_loss: 109.7061 - val_mean_absolute_percentage_error: 109.7061\n",
            "Epoch 908/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 49.0976 - mean_absolute_percentage_error: 49.0976 - val_loss: 107.5850 - val_mean_absolute_percentage_error: 107.5850\n",
            "Epoch 909/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 49.4355 - mean_absolute_percentage_error: 49.4355 - val_loss: 110.7345 - val_mean_absolute_percentage_error: 110.7345\n",
            "Epoch 910/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 48.2391 - mean_absolute_percentage_error: 48.2391 - val_loss: 112.1813 - val_mean_absolute_percentage_error: 112.1813\n",
            "Epoch 911/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 48.3665 - mean_absolute_percentage_error: 48.3665 - val_loss: 110.4860 - val_mean_absolute_percentage_error: 110.4860\n",
            "Epoch 912/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 48.6189 - mean_absolute_percentage_error: 48.6189 - val_loss: 110.5399 - val_mean_absolute_percentage_error: 110.5399\n",
            "Epoch 913/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 48.3666 - mean_absolute_percentage_error: 48.3666 - val_loss: 113.6703 - val_mean_absolute_percentage_error: 113.6703\n",
            "Epoch 914/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 49.4223 - mean_absolute_percentage_error: 49.4223 - val_loss: 114.4230 - val_mean_absolute_percentage_error: 114.4230\n",
            "Epoch 915/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 47.8999 - mean_absolute_percentage_error: 47.8999 - val_loss: 114.6015 - val_mean_absolute_percentage_error: 114.6015\n",
            "Epoch 916/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 47.6732 - mean_absolute_percentage_error: 47.6732 - val_loss: 116.2366 - val_mean_absolute_percentage_error: 116.2366\n",
            "Epoch 917/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 47.4269 - mean_absolute_percentage_error: 47.4269 - val_loss: 114.5226 - val_mean_absolute_percentage_error: 114.5226\n",
            "Epoch 918/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 47.8836 - mean_absolute_percentage_error: 47.8836 - val_loss: 111.8589 - val_mean_absolute_percentage_error: 111.8589\n",
            "Epoch 919/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 48.3338 - mean_absolute_percentage_error: 48.3338 - val_loss: 111.9618 - val_mean_absolute_percentage_error: 111.9618\n",
            "Epoch 920/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 47.9740 - mean_absolute_percentage_error: 47.9740 - val_loss: 108.3920 - val_mean_absolute_percentage_error: 108.3920\n",
            "Epoch 921/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 48.9058 - mean_absolute_percentage_error: 48.9058 - val_loss: 106.5062 - val_mean_absolute_percentage_error: 106.5062\n",
            "Epoch 922/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 47.7727 - mean_absolute_percentage_error: 47.7727 - val_loss: 113.1150 - val_mean_absolute_percentage_error: 113.1150\n",
            "Epoch 923/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 47.7410 - mean_absolute_percentage_error: 47.7410 - val_loss: 108.3517 - val_mean_absolute_percentage_error: 108.3517\n",
            "Epoch 924/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 47.6241 - mean_absolute_percentage_error: 47.6241 - val_loss: 125.8679 - val_mean_absolute_percentage_error: 125.8679\n",
            "Epoch 925/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 47.3338 - mean_absolute_percentage_error: 47.3338 - val_loss: 106.9252 - val_mean_absolute_percentage_error: 106.9252\n",
            "Epoch 926/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 48.3589 - mean_absolute_percentage_error: 48.3589 - val_loss: 112.7549 - val_mean_absolute_percentage_error: 112.7549\n",
            "Epoch 927/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 47.2916 - mean_absolute_percentage_error: 47.2916 - val_loss: 111.0177 - val_mean_absolute_percentage_error: 111.0177\n",
            "Epoch 928/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 48.3338 - mean_absolute_percentage_error: 48.3338 - val_loss: 106.1789 - val_mean_absolute_percentage_error: 106.1789\n",
            "Epoch 929/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 48.9938 - mean_absolute_percentage_error: 48.9938 - val_loss: 116.2399 - val_mean_absolute_percentage_error: 116.2399\n",
            "Epoch 930/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 48.6888 - mean_absolute_percentage_error: 48.6888 - val_loss: 109.9816 - val_mean_absolute_percentage_error: 109.9816\n",
            "Epoch 931/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 50.0850 - mean_absolute_percentage_error: 50.0850 - val_loss: 114.7211 - val_mean_absolute_percentage_error: 114.7211\n",
            "Epoch 932/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 49.2466 - mean_absolute_percentage_error: 49.2466 - val_loss: 119.2355 - val_mean_absolute_percentage_error: 119.2355\n",
            "Epoch 933/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 47.0045 - mean_absolute_percentage_error: 47.0045 - val_loss: 115.8102 - val_mean_absolute_percentage_error: 115.8102\n",
            "Epoch 934/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 51.2875 - mean_absolute_percentage_error: 51.2875 - val_loss: 113.6804 - val_mean_absolute_percentage_error: 113.6804\n",
            "Epoch 935/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 47.1419 - mean_absolute_percentage_error: 47.1419 - val_loss: 117.2326 - val_mean_absolute_percentage_error: 117.2326\n",
            "Epoch 936/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 47.8284 - mean_absolute_percentage_error: 47.8284 - val_loss: 114.6571 - val_mean_absolute_percentage_error: 114.6571\n",
            "Epoch 937/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 48.3385 - mean_absolute_percentage_error: 48.3385 - val_loss: 111.1493 - val_mean_absolute_percentage_error: 111.1493\n",
            "Epoch 938/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 49.0442 - mean_absolute_percentage_error: 49.0442 - val_loss: 106.1693 - val_mean_absolute_percentage_error: 106.1693\n",
            "Epoch 939/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 47.0058 - mean_absolute_percentage_error: 47.0058 - val_loss: 123.5579 - val_mean_absolute_percentage_error: 123.5579\n",
            "Epoch 940/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 51.6656 - mean_absolute_percentage_error: 51.6656 - val_loss: 99.3719 - val_mean_absolute_percentage_error: 99.3719\n",
            "Epoch 941/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 49.4791 - mean_absolute_percentage_error: 49.4791 - val_loss: 114.3138 - val_mean_absolute_percentage_error: 114.3138\n",
            "Epoch 942/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 48.0911 - mean_absolute_percentage_error: 48.0911 - val_loss: 116.2784 - val_mean_absolute_percentage_error: 116.2784\n",
            "Epoch 943/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 47.5474 - mean_absolute_percentage_error: 47.5474 - val_loss: 113.2135 - val_mean_absolute_percentage_error: 113.2135\n",
            "Epoch 944/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 46.9352 - mean_absolute_percentage_error: 46.9352 - val_loss: 108.1296 - val_mean_absolute_percentage_error: 108.1296\n",
            "Epoch 945/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 46.4357 - mean_absolute_percentage_error: 46.4357 - val_loss: 116.4882 - val_mean_absolute_percentage_error: 116.4882\n",
            "Epoch 946/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 47.5073 - mean_absolute_percentage_error: 47.5073 - val_loss: 117.0556 - val_mean_absolute_percentage_error: 117.0556\n",
            "Epoch 947/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 48.2327 - mean_absolute_percentage_error: 48.2327 - val_loss: 109.1732 - val_mean_absolute_percentage_error: 109.1732\n",
            "Epoch 948/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 48.5857 - mean_absolute_percentage_error: 48.5857 - val_loss: 112.6950 - val_mean_absolute_percentage_error: 112.6950\n",
            "Epoch 949/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 46.4444 - mean_absolute_percentage_error: 46.4444 - val_loss: 110.3850 - val_mean_absolute_percentage_error: 110.3850\n",
            "Epoch 950/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 47.4340 - mean_absolute_percentage_error: 47.4340 - val_loss: 110.1865 - val_mean_absolute_percentage_error: 110.1865\n",
            "Epoch 951/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 46.4215 - mean_absolute_percentage_error: 46.4215 - val_loss: 113.3196 - val_mean_absolute_percentage_error: 113.3196\n",
            "Epoch 952/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 47.4607 - mean_absolute_percentage_error: 47.4607 - val_loss: 110.3914 - val_mean_absolute_percentage_error: 110.3914\n",
            "Epoch 953/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 46.4931 - mean_absolute_percentage_error: 46.4931 - val_loss: 113.9582 - val_mean_absolute_percentage_error: 113.9582\n",
            "Epoch 954/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 48.2049 - mean_absolute_percentage_error: 48.2049 - val_loss: 113.7779 - val_mean_absolute_percentage_error: 113.7779\n",
            "Epoch 955/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 48.3101 - mean_absolute_percentage_error: 48.3101 - val_loss: 105.6709 - val_mean_absolute_percentage_error: 105.6709\n",
            "Epoch 956/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 46.7298 - mean_absolute_percentage_error: 46.7298 - val_loss: 110.5321 - val_mean_absolute_percentage_error: 110.5321\n",
            "Epoch 957/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 45.9386 - mean_absolute_percentage_error: 45.9386 - val_loss: 107.3231 - val_mean_absolute_percentage_error: 107.3231\n",
            "Epoch 958/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 46.7202 - mean_absolute_percentage_error: 46.7202 - val_loss: 114.0786 - val_mean_absolute_percentage_error: 114.0786\n",
            "Epoch 959/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 48.4115 - mean_absolute_percentage_error: 48.4115 - val_loss: 107.8873 - val_mean_absolute_percentage_error: 107.8873\n",
            "Epoch 960/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 46.7833 - mean_absolute_percentage_error: 46.7833 - val_loss: 105.7934 - val_mean_absolute_percentage_error: 105.7934\n",
            "Epoch 961/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 46.6119 - mean_absolute_percentage_error: 46.6119 - val_loss: 101.8143 - val_mean_absolute_percentage_error: 101.8143\n",
            "Epoch 962/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 49.2388 - mean_absolute_percentage_error: 49.2388 - val_loss: 106.0408 - val_mean_absolute_percentage_error: 106.0408\n",
            "Epoch 963/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 50.5479 - mean_absolute_percentage_error: 50.5479 - val_loss: 105.9807 - val_mean_absolute_percentage_error: 105.9807\n",
            "Epoch 964/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 47.3619 - mean_absolute_percentage_error: 47.3619 - val_loss: 114.3671 - val_mean_absolute_percentage_error: 114.3671\n",
            "Epoch 965/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 48.4825 - mean_absolute_percentage_error: 48.4825 - val_loss: 104.2032 - val_mean_absolute_percentage_error: 104.2032\n",
            "Epoch 966/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 46.0821 - mean_absolute_percentage_error: 46.0821 - val_loss: 115.5634 - val_mean_absolute_percentage_error: 115.5634\n",
            "Epoch 967/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 45.9390 - mean_absolute_percentage_error: 45.9390 - val_loss: 117.0583 - val_mean_absolute_percentage_error: 117.0583\n",
            "Epoch 968/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 46.0207 - mean_absolute_percentage_error: 46.0207 - val_loss: 126.9967 - val_mean_absolute_percentage_error: 126.9967\n",
            "Epoch 969/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 47.9887 - mean_absolute_percentage_error: 47.9887 - val_loss: 126.1984 - val_mean_absolute_percentage_error: 126.1984\n",
            "Epoch 970/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 47.4029 - mean_absolute_percentage_error: 47.4029 - val_loss: 109.4194 - val_mean_absolute_percentage_error: 109.4194\n",
            "Epoch 971/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 46.3725 - mean_absolute_percentage_error: 46.3725 - val_loss: 108.3098 - val_mean_absolute_percentage_error: 108.3098\n",
            "Epoch 972/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 45.6930 - mean_absolute_percentage_error: 45.6930 - val_loss: 108.3614 - val_mean_absolute_percentage_error: 108.3614\n",
            "Epoch 973/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 45.6464 - mean_absolute_percentage_error: 45.6464 - val_loss: 107.1503 - val_mean_absolute_percentage_error: 107.1503\n",
            "Epoch 974/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 45.9766 - mean_absolute_percentage_error: 45.9766 - val_loss: 117.5070 - val_mean_absolute_percentage_error: 117.5070\n",
            "Epoch 975/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 46.5567 - mean_absolute_percentage_error: 46.5567 - val_loss: 111.8621 - val_mean_absolute_percentage_error: 111.8621\n",
            "Epoch 976/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 45.7499 - mean_absolute_percentage_error: 45.7499 - val_loss: 96.0954 - val_mean_absolute_percentage_error: 96.0954\n",
            "Epoch 977/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 47.0247 - mean_absolute_percentage_error: 47.0247 - val_loss: 115.9243 - val_mean_absolute_percentage_error: 115.9243\n",
            "Epoch 978/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 44.8906 - mean_absolute_percentage_error: 44.8906 - val_loss: 105.8651 - val_mean_absolute_percentage_error: 105.8651\n",
            "Epoch 979/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 45.5181 - mean_absolute_percentage_error: 45.5181 - val_loss: 112.6493 - val_mean_absolute_percentage_error: 112.6493\n",
            "Epoch 980/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 45.3656 - mean_absolute_percentage_error: 45.3656 - val_loss: 104.9065 - val_mean_absolute_percentage_error: 104.9065\n",
            "Epoch 981/1000\n",
            "66/66 [==============================] - 1s 13ms/step - loss: 47.4852 - mean_absolute_percentage_error: 47.4852 - val_loss: 108.6236 - val_mean_absolute_percentage_error: 108.6236\n",
            "Epoch 982/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 44.3504 - mean_absolute_percentage_error: 44.3504 - val_loss: 107.1752 - val_mean_absolute_percentage_error: 107.1752\n",
            "Epoch 983/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 46.0466 - mean_absolute_percentage_error: 46.0466 - val_loss: 114.6288 - val_mean_absolute_percentage_error: 114.6288\n",
            "Epoch 984/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 48.7892 - mean_absolute_percentage_error: 48.7892 - val_loss: 109.1047 - val_mean_absolute_percentage_error: 109.1047\n",
            "Epoch 985/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 44.5612 - mean_absolute_percentage_error: 44.5612 - val_loss: 115.7493 - val_mean_absolute_percentage_error: 115.7493\n",
            "Epoch 986/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 48.2588 - mean_absolute_percentage_error: 48.2588 - val_loss: 108.4067 - val_mean_absolute_percentage_error: 108.4067\n",
            "Epoch 987/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 46.1037 - mean_absolute_percentage_error: 46.1037 - val_loss: 115.9215 - val_mean_absolute_percentage_error: 115.9215\n",
            "Epoch 988/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 47.7754 - mean_absolute_percentage_error: 47.7754 - val_loss: 103.4023 - val_mean_absolute_percentage_error: 103.4023\n",
            "Epoch 989/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 45.6446 - mean_absolute_percentage_error: 45.6446 - val_loss: 102.5682 - val_mean_absolute_percentage_error: 102.5682\n",
            "Epoch 990/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 45.7781 - mean_absolute_percentage_error: 45.7781 - val_loss: 107.9849 - val_mean_absolute_percentage_error: 107.9849\n",
            "Epoch 991/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 44.8293 - mean_absolute_percentage_error: 44.8293 - val_loss: 117.3535 - val_mean_absolute_percentage_error: 117.3535\n",
            "Epoch 992/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 47.4698 - mean_absolute_percentage_error: 47.4698 - val_loss: 113.5430 - val_mean_absolute_percentage_error: 113.5430\n",
            "Epoch 993/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 45.8188 - mean_absolute_percentage_error: 45.8188 - val_loss: 101.4725 - val_mean_absolute_percentage_error: 101.4725\n",
            "Epoch 994/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 46.7747 - mean_absolute_percentage_error: 46.7747 - val_loss: 104.3417 - val_mean_absolute_percentage_error: 104.3417\n",
            "Epoch 995/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 45.3268 - mean_absolute_percentage_error: 45.3268 - val_loss: 113.4336 - val_mean_absolute_percentage_error: 113.4336\n",
            "Epoch 996/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 45.7187 - mean_absolute_percentage_error: 45.7187 - val_loss: 103.4065 - val_mean_absolute_percentage_error: 103.4065\n",
            "Epoch 997/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 43.8635 - mean_absolute_percentage_error: 43.8635 - val_loss: 101.1516 - val_mean_absolute_percentage_error: 101.1516\n",
            "Epoch 998/1000\n",
            "66/66 [==============================] - 1s 12ms/step - loss: 44.2205 - mean_absolute_percentage_error: 44.2205 - val_loss: 108.5367 - val_mean_absolute_percentage_error: 108.5367\n",
            "Epoch 999/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 44.9388 - mean_absolute_percentage_error: 44.9388 - val_loss: 105.9427 - val_mean_absolute_percentage_error: 105.9427\n",
            "Epoch 1000/1000\n",
            "66/66 [==============================] - 1s 11ms/step - loss: 45.3606 - mean_absolute_percentage_error: 45.3606 - val_loss: 120.8028 - val_mean_absolute_percentage_error: 120.8028\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f528491d6d0>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#create convolutional layers and fit the model \n",
        "model=Sequential()\n",
        "model.add(Conv2D(32,kernel_size=(3,5),activation='relu',input_shape=(3,60,1),padding='same'))\n",
        "model.add(MaxPooling2D(padding='same'))\n",
        "\n",
        "model.add(Conv2D(64,kernel_size=(3,5),activation='relu',padding='same'))\n",
        "model.add(MaxPooling2D(padding='same'))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(960))\n",
        "model.add(Dense(60))\n",
        "model.compile(loss='mean_absolute_percentage_error',metrics=['mean_absolute_percentage_error'],optimizer='adam')\n",
        "\n",
        "model.fit(X_train,Y_train,epochs=1000,batch_size=1,validation_data=(X_test,Y_test))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuEdFI9-KYBn"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwPWJ_IDMqtH",
        "outputId": "b2a624d2-47f7-43b1-d704-5ab8928c8d8d",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting alibi[tensorflow]\n",
            "  Downloading alibi-0.8.0-py3-none-any.whl (472 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.4/472.4 KB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pillow<10.0,>=5.4.1 in /usr/local/lib/python3.8/dist-packages (from alibi[tensorflow]) (7.1.2)\n",
            "Requirement already satisfied: blis<0.8.0 in /usr/local/lib/python3.8/dist-packages (from alibi[tensorflow]) (0.7.9)\n",
            "Requirement already satisfied: scikit-learn<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from alibi[tensorflow]) (1.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from alibi[tensorflow]) (2.25.1)\n",
            "Requirement already satisfied: attrs<23.0.0,>=19.2.0 in /usr/local/lib/python3.8/dist-packages (from alibi[tensorflow]) (22.2.0)\n",
            "Requirement already satisfied: dill<0.4.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from alibi[tensorflow]) (0.3.6)\n",
            "Requirement already satisfied: matplotlib<4.0.0,>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from alibi[tensorflow]) (3.2.2)\n",
            "Requirement already satisfied: scikit-image<0.20,>=0.17.2 in /usr/local/lib/python3.8/dist-packages (from alibi[tensorflow]) (0.18.3)\n",
            "Collecting transformers<5.0.0,>=4.7.0\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from alibi[tensorflow]) (4.4.0)\n",
            "Requirement already satisfied: pandas<2.0.0,>=0.23.3 in /usr/local/lib/python3.8/dist-packages (from alibi[tensorflow]) (1.3.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.28.1 in /usr/local/lib/python3.8/dist-packages (from alibi[tensorflow]) (4.64.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.16.2 in /usr/local/lib/python3.8/dist-packages (from alibi[tensorflow]) (1.21.6)\n",
            "Requirement already satisfied: spacy[lookups]<4.0.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from alibi[tensorflow]) (3.4.4)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from alibi[tensorflow]) (1.7.3)\n",
            "Requirement already satisfied: tensorflow!=2.6.0,!=2.6.1,<2.11.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from alibi[tensorflow]) (2.9.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4.0.0,>=3.0.0->alibi[tensorflow]) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4.0.0,>=3.0.0->alibi[tensorflow]) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4.0.0,>=3.0.0->alibi[tensorflow]) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4.0.0,>=3.0.0->alibi[tensorflow]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas<2.0.0,>=0.23.3->alibi[tensorflow]) (2022.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.21.0->alibi[tensorflow]) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.21.0->alibi[tensorflow]) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.21.0->alibi[tensorflow]) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.21.0->alibi[tensorflow]) (2022.12.7)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image<0.20,>=0.17.2->alibi[tensorflow]) (1.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image<0.20,>=0.17.2->alibi[tensorflow]) (2.8.8)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image<0.20,>=0.17.2->alibi[tensorflow]) (2022.10.10)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image<0.20,>=0.17.2->alibi[tensorflow]) (2.9.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn<2.0.0,>=1.0.0->alibi[tensorflow]) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn<2.0.0,>=1.0.0->alibi[tensorflow]) (3.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi[tensorflow]) (57.4.0)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi[tensorflow]) (8.1.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi[tensorflow]) (2.11.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi[tensorflow]) (2.4.5)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi[tensorflow]) (0.10.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi[tensorflow]) (1.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi[tensorflow]) (6.3.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi[tensorflow]) (3.0.10)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi[tensorflow]) (3.0.8)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi[tensorflow]) (3.3.0)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi[tensorflow]) (0.7.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi[tensorflow]) (21.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi[tensorflow]) (2.0.7)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi[tensorflow]) (0.10.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi[tensorflow]) (1.0.9)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi[tensorflow]) (2.0.8)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi[tensorflow]) (1.0.4)\n",
            "Collecting spacy-lookups-data<1.1.0,>=1.0.3\n",
            "  Downloading spacy_lookups_data-1.0.3-py2.py3-none-any.whl (98.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.5/98.5 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow!=2.6.0,!=2.6.1,<2.11.0,>=2.0.0->alibi[tensorflow]) (1.6.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow!=2.6.0,!=2.6.1,<2.11.0,>=2.0.0->alibi[tensorflow]) (1.51.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow!=2.6.0,!=2.6.1,<2.11.0,>=2.0.0->alibi[tensorflow]) (3.3.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow!=2.6.0,!=2.6.1,<2.11.0,>=2.0.0->alibi[tensorflow]) (1.1.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow!=2.6.0,!=2.6.1,<2.11.0,>=2.0.0->alibi[tensorflow]) (1.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow!=2.6.0,!=2.6.1,<2.11.0,>=2.0.0->alibi[tensorflow]) (0.2.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow!=2.6.0,!=2.6.1,<2.11.0,>=2.0.0->alibi[tensorflow]) (0.4.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow!=2.6.0,!=2.6.1,<2.11.0,>=2.0.0->alibi[tensorflow]) (2.9.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow!=2.6.0,!=2.6.1,<2.11.0,>=2.0.0->alibi[tensorflow]) (2.1.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow!=2.6.0,!=2.6.1,<2.11.0,>=2.0.0->alibi[tensorflow]) (0.29.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow!=2.6.0,!=2.6.1,<2.11.0,>=2.0.0->alibi[tensorflow]) (3.1.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow!=2.6.0,!=2.6.1,<2.11.0,>=2.0.0->alibi[tensorflow]) (3.19.6)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow!=2.6.0,!=2.6.1,<2.11.0,>=2.0.0->alibi[tensorflow]) (2.9.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow!=2.6.0,!=2.6.1,<2.11.0,>=2.0.0->alibi[tensorflow]) (1.14.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow!=2.6.0,!=2.6.1,<2.11.0,>=2.0.0->alibi[tensorflow]) (1.15.0)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow!=2.6.0,!=2.6.1,<2.11.0,>=2.0.0->alibi[tensorflow]) (2.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow!=2.6.0,!=2.6.1,<2.11.0,>=2.0.0->alibi[tensorflow]) (14.0.6)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow!=2.6.0,!=2.6.1,<2.11.0,>=2.0.0->alibi[tensorflow]) (1.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers<5.0.0,>=4.7.0->alibi[tensorflow]) (2022.6.2)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m91.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.4/182.4 KB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers<5.0.0,>=4.7.0->alibi[tensorflow]) (3.8.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers<5.0.0,>=4.7.0->alibi[tensorflow]) (6.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow!=2.6.0,!=2.6.1,<2.11.0,>=2.0.0->alibi[tensorflow]) (0.38.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow!=2.6.0,!=2.6.1,<2.11.0,>=2.0.0->alibi[tensorflow]) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow!=2.6.0,!=2.6.1,<2.11.0,>=2.0.0->alibi[tensorflow]) (2.15.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow!=2.6.0,!=2.6.1,<2.11.0,>=2.0.0->alibi[tensorflow]) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow!=2.6.0,!=2.6.1,<2.11.0,>=2.0.0->alibi[tensorflow]) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow!=2.6.0,!=2.6.1,<2.11.0,>=2.0.0->alibi[tensorflow]) (3.4.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow!=2.6.0,!=2.6.1,<2.11.0,>=2.0.0->alibi[tensorflow]) (1.0.1)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy[lookups]<4.0.0,>=2.0.0->alibi[tensorflow]) (0.0.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy[lookups]<4.0.0,>=2.0.0->alibi[tensorflow]) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy[lookups]<4.0.0,>=2.0.0->alibi[tensorflow]) (2.0.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow!=2.6.0,!=2.6.1,<2.11.0,>=2.0.0->alibi[tensorflow]) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow!=2.6.0,!=2.6.1,<2.11.0,>=2.0.0->alibi[tensorflow]) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow!=2.6.0,!=2.6.1,<2.11.0,>=2.0.0->alibi[tensorflow]) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow!=2.6.0,!=2.6.1,<2.11.0,>=2.0.0->alibi[tensorflow]) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow!=2.6.0,!=2.6.1,<2.11.0,>=2.0.0->alibi[tensorflow]) (5.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow!=2.6.0,!=2.6.1,<2.11.0,>=2.0.0->alibi[tensorflow]) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow!=2.6.0,!=2.6.1,<2.11.0,>=2.0.0->alibi[tensorflow]) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow!=2.6.0,!=2.6.1,<2.11.0,>=2.0.0->alibi[tensorflow]) (3.2.2)\n",
            "Installing collected packages: tokenizers, spacy-lookups-data, huggingface-hub, transformers, alibi\n",
            "Successfully installed alibi-0.8.0 huggingface-hub-0.11.1 spacy-lookups-data-1.0.3 tokenizers-0.13.2 transformers-4.25.1\n"
          ]
        }
      ],
      "source": [
        "pip install alibi[tensorflow]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcBNv-XVsREM",
        "outputId": "717ed79e-6f5e-4f61-a03f-0cf5934d5bb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(66, 3, 60, 1) (17, 3, 60, 1) (66, 1, 60) (17, 1, 60)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAR3lQVLM9vv",
        "outputId": "a43b1f72-7abe-4bf6-fbcd-f91043c90aa1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 0s 8ms/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from alibi.explainers import IntegratedGradients\n",
        "from functools import partial\n",
        "\n",
        "target_fn=partial(np.argmax, axis=1)\n",
        "\n",
        "ig=IntegratedGradients(model, target_fn=target_fn)\n",
        "explanations=ig.explain(X_train)\n",
        "predictions=model.predict(X_train)\n",
        "#ig  = IntegratedGradients(model,\n",
        "#                        method=\"gausslegendre\",\n",
        "#                          n_steps=20)\n",
        "\n",
        "#predictions = model.predict(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wefxm9vc2TxY",
        "outputId": "ae24ca69-0911-4889-db18-cce4f2875a08"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1.4661005e+05, 1.5074988e+05, 1.5490923e+05, ..., 4.3458981e+05,\n",
              "        3.5429728e+05, 4.3353225e+05],\n",
              "       [1.5412368e+06, 2.0662274e+06, 2.2175938e+06, ..., 4.6636375e+06,\n",
              "        4.7179175e+06, 5.7353950e+06],\n",
              "       [5.6633275e+05, 7.3907288e+05, 8.1263112e+05, ..., 1.6145830e+06,\n",
              "        1.6616092e+06, 1.9742926e+06],\n",
              "       ...,\n",
              "       [4.3647684e+05, 4.9383984e+05, 5.3301269e+05, ..., 1.0021241e+06,\n",
              "        9.7177762e+05, 1.0958945e+06],\n",
              "       [9.7191809e+02, 1.0986787e+03, 1.1741982e+03, ..., 3.1525784e+03,\n",
              "        2.9749336e+03, 3.3496433e+03],\n",
              "       [4.9758286e+03, 6.0645103e+03, 5.5834658e+03, ..., 5.4766787e+03,\n",
              "        4.8023022e+03, 5.0941626e+03]], dtype=float32)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "explanations.predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRa8xg_FaJKP",
        "outputId": "9848b30a-e817-4264-d811-bde85cdba0d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1.46610047e+05 1.50749875e+05 1.54909234e+05 ... 4.34589812e+05\n",
            "  3.54297281e+05 4.33532250e+05]\n",
            " [1.54123675e+06 2.06622738e+06 2.21759375e+06 ... 4.66363750e+06\n",
            "  4.71791750e+06 5.73539500e+06]\n",
            " [5.66332750e+05 7.39072875e+05 8.12631125e+05 ... 1.61458300e+06\n",
            "  1.66160925e+06 1.97429262e+06]\n",
            " ...\n",
            " [4.36476844e+05 4.93839812e+05 5.33012688e+05 ... 1.00212406e+06\n",
            "  9.71777750e+05 1.09589438e+06]\n",
            " [9.71918274e+02 1.09867871e+03 1.17419812e+03 ... 3.15257861e+03\n",
            "  2.97493335e+03 3.34964258e+03]\n",
            " [4.97582861e+03 6.06451074e+03 5.58346533e+03 ... 5.47667920e+03\n",
            "  4.80230273e+03 5.09416406e+03]]\n"
          ]
        }
      ],
      "source": [
        "# Calculate attributions\n",
        "#predictions = model(X_train).numpy()\n",
        "print(predictions)\n",
        "\n",
        "#explanation = ig.explain(X_train,\n",
        "#                         baselines = None,\n",
        "#                         target = None)\n",
        "\n",
        "attributions = explanations.attributions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmiK5QaioUgr",
        "outputId": "af98d99a-1877-4782-eea1-73becacf7c43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[146610.05 150749.88 154909.23 153163.66 129094.11  96247.46 151049.92\n",
            " 162611.67 151573.8  138646.23 140227.02 128730.48 139517.19 212265.36\n",
            " 204967.12 250372.89 236547.53 277186.   264399.   279308.53 281223.47\n",
            " 318310.06 323179.3  365812.12 369578.22 368233.   329419.66 293041.94\n",
            " 275930.72 307988.44 332232.62 312515.78 311230.84 312458.5  395407.53\n",
            " 413293.72 356232.53 367157.47 313396.34 342445.62 360356.6  390325.22\n",
            " 412426.9  434939.34 428137.25 415463.5  406300.34 422876.62 436334.7\n",
            " 452793.06 481596.62 550944.1  479316.06 507077.4  509827.53 517343.2\n",
            " 437107.84 434589.8  354297.28 433532.25]\n",
            "[1541236.8 2066227.4 2217593.8 2254696.  1909469.1 1712429.9 2451872.8\n",
            " 2793552.5 2855744.5 2556757.  2759339.8 2539451.5 2500139.  3059031.8\n",
            " 3258597.  3908173.2 3210062.8 3805718.  3651120.8 3734614.5 3815925.2\n",
            " 3953897.8 4276514.5 4133092.2 4543747.5 4937459.  4690222.  4226414.\n",
            " 4143328.  4811439.5 5015023.5 4636854.5 4656681.  4191438.5 4366276.5\n",
            " 5225951.5 4585506.  5155331.5 4650891.5 4707863.  4658706.5 5260561.\n",
            " 5226535.5 5541456.  5556487.  5472348.5 5032601.  5236512.  5408708.\n",
            " 5160658.5 6104798.  6288798.5 6113908.  5604987.  5468514.5 5464216.\n",
            " 5130675.  4663637.5 4717917.5 5735395. ]\n",
            "[ 566332.75  739072.9   812631.1   809909.06  687371.25  608183.8\n",
            "  879849.94 1001949.7  1009805.06  906871.7   986231.4   898078.94\n",
            "  906299.56 1082494.2  1142702.5  1375320.1  1123597.2  1354032.2\n",
            " 1304052.4  1337202.8  1380519.5  1429147.1  1537585.5  1497037.9\n",
            " 1614319.   1710392.8  1626433.4  1481849.8  1440840.2  1707580.5\n",
            " 1761833.6  1650380.8  1670275.1  1503515.6  1525093.2  1808104.5\n",
            " 1537591.4  1723244.1  1524428.2  1611540.9  1615080.6  1802785.\n",
            " 1775854.   1897212.6  1909751.1  1864804.5  1742356.1  1807251.6\n",
            " 1784389.4  1663011.1  1951792.2  2043015.4  2082527.6  1893071.9\n",
            " 1893235.6  1857043.8  1753382.8  1614583.   1661609.2  1974292.6 ]\n",
            "[1862.5992 2511.059  2288.8606 3051.1694 2583.917  2451.4102 3570.0103\n",
            " 3129.7546 3454.0393 2928.8926 2317.4497 2118.9802 1720.3854 4009.618\n",
            " 3500.8298 4795.523  4036.626  3810.3303 2864.81   2706.6697 2277.075\n",
            " 2735.9048 3569.7537 3548.6992 3730.3198 4625.7803 3351.1636 4127.765\n",
            " 4033.8406 4361.53   4674.635  4373.889  3398.307  3290.5415 4426.3174\n",
            " 8230.956  8092.0947 7912.8564 7017.678  7071.7085 7281.554  8216.121\n",
            " 8923.282  8397.801  8513.189  8068.2344 8278.296  8294.744  9459.015\n",
            " 6900.211  6831.3623 6190.5557 5027.5444 3870.8862 2266.3013 6309.4727\n",
            " 4255.8613 5068.4946 4917.894  6020.957 ]\n",
            "[ 35031.07   61428.42   63514.227  65180.12   52225.836  49793.082\n",
            "  69674.945  89012.98   95325.61   86448.33   94131.08   88599.72\n",
            "  84398.24  107434.89  117181.84  141153.42  120086.664 141043.5\n",
            " 138544.03  138831.52  140860.75  151121.05  171154.88  172133.08\n",
            " 200242.4   239977.33  231099.2   208851.75  206475.8   232665.2\n",
            " 237924.02  220527.73  201160.02  180262.1   182837.23  217402.14\n",
            " 199401.5   226990.72  221368.98  212790.75  202824.5   235064.1\n",
            " 241227.06  247542.03  247506.52  249853.02  231423.39  224768.86\n",
            " 260964.72  282922.34  325389.97  335295.34  301027.88  280315.72\n",
            " 270303.28  257471.14  258497.92  238322.47  260978.89  290419.56 ]\n",
            "[4480.2437 4776.013  4967.4585 4907.309  4662.2827 4227.728  5535.4644\n",
            " 5052.4766 5036.868  4863.373  4552.147  4429.0835 3673.2332 5714.8394\n",
            " 6572.423  7201.7896 6209.3975 6466.6436 4960.302  5306.9126 5192.9424\n",
            " 5036.2754 4125.576  3092.6138 2997.25   2635.6926 2616.3464 2641.7595\n",
            " 2419.6116 2312.655  2233.4932 2657.9478 3318.7512 3103.023  5266.0405\n",
            " 5719.445  5508.254  5286.4365 3873.4456 3955.68   4072.2976 4176.32\n",
            " 4178.178  3794.7126 4217.063  3978.2507 4077.145  3567.36   3947.5698\n",
            " 3986.6675 4245.631  3816.0952 3034.4255 2883.8276 2795.4187 2865.3447\n",
            " 2849.9897 2797.004  2898.293  3043.6633]\n",
            "[1143.8973    588.7929   1053.7339   1103.2579   1171.0563   1030.4005\n",
            " 1310.7104    803.9469    451.27908   505.26624   578.92      597.9222\n",
            "  610.5532    583.1083    493.30734   523.4935    534.50916   530.0839\n",
            "  381.3555    394.3178    358.2271    299.2341    275.40256   263.97922\n",
            "  296.6704    338.01654   339.06824   374.5456    356.22537   365.5097\n",
            "  365.68796   371.2586    343.8466    331.701     503.43958   552.3865\n",
            "  556.30255   549.7147    535.91394   581.2564    645.80664   129.7615\n",
            "  243.32413   321.01688   564.79987   288.39795   285.11853   297.35095\n",
            "  195.8209    229.8529    219.46588   179.4939    100.22756    68.02284\n",
            "   89.69352    42.214973  491.82828  1015.21704   796.2093    623.9755  ]\n",
            "[-4.40806770e+00 -8.69601154e+00  1.74968395e+01  5.42296600e+00\n",
            "  1.23559885e+01  1.24301132e+02  1.38409866e+02  1.15016350e+02\n",
            "  1.54074173e+02  1.46837204e+02  1.16401115e+02  9.78672256e+01\n",
            "  7.55276108e+01  8.54455032e+01  3.06504898e+01  1.10187523e+02\n",
            "  2.11231934e+02  6.55807343e+01  1.04195328e+02  9.17829895e+01\n",
            "  1.66432098e+02  2.14378601e+02  3.09215698e+02  4.75647064e+02\n",
            "  4.80762390e+02  5.91208740e+02  5.61922791e+02  5.74340637e+02\n",
            "  5.94043762e+02  6.51777283e+02  7.37741211e+02  6.90989441e+02\n",
            "  4.27477020e+02  3.61616882e+02  3.61045227e+02  4.58644043e+02\n",
            "  4.27370941e+02  5.57153870e+02  5.94844788e+02  6.06203796e+02\n",
            "  5.86750916e+02  5.91962280e+02  7.02466125e+02  9.18006653e+02\n",
            "  6.32672668e+02  7.30264404e+02  2.08034253e+03  3.60721338e+03\n",
            "  3.40371973e+03  2.42712891e+03  3.02432056e+03  6.26395117e+03\n",
            "  5.64926855e+03  5.66959277e+03  6.30330469e+03  7.60136914e+03\n",
            "  6.14225342e+03  7.57869971e+03  5.28019531e+03  7.60421436e+03]\n",
            "[10512.425 12523.071 13342.089 13608.785 11804.829  9705.863 14911.86\n",
            " 15204.016 15151.672 13396.922 13168.63  12530.108 11839.904 17977.818\n",
            " 20703.521 23422.992 19830.252 22463.395 20434.346 21661.031 21045.828\n",
            " 22164.826 21630.568 20578.615 21057.496 21412.734 20728.889 19570.986\n",
            " 17721.488 19097.752 19958.08  20100.707 22632.658 20768.936 24710.889\n",
            " 26307.992 22162.172 20396.371 14946.504 18341.604 19676.168 22431.979\n",
            " 23041.975 21633.121 23247.973 21337.633 21164.184 17996.56  17893.83\n",
            " 20318.744 19446.43  19854.215 19911.69  19671.014 19258.66  16683.385\n",
            " 15390.646 16362.273 20481.732 19373.822]\n",
            "[  607.0117    552.0557    679.7761    746.7634    765.8942    642.8256\n",
            "   750.67523   801.94794   839.52094   765.2408   1002.0548    764.70233\n",
            "   737.5899    845.9672   1195.654    1093.1343   1063.1024   1111.1886\n",
            "  1199.9736   1896.7628   2389.2288   2997.6562   3276.8726   3850.7158\n",
            "  4362.845    6062.3115   5381.676    4853.7397   4321.0317   4461.565\n",
            "  5710.9233   3131.936    6197.2974   7185.2676   7054.233    5765.3945\n",
            "  5722.0913   5195.721    3206.948    3077.7297   6184.67    10249.463\n",
            " 10500.737    8243.127   10947.963   12490.935   12513.739   14417.792\n",
            " 12780.233   13726.377   15915.865   15389.852   14326.586    9880.233\n",
            " 10808.273    9110.466    5716.5005   5571.6274   5992.9736  12051.845  ]\n",
            "[6054.3677 5639.386  6418.174  5594.239  5556.571  4814.468  5807.0703\n",
            " 6271.335  5731.072  6034.538  6754.9663 6726.824  6371.7954 6875.874\n",
            " 7320.1377 7970.9185 7803.287  8813.294  7778.1562 8081.232  9000.582\n",
            " 8906.706  7652.6655 8107.0713 8760.687  7717.634  7582.7925 4514.4487\n",
            " 4436.1426 5624.016  5913.512  5535.0903 6372.9097 6162.305  7036.583\n",
            " 6139.6797 5512.857  7372.669  5542.488  4998.2085 4815.2285 5022.3345\n",
            " 5232.177  4618.752  9535.081  9679.764  8806.875  6513.723  4614.6924\n",
            " 5176.4404 6553.658  5030.623  5324.7964 5153.91   3880.3987 2603.3547\n",
            " 3678.846  1061.4258 1030.8125 1360.9417]\n",
            "[ 615656.    991884.1  1017954.   1049126.4   855379.4   810332.06\n",
            " 1153847.9  1383178.5  1478208.4  1310196.6  1405921.8  1305247.4\n",
            " 1245449.8  1574787.8  1774920.2  2099693.5  1681941.4  1974876.1\n",
            " 1874614.4  1894854.6  1906480.1  1967816.9  2177998.5  2063718.5\n",
            " 2298798.8  2493300.2  2465882.2  2268101.8  2194027.   2563037.5\n",
            " 2618732.   2464933.2  2467081.5  2155142.8  2193033.   2661722.8\n",
            " 2309149.8  2561637.8  2378334.2  2369770.2  2372189.5  2762085.5\n",
            " 2747328.   2877513.8  2791998.8  2771135.   2619128.2  2670627.5\n",
            " 2916380.   2812586.5  3412123.2  3646876.5  3443388.2  3085520.5\n",
            " 3086353.5  3085533.   2943336.   2683527.2  2774798.2  3472175.5 ]\n",
            "[ 5762.7983 16403.686  11003.333  14878.838  12526.584  14900.844\n",
            " 19138.953  18003.486  24034.172  20782.377  15530.544  15917.44\n",
            "  8319.851  24992.385  31794.795  35671.53   28389.234  24689.547\n",
            " 16678.145  15998.525  12684.926  11935.284  13766.704   8052.8438\n",
            " 11386.859  16575.312  17046.113  20183.87   17010.418  14228.697\n",
            " 13506.859  13861.033  13244.54    9264.439  25692.129  38822.676\n",
            " 40485.023  39223.07   40689.883  29962.451  32517.402  39004.496\n",
            " 44543.39   42270.137  33268.44   34134.434  37067.08   37258.258\n",
            " 61775.684  57100.355  75606.32   88691.69   63633.36   59027.047\n",
            " 52819.473  75522.41   63404.344  64898.504  48062.156  81622.016 ]\n",
            "[19517428. 26824872. 29224030. 29334284. 24957848. 22495324. 32379360.\n",
            " 36703968. 37519964. 33475848. 36088324. 32943376. 32440550. 39039632.\n",
            " 42335696. 50514956. 40563728. 48350872. 46168976. 47404376. 48961856.\n",
            " 49808436. 53335864. 50249904. 54684952. 58167256. 55823192. 51093488.\n",
            " 49459820. 58259992. 59843260. 56003880. 57766272. 51073848. 52099064.\n",
            " 62673056. 53530288. 59902056. 53109076. 54969948. 54842720. 61959832.\n",
            " 60967784. 65094440. 64809364. 63167436. 58794248. 61312132. 61981096.\n",
            " 57594568. 68701520. 71576688. 73307464. 65663760. 65350424. 64566600.\n",
            " 61147488. 56410480. 58735732. 70796928.]\n",
            "[2380376.2 3208467.5 3484035.8 3486503.  2968917.  2611369.2 3851714.8\n",
            " 4276412.5 4351596.  3846779.8 4076044.5 3713825.5 3675670.  4579923.\n",
            " 4977853.  5940519.5 4800541.  5694661.5 5382647.5 5567065.5 5727494.\n",
            " 5841349.5 6146666.5 5837136.  6211922.  6410214.5 6098643.  5619468.\n",
            " 5352523.5 6359419.5 6538727.  6195721.  6517280.  5802882.  6033162.5\n",
            " 7165201.5 5983055.5 6584123.  5622264.5 6026516.5 6129154.  6855892.\n",
            " 6772236.5 7197713.5 7238043.  6946021.5 6591629.5 6792976.  6623203.\n",
            " 5991490.5 6982645.  7437897.  7890692.5 7026848.  7117719.5 7078387.\n",
            " 6519481.  6191594.5 6416685.5 7699647.5]\n",
            "[ 46309.844  53556.465  59805.42   60218.113  51914.69   42407.13\n",
            "  65304.33   69218.414  67583.11   59200.78   62326.832  56298.973\n",
            "  60391.137  73886.72   72145.25   89638.96   75327.23   90275.47\n",
            "  86442.23   90255.83   92287.01   97930.7   102263.984 103702.766\n",
            " 106880.88  108442.195  94450.98   84335.055  82420.4   100946.96\n",
            " 109553.016 101887.13  103239.71   98051.66  101284.43  121906.06\n",
            " 101183.27  113980.06   89724.92  104481.07  105526.02  112236.94\n",
            " 110800.45  117417.97  129428.71  121640.18  115356.88  119532.71\n",
            "  97199.15   75490.36   74208.336  76922.9    96700.98   86630.37\n",
            "  87104.734  94401.46   74745.05   75408.4    76214.29   83367.8  ]\n",
            "[ 392876.72  569605.7   591527.25  608724.56  515338.2   464999.5\n",
            "  684175.4   752375.    789791.6   689724.6   709511.44  653639.\n",
            "  616443.8   819696.6   911881.44 1085564.8   865402.7   995591.1\n",
            "  920379.75  947964.6   955372.    966072.5  1022485.6   926150.94\n",
            " 1004146.9  1040591.25 1005207.25  952713.4   898889.06 1033873.1\n",
            " 1058984.9  1005588.5  1070136.9   926005.3  1027149.5  1271366.8\n",
            " 1092272.4  1157780.6  1007021.6  1034631.3  1059807.2  1213311.4\n",
            " 1215867.9  1270401.1  1229385.4  1185297.8  1128809.1  1158627.6\n",
            " 1229678.   1111581.6  1341649.1  1429314.6  1418585.6  1261417.9\n",
            " 1236726.1  1301451.1  1194014.6  1138544.5  1145488.4  1453920.1 ]\n",
            "[1421.1743  1422.6167  1521.5312  1524.7141  1501.382   1693.2456\n",
            " 1722.4382  1881.7598  1859.095   2046.2777  2030.1798  2004.0541\n",
            " 2862.7     3061.781   3071.0344  2163.431    662.4527   412.21143\n",
            "  277.3237   493.83698  522.30304 1263.7561  1289.349   1345.4111\n",
            "  498.98096  479.00848  522.1198   885.1084  1036.942   1374.5789\n",
            " 1407.1786  1471.124   1446.3389  1463.3488  1536.6835  1623.2383\n",
            " 1411.694    988.66833 1241.7372  1654.3082  1581.9757  1551.7836\n",
            " 1372.8617  1451.9805  1042.2433   915.933   1090.3157  1301.2338\n",
            " 2007.9119  2478.7766  2297.561   2280.0642  1330.3947  3529.3196\n",
            " 2920.9622  4212.731   4155.1777  3814.8604  3678.5203  3072.4534 ]\n",
            "[1073059.  1506782.8 1610913.1 1626311.2 1384081.8 1242993.4 1814137.2\n",
            " 2016890.4 2082588.5 1841504.8 1935425.  1770742.5 1715723.2 2170120.5\n",
            " 2384254.  2837116.2 2269891.2 2657218.  2492708.2 2569371.2 2629247.8\n",
            " 2667943.2 2824153.5 2618336.5 2823444.2 2945984.  2831819.5 2643161.8\n",
            " 2517684.2 2949977.2 3018545.2 2860853.2 2998179.  2630085.2 2795793.2\n",
            " 3382259.  2869408.  3123657.8 2718347.8 2841315.8 2884126.  3260711.5\n",
            " 3235027.8 3421936.5 3364605.8 3252652.8 3090535.  3192181.  3261405.2\n",
            " 2972934.8 3540483.8 3782848.5 3857680.8 3447635.2 3447373.5 3506069.2\n",
            " 3247186.5 3080605.8 3143593.  3864445.5]\n",
            "[279278.34 310833.94 370087.1  347574.5  301381.62 244974.36 366875.66\n",
            " 401976.44 374801.28 347990.03 380597.38 337009.3  366045.88 435716.03\n",
            " 426334.7  525440.75 465216.38 575910.44 558780.2  578489.6  617256.2\n",
            " 658555.1  689574.75 748842.5  769683.5  811071.25 735649.6  664667.25\n",
            " 638478.2  791231.94 807186.6  774902.7  742307.7  711917.56 701319.5\n",
            " 773013.2  624235.9  725134.   611069.25 716634.3  725812.4  757013.7\n",
            " 756266.25 811130.2  871388.6  835894.8  821646.44 827882.44 719406.4\n",
            " 682588.25 689704.1  767528.25 856076.56 783132.06 853772.2  787345.44\n",
            " 726774.44 725409.4  766156.9  782130.94]\n",
            "[1444013.4 2074083.6 2197341.8 2240585.  1885320.5 1704765.9 2472284.2\n",
            " 2801969.8 2909097.2 2569915.8 2730562.8 2515012.5 2438544.2 3070630.5\n",
            " 3376879.  4029481.8 3267727.8 3843437.5 3642945.8 3733751.8 3797241.\n",
            " 3890007.2 4181423.8 3953844.5 4336406.  4649522.5 4459801.  4072914.\n",
            " 3933022.2 4592327.5 4752096.  4444828.  4558547.  4047223.  4223525.\n",
            " 5065878.  4364919.  4860793.  4328260.  4401939.  4419995.5 5018241.\n",
            " 4991901.  5267632.  5245749.5 5126745.5 4791933.5 4924829.  5103096.\n",
            " 4788996.5 5715189.  6028323.5 5973252.  5356309.  5308766.5 5339282.5\n",
            " 4950353.  4599799.  4689927.5 5810345. ]\n",
            "[ 898562.44 1211484.5  1318213.1  1322940.9  1122329.6  1001231.4\n",
            " 1450683.9  1642482.9  1671705.5  1493117.   1605810.4  1462059.5\n",
            " 1456664.5  1773837.2  1897977.4  2275025.   1832819.2  2189428.8\n",
            " 2088654.4  2144308.8  2207063.8  2269267.5  2434451.   2322383.\n",
            " 2502422.   2636233.2  2513815.   2319766.8  2244397.8  2654722.\n",
            " 2728763.5  2567191.2  2625348.8  2338756.2  2395567.   2883837.2\n",
            " 2448626.2  2711026.8  2385381.2  2515339.8  2527954.   2845722.5\n",
            " 2803286.8  2984621.8  2974708.   2892090.2  2705387.5  2796945.8\n",
            " 2797522.8  2579336.2  3038203.2  3158123.   3239701.8  2918095.2\n",
            " 2909287.   2882774.8  2715739.8  2504949.5  2616782.8  3114499.2 ]\n",
            "[  811.69086   774.4206    679.34106   823.7319    352.5851    623.49457\n",
            "   221.66002   232.91216   101.43276   278.82956   286.75754   330.75775\n",
            "   746.37714  1369.8707   1591.7046    708.255    1661.1973   1730.6263\n",
            "   699.25275   638.037    1250.8649   1948.1146   2276.5073   8029.5625\n",
            "  6768.2974   8221.3125   6071.7646   2001.354    2392.2473   7796.774\n",
            "  8423.373    7847.1797   4306.1533   7108.4995   2829.824    1550.4725\n",
            "   496.53992  9288.356   10384.886    8476.645    6363.454    3415.4487\n",
            "  3233.6199   6002.0723   8801.842    7509.659    6738.7637   8698.403\n",
            "  5700.8716   4427.4775    661.7719   2324.3909   4769.9277   1083.5643\n",
            "  7487.4624   7321.5933   5499.58     4215.3735   4380.701    3602.5427 ]\n",
            "[21183.242 24051.385 27742.055 27052.883 24456.941 20681.918 30315.758\n",
            " 30293.133 29237.594 26614.492 27211.91  24581.201 24961.633 30967.414\n",
            " 33328.27  38158.953 31361.236 37258.87  34482.668 36909.98  38584.89\n",
            " 39057.086 37899.168 35779.715 35771.547 37912.777 34447.16  31834.56\n",
            " 29637.926 34952.86  36098.79  35572.09  39839.965 37444.16  39699.06\n",
            " 42493.05  34668.383 37085.977 27304.463 33987.906 34708.023 35916.96\n",
            " 34622.367 35783.79  39790.688 36108.26  34476.508 33500.168 25824.008\n",
            " 24596.93  22516.793 21415.637 31542.506 29264.186 30411.422 25801.258\n",
            " 24475.701 25838.025 31965.537 27924.344]\n",
            "[ 3392123.   4469033.5  4918146.   4876844.5  4156396.2  3635812.5\n",
            "  5353676.   5969088.5  6009985.5  5348720.5  5717209.5  5183737.\n",
            "  5199810.   6390853.5  6871124.   8223747.   6678127.5  7982122.\n",
            "  7575923.5  7832405.   8113122.   8310173.   8752067.   8450225.\n",
            "  8932484.   9182440.   8709159.   8012394.   7643108.5  9180975.\n",
            "  9402557.   8933805.   9299342.   8339925.   8527703.  10054803.\n",
            "  8320014.   9236114.   7885714.5  8566989.   8704504.   9669282.\n",
            "  9526364.  10179104.  10289950.   9871112.   9406526.   9708163.\n",
            "  9302061.   8421681.   9695219.  10357282.  11128210.   9903958.\n",
            " 10173512.   9967241.   9233447.   8762272.   9163273.  10772559. ]\n",
            "[ 1755.2042  1852.0348  1383.749   1256.4067  1339.719   1331.1818\n",
            "  1431.6597  1117.3154  1197.0547  1074.0208  1438.4326  1189.9341\n",
            "   754.5263  1078.1202  2429.946   2981.3289  4688.903   4108.6206\n",
            "  5211.577   8303.23   10321.031  11904.972   9119.789  11263.489\n",
            " 13429.331  16115.87   17489.021  11029.058   9512.568   8985.418\n",
            " 10557.3545  8052.4478 12709.493  15790.142  19918.03    7586.7783\n",
            "  8059.2617 11877.606  11937.347   8675.769   8665.953  10944.227\n",
            " 10772.563  11981.028  11059.379  12766.459  11964.942  18015.701\n",
            " 19308.525  30576.145  31863.105  38653.473  30201.51   30698.596\n",
            " 37810.668  28382.637  26145.17   25819.021  20218.225  27125.566 ]\n",
            "[ 727031.25 1007510.75 1073993.1  1086108.2   921997.56  816079.9\n",
            " 1208263.1  1337626.6  1377753.9  1210336.2  1266691.4  1155905.\n",
            " 1128348.   1442035.6  1571091.2  1882050.2  1505298.8  1766671.6\n",
            " 1657065.1  1712391.9  1747527.1  1779615.4  1877729.4  1741087.1\n",
            " 1861593.5  1904926.4  1820996.1  1714638.5  1625439.5  1901551.6\n",
            " 1950919.1  1852451.6  1961111.6  1719878.1  1851343.   2253058.5\n",
            " 1899258.1  2029489.2  1736560.1  1847519.1  1891660.8  2143092.2\n",
            " 2130627.2  2250161.5  2208034.   2120044.8  2017952.6  2079681.4\n",
            " 2102307.2  1886565.9  2229360.   2371934.2  2450363.8  2192964.8\n",
            " 2182178.8  2236044.5  2047881.   1952254.6  1995877.9  2445463.  ]\n",
            "[ 3527.8381  3448.721   3056.0925  1912.9675  1968.0822  2048.133\n",
            "  2059.415   1964.94    2033.4238  2159.9236  2196.3467  2186.4087\n",
            "  2123.2844  1963.1835  2127.7346  2192.2097  2424.2751  2280.2532\n",
            "  2278.27    2182.2896  2137.5334  1731.8358  1918.76    1562.6228\n",
            "  1756.897   1526.3638  1918.711   1674.9932  1998.4545  2594.4436\n",
            "  3002.898   1676.3435  2346.8318  2819.9253  6476.628   3649.991\n",
            "  2974.9421  6953.902   8030.605   6487.773   9694.937   6841.2905\n",
            "  5877.7363  9171.029   5429.8027  9121.833   9199.878  14047.649\n",
            " 15629.193  10682.665  25367.36   38611.37   30057.281  30753.975\n",
            " 32017.684  38397.7    29857.348  30431.94    8502.362  35394.004 ]\n",
            "[ 942.3807   751.8642  1069.848    620.9525   590.459    428.66476\n",
            "  490.9173   746.0594   637.4629   932.8011  1293.293   1531.2041\n",
            "  949.87213  791.4029  3188.9473  1346.4243  1370.1921  2480.1538\n",
            " 2599.6223  2906.1475  2799.9734  2467.8276  1714.2253  2525.1477\n",
            " 2290.7412  3908.1252  4958.0273  3191.222   3213.103   3133.7136\n",
            " 3660.667   3776.4766  4670.1353  4538.197   4590.5244   402.99738\n",
            "  183.27579  107.6687   150.42236  277.19235  305.798    485.2887\n",
            "  450.08075  433.36703  281.88046  360.1932   394.30774  410.90308\n",
            "  541.05365 5404.8984  4631.9834  6780.1973  4501.2793  6889.934\n",
            " 7934.17    3807.9758  5474.9185  5725.148   5320.1187  4799.839  ]\n",
            "[  819.0009    892.0484   1356.0532   -169.7905    145.2085   -302.08627\n",
            "  -111.75989   200.75446   338.97202  1023.17236  1021.68726  2081.6597\n",
            "  2100.9138   2411.746    1837.6703   2507.161    3314.2156   3225.7336\n",
            "  2500.1646   1575.9215    398.81693  1842.4227   2898.088    2885.9106\n",
            "  4948.7046   5897.0874   7026.2173   8593.914    8837.152    9735.917\n",
            "  9332.129   10451.1045   4675.7534   3197.3079   5891.4883   6873.5737\n",
            "  6063.493    4002.578    3569.9539   6592.2783   8634.983    7789.0527\n",
            "  9680.177    7046.503    9350.234   11100.832   13570.264    6781.9023\n",
            "  7386.4634   8528.896    9237.913   14703.957    7769.119    8085.08\n",
            "  8046.062    9753.85    11067.669   12459.6455  11404.942   13143.041  ]\n",
            "[ 622676.6   671740.06  741390.4   740728.75  632241.7   508219.53\n",
            "  766124.4   848071.75  808014.9   732235.    794898.9   718731.06\n",
            "  768496.3   959954.06  909521.3  1134376.2   980902.1  1191060.8\n",
            " 1161121.6  1202850.9  1230165.   1338870.9  1422383.2  1480954.\n",
            " 1548970.2  1594582.8  1443035.6  1311113.5  1288895.4  1489754.\n",
            " 1581728.2  1466349.6  1441086.1  1362791.4  1502896.9  1759805.1\n",
            " 1526092.4  1630074.9  1400804.6  1545658.2  1553274.9  1707820.1\n",
            " 1717625.2  1826650.8  1854090.4  1795734.6  1652181.4  1719567.9\n",
            " 1657901.9  1582035.6  1709098.9  1698476.2  1660282.5  1639386.1\n",
            " 1575110.4  1560122.   1430445.   1305735.5  1291375.2  1400326.1 ]\n",
            "[ 7101.1064 10881.077  12178.469  11124.158   9340.698   7726.7437\n",
            " 11879.77   13696.205  13565.472  12318.355  13021.097  11243.56\n",
            " 12342.108  16120.898  16736.064  20762.057  17582.426  21602.62\n",
            " 20755.008  21589.246  23189.898  24633.627  26082.465  26628.072\n",
            " 27457.877  29048.934  25976.643  25707.154  24610.047  29791.322\n",
            " 30408.988  29019.918  28645.398  26965.855  28523.701  31539.113\n",
            " 24922.723  26489.95   21638.762  25379.084  28325.195  31294.346\n",
            " 32121.467  33801.277  33522.72   33468.562  34137.86   34164.94\n",
            " 33209.758  31301.328  34774.98   41166.707  41665.152  39214.543\n",
            " 40718.957  41563.164  32957.977  34042.324  31446.76   39301.59  ]\n",
            "[181786.64 230778.4  255302.45 250687.25 214333.62 181714.7  275538.62\n",
            " 299175.3  297508.97 262688.2  275786.06 247631.66 252653.17 320062.9\n",
            " 342062.1  410698.   334743.12 399910.5  375533.25 392390.25 406995.7\n",
            " 418342.44 431243.06 421775.53 430356.47 420741.62 393878.6  369672.9\n",
            " 343675.22 420822.2  429280.   415918.75 444412.34 402727.12 420761.53\n",
            " 487561.75 388066.34 418987.06 336771.66 392835.1  412158.8  450103.06\n",
            " 444662.97 475435.6  482031.38 452165.25 446510.22 460256.28 414912.3\n",
            " 356581.4  391544.2  441635.25 505397.9  446656.9  477723.03 471975.06\n",
            " 418927.3  419212.84 431473.9  502505.44]\n",
            "[ 476930.72  730892.7   759514.7   786907.1   656362.3   602015.56\n",
            "  872814.5  1002374.94 1058801.2   926786.8   985649.9   916573.\n",
            "  874520.44 1105804.5  1235120.5  1474203.1  1188011.9  1385972.\n",
            " 1317565.9  1346291.9  1352096.   1383387.4  1501249.1  1387192.4\n",
            " 1559048.5  1695359.5  1640156.9  1491865.   1450340.4  1668268.5\n",
            " 1740912.5  1611834.8  1651210.1  1448979.8  1525853.   1852943.9\n",
            " 1622842.5  1802555.8  1621767.8  1607064.1  1603819.2  1850774.1\n",
            " 1845196.4  1932119.2  1916148.2  1888073.9  1743105.2  1783129.8\n",
            " 1904304.5  1806349.4  2188268.8  2290661.8  2211520.8  1979841.6\n",
            " 1929975.4  1957596.2  1805926.   1660042.   1695418.2  2150467.  ]\n",
            "[ 3758.4832   3492.5046   2698.238    2945.1504   2210.7065   1664.9691\n",
            "  1887.397    2637.8801   1651.3689   2153.0889   2061.561    1549.336\n",
            "  1003.43195  5835.9062   6960.6084   7362.406    7634.729    7889.437\n",
            "  6566.384    7442.8335   8643.91     9673.139    7935.3394  12642.181\n",
            " 10506.481    4579.878    3740.5166   2481.101     891.0728    612.6656\n",
            "   270.71143   400.7609   1132.1462   1796.7511  10190.098    9159.08\n",
            "  7382.4756   4734.385    5400.626    2303.7893   2748.924    5779.5996\n",
            "  9950.544   12296.828    7636.715    5696.025    7327.044   10278.278\n",
            " 19295.834   24082.66    23704.484   29437.953   19530.69    24688.75\n",
            " 26359.904   27963.72    21969.52    22859.95    14799.667   18659.861  ]\n",
            "[ 19578.795  29474.54   30571.246  27826.32   22376.79   17263.713\n",
            "  28283.389  35141.02   35529.848  32362.725  33794.562  31773.926\n",
            "  31264.34   48113.535  56698.395  64856.523  56849.344  66791.586\n",
            "  63335.188  65672.55   65964.86   71790.59   73926.01   77116.83\n",
            "  80461.445  81388.93   79716.875  76593.69   71076.83   80103.016\n",
            "  81939.18   80187.39   81123.836  74089.36   88278.266  89421.58\n",
            "  71918.31   66268.18   53850.734  63372.113  74019.836  87516.05\n",
            "  93879.47   92248.31   90488.16   91227.35   95408.4    86902.12\n",
            "  96065.41  107846.81  118179.4   141895.5   123277.27  123415.84\n",
            " 127163.42  121751.68  103417.86  105406.69   99450.63  123216.74 ]\n",
            "[ 6553.784  11143.988   9925.942  11498.042   9468.764   9786.92\n",
            " 13914.226  13281.296  15391.8545 13259.58   11109.089  12151.628\n",
            "  4747.168  18400.072  28034.525  29394.057  24503.95   21524.29\n",
            " 14521.397  14415.729  11260.898  10568.14    9635.018   9463.638\n",
            "  9706.74    7814.2197 14485.211  13884.367   8721.02   11469.93\n",
            "  6422.8457 11442.791  12337.591   8766.538  11413.099  13795.146\n",
            " 12023.274  12340.776  14047.625  10629.893  11201.516  13449.681\n",
            " 15040.355  10556.624  10429.489   8439.041  11698.369   3533.289\n",
            " 15169.669  19908.691  22921.184  24323.164  15636.156   3938.1675\n",
            " 12167.781   6957.3594 17023.354  15446.833  27946.967  31698.887 ]\n",
            "[  5991.0386  17633.273   16822.291   17096.082   12698.675   10662.784\n",
            "  18504.69    21819.977   24509.83    20257.596   19526.596   17229.227\n",
            "  18125.348   30157.543   32758.664   42321.97    36426.74    42822.99\n",
            "  40863.55    42027.55    41769.38    46518.957   52180.88    52919.203\n",
            "  57613.297   65802.21    59197.66    58999.65    56728.625   66082.836\n",
            "  69307.4     65725.95    62025.457   58896.098   64496.305   73377.67\n",
            "  61126.812   64344.164   55518.613   60133.938   66621.945   75398.06\n",
            "  78610.8     80055.07    77134.15    77649.01    78648.82    76801.84\n",
            "  81230.72    78021.09    86964.76   102972.336   95568.086   88141.28\n",
            "  90754.12    96362.28    74199.66    77461.9     71410.66    93059.055 ]\n",
            "[2154.512  2258.3645 2422.532  2541.1746 2114.9985 1612.9432 2731.2944\n",
            " 2777.3845 2663.277  2279.3147 2216.2285 2094.584  2187.239  3501.3901\n",
            " 3519.9702 4329.879  3866.8767 4302.791  4023.5554 4204.1587 3981.0771\n",
            " 4544.5195 4727.8037 5052.473  5010.0405 4863.0923 4438.667  4286.031\n",
            " 4051.8376 4583.521  4942.9277 4886.6045 4844.404  4615.328  5223.4917\n",
            " 6085.2383 5094.0933 4802.792  3589.4363 4706.8647 4976.007  5502.7505\n",
            " 5678.019  5536.5703 5866.4927 5447.311  6034.2305 6125.2856 5432.3057\n",
            " 4818.1006 4282.9844 5605.963  5351.0146 5294.9146 5599.7773 6074.8433\n",
            " 4980.603  5944.931  5689.5786 6083.719 ]\n",
            "[169046.42 185557.   201248.11 201293.23 167973.98 131561.19 205016.45\n",
            " 229840.06 219792.28 197213.92 212069.25 192311.8  209596.17 275645.47\n",
            " 262519.38 329866.12 288827.75 349687.62 339118.56 349958.25 351631.34\n",
            " 390705.25 418098.88 444899.44 461127.1  465252.25 421956.   387918.56\n",
            " 377981.94 443397.22 470130.62 443386.7  427884.4  407297.12 448619.25\n",
            " 520147.78 440923.72 464561.3  394286.28 448492.4  460441.97 504923.7\n",
            " 511120.8  537838.44 547632.94 528947.4  499788.53 504194.66 481059.2\n",
            " 454728.22 482579.72 501380.75 484736.22 476771.88 471813.47 469771.7\n",
            " 419216.75 391524.97 384594.78 421971.56]\n",
            "[ 9013.8955  6224.65   11690.973   8387.648  10238.577  10329.449\n",
            "  9434.797   9853.637   5958.846  10160.274  13072.392  10049.115\n",
            " 10773.989   6356.909   3298.9807  3218.987   2387.3806  3302.652\n",
            "  2898.4277  3197.276  10391.802   8422.188   6452.811   6397.0835\n",
            "  5396.2295  5810.251   3663.0088  5531.7456  5490.4253  7389.3047\n",
            "  3313.3994  2491.4043  2103.352   1722.1322  1864.7592  2171.113\n",
            "  1905.5112  1805.9883  2114.8523  2230.3503  2621.805   3409.502\n",
            "  4434.235   5810.2134  7171.1216  9259.205  10840.006  13526.97\n",
            " 15573.129  18497.977  21335.777  18460.273  20428.547  21447.082\n",
            " 19601.453  17917.54   18076.209  17532.07   18061.11   15330.726 ]\n",
            "[ 464892.9   607660.6   675291.    670000.94  572731.4   502958.75\n",
            "  736951.4   823559.25  826983.6   735610.1   794856.9   721457.2\n",
            "  724827.    865133.6   934775.2  1115464.9   901433.3  1084907.2\n",
            " 1037510.75 1073589.2  1114335.   1133845.9  1193069.4  1142077.1\n",
            " 1214397.   1251262.2  1192996.1  1083336.4  1038017.7  1248065.2\n",
            " 1283102.1  1211884.1  1275691.1  1140079.6  1143091.2  1342462.5\n",
            " 1110507.1  1247978.1  1063998.   1151811.1  1159483.1  1290015.8\n",
            " 1258840.5  1352112.1  1379808.   1321493.8  1243597.   1292942.\n",
            " 1217599.8  1099432.2  1277218.   1347580.1  1480652.8  1309234.\n",
            " 1343321.8  1290962.5  1212245.5  1138378.5  1210442.2  1416111.4 ]\n",
            "[241466.42 250016.66 272888.6  271493.97 226195.72 169743.92 269774.75\n",
            " 300651.9  279306.   252511.47 271707.28 246338.81 274058.   371998.1\n",
            " 348381.97 437684.72 395433.34 479514.2  465700.56 482417.88 484282.06\n",
            " 546454.2  579285.2  639350.44 654212.9  655520.8  588379.94 534796.1\n",
            " 519275.44 609660.94 649209.8  613929.94 586438.3  570133.44 636413.2\n",
            " 719269.75 607600.1  637193.94 535990.1  618739.8  636489.1  693166.1\n",
            " 708825.4  743470.8  765869.1  735834.3  697925.6  697767.56 659569.75\n",
            " 643824.9  654884.8  680045.8  649079.5  652808.6  653413.1  635781.9\n",
            " 564167.6  531341.3  523187.4  545368.4 ]\n",
            "[ 3012.9036  4002.431   4261.9805  4547.4487  4155.4097  4047.6216\n",
            "  5334.7397  4980.5796  5197.445   4714.292   4531.4214  4115.9067\n",
            "  3734.261   5149.121   5746.016   6685.5933  5478.7715  6232.325\n",
            "  5298.111   5531.132   5727.1426  5598.173   5798.3457  5219.0728\n",
            "  5578.319   6471.644   5780.032   5700.747   5284.933   5861.3267\n",
            "  6098.3105  5701.419   6349.1196  5895.8364  7048.553   8592.289\n",
            "  7847.685   8309.575   7409.2544  6917.9995  7346.8174  7987.074\n",
            "  8385.272   8782.194   8535.794   8018.645   8167.7637  9020.054\n",
            " 10073.792   9050.573  10882.431  12177.106  11704.895  10721.785\n",
            " 10333.189  11991.588   9962.33   10745.745   9239.114  12342.386 ]\n",
            "[ 687.47675  658.20416  606.1918   494.2722   466.19656  464.41098\n",
            "  494.88318  507.90326  598.942    630.5966   600.56836  595.29913\n",
            "  613.2826   496.55444  477.82095  504.27145  521.65533  918.7414\n",
            "  674.987    665.7611   660.03394  678.9376   671.0127   704.08093\n",
            "  664.5281   752.55493  726.37897  788.5545   790.53217  859.138\n",
            "  885.17365  919.2942   872.355    901.1464   979.6888  1059.5814\n",
            " 1093.5562  1082.047    986.1551  1124.6779  1169.5742  1175.515\n",
            " 1174.9622  1202.4978  1203.9086  1185.5771  1263.4866  1270.6764\n",
            " 1299.5273  1300.0459  1329.5758  1436.4913  1305.458   1311.3314\n",
            " 1330.8846  1395.1837  1375.1932  1418.6471  1327.2821  1369.3535 ]\n",
            "[ 36645.21   41036.586  49182.773  50414.316  45456.46   42684.85\n",
            "  56191.367  64616.582  64351.38   58157.766  70110.88   65221.31\n",
            "  62323.453  51714.668  58077.22   65218.566  50015.117  66921.15\n",
            "  71908.36   74746.13   79970.055  73623.14   78497.92   63058.74\n",
            "  79502.87  102072.98  102504.97   78580.83   84231.23   90472.32\n",
            "  99502.31   81751.48   97377.055  84162.02   69174.2    77911.\n",
            "  79062.695 101986.44   95580.19   85370.26   70401.43   84817.03\n",
            "  72131.05   81861.51   90413.98   91683.     62220.31   81640.49\n",
            "  73576.89   79743.79  110400.87   81274.63   94991.7    84328.125\n",
            "  66316.54   39948.88   66877.72   39826.973  58490.793  63280.367]\n",
            "[ 738565.9  993758.6 1066989.9 1077509.2  911144.6  803773.6 1178428.4\n",
            " 1326646.6 1355110.1 1202603.4 1280852.5 1174219.  1165936.1 1456696.\n",
            " 1561042.  1872270.9 1524518.9 1808304.1 1720301.6 1766952.1 1798772.5\n",
            " 1861694.1 1992456.5 1910047.1 2059792.8 2166544.  2057373.1 1892466.6\n",
            " 1828510.  2144189.8 2223935.8 2089906.  2136886.5 1912148.  2005798.9\n",
            " 2401507.  2048371.9 2245239.2 1960319.4 2066882.4 2090787.6 2351546.5\n",
            " 2334885.5 2464605.5 2470637.8 2402060.  2254028.5 2306310.5 2314268.2\n",
            " 2139026.  2506836.8 2632074.2 2651436.  2410854.8 2384208.  2399018.5\n",
            " 2215728.5 2063304.4 2105516.5 2548224.2]\n",
            "[14030519. 20942266. 21928672. 22478672. 18731916. 17207946. 24762178.\n",
            " 28570912. 30013416. 26569288. 28320128. 26189424. 25276912. 31774122.\n",
            " 34873816. 41721136. 33844192. 39750456. 37766760. 38424324. 38868444.\n",
            " 40103444. 43881424. 41666564. 46288660. 50590984. 48764504. 44689400.\n",
            " 43445836. 50520304. 52229832. 48692792. 48762024. 43231456. 44953536.\n",
            " 54469952. 47559708. 53112496. 48362504. 48528288. 48570296. 55393856.\n",
            " 55282796. 58114916. 57346244. 56685956. 52980932. 54363088. 57756556.\n",
            " 54855948. 65769848. 69517952. 66697300. 59988680. 59265600. 60139472.\n",
            " 56019936. 51677332. 52331020. 65431780.]\n",
            "[ 36259.4    32194.777  29904.578  30586.268  19757.97    8176.074\n",
            "  19784.908  27607.764  21597.64   21544.627  21913.21   21398.145\n",
            "  31664.604  68395.22   60782.176  77423.82   84135.96   98790.734\n",
            "  94784.83   96231.94   88835.95  119227.66  131684.64  176619.19\n",
            " 176219.48  175429.7   157132.6   141540.12  135453.95  164258.14\n",
            " 175238.77  171961.7   140728.28  149839.3   174091.73  178693.11\n",
            " 147263.92  154656.72  138883.17  161063.47  171800.28  183471.62\n",
            " 198127.    202694.88  206642.86  200946.03  204543.19  190212.44\n",
            " 195926.55  212105.7   201578.02  241234.69  191006.73  201919.19\n",
            " 223534.67  218095.05  182635.55  181443.72  163695.88  174714.64 ]\n",
            "[ 42410.03   47514.06   54320.22   54716.395  49115.145  42817.133\n",
            "  60273.953  62083.953  59412.473  54964.906  57585.836  51315.023\n",
            "  51619.81   64045.76   64825.5    76931.65   63901.977  74270.99\n",
            "  68554.49   71999.69   77340.8    78953.67   79651.4    80539.66\n",
            "  81552.695  83155.95   72354.555  64829.38   61373.797  74555.305\n",
            "  77674.53   72155.914  76643.086  72543.875  78240.98   94305.96\n",
            "  80192.05   89411.75   72962.23   78902.914  79057.49   86045.664\n",
            "  87035.94   91960.6   100284.42   93501.79   88392.234  92286.46\n",
            "  84981.14   74487.84   76058.92   72133.516  84557.57   76739.84\n",
            "  74753.53   79373.49   66854.734  66180.42   69542.99   73675.98 ]\n",
            "[ 6330.8525  9770.851   9027.087  10491.037   8783.46    8416.819\n",
            " 11659.218  11874.234  12847.699  11363.866  10354.812   9530.028\n",
            "  7761.943  15420.885  16599.22   20432.45   17319.346  17820.254\n",
            " 14510.333  14564.345  14273.383  15335.734  16802.123  17350.037\n",
            " 18084.19   17997.525  15843.98   16400.88   14677.44   16761.668\n",
            " 16785.424  15919.485  15563.406  14288.688  19167.494  27467.658\n",
            " 25087.498  24672.277  22380.197  20718.62   22573.348  27172.447\n",
            " 30107.965  29283.438  28877.273  27745.715  28236.193  27175.275\n",
            " 34326.117  30911.379  34757.95   35357.688  29527.986  25338.842\n",
            " 23217.46   30808.71   23519.25   23596.396  22373.826  30666.785 ]\n",
            "[ 15304.13   15894.997  16424.559  20700.443  20687.512  20874.488\n",
            "  22564.725  21845.326  21915.898  22500.88   22954.443  23358.33\n",
            "  17097.375  21062.559  19645.885  20129.787  22771.062  21988.012\n",
            "  24393.803  25638.467  27843.63   27997.959  30352.426  30725.99\n",
            "  47405.293  92561.52   78818.77   57305.074  65258.926  57665.285\n",
            "  66437.95   49958.12   38153.73   40246.574  50071.215  55714.023\n",
            "  75073.1   102969.88  111775.92   81486.72   57944.047  61641.31\n",
            "  66077.11   70950.766  75480.97   79035.69   51000.65   60055.395\n",
            "  90527.7   122370.96  141923.2   116492.555  88846.35  100175.22\n",
            "  68255.56   64786.37   78055.375  65791.445  64830.81   58864.215]\n",
            "[ 9508347. 12762108. 13978728. 14030197. 12034144. 10816619. 15533518.\n",
            " 17433316. 17748276. 15834852. 17072722. 15599029. 15335677. 18213754.\n",
            " 19785340. 23487432. 18826306. 22483804. 21495040. 22143294. 22931926.\n",
            " 23142404. 24567844. 22916960. 24933232. 26564100. 25455286. 23071384.\n",
            " 22367294. 26246112. 27069226. 25229914. 26456044. 23361300. 23807176.\n",
            " 28525140. 24439256. 27487346. 24187666. 24980708. 24740752. 27866452.\n",
            " 27261132. 29223866. 29318980. 28456332. 26206472. 27566966. 27469196.\n",
            " 25417460. 30470850. 31360744. 32751290. 29377134. 28958834. 28435016.\n",
            " 27156808. 24939886. 26041436. 31278986.]\n",
            "[21500872. 29957048. 32303772. 32506650. 27311962. 24438058. 35562680.\n",
            " 40660568. 41730156. 37094136. 39879816. 36496592. 36143064. 44459288.\n",
            " 48012868. 57632904. 46926092. 55920144. 53389292. 54645936. 55996240.\n",
            " 57796896. 62412232. 60297780. 65490532. 69821544. 66732144. 61076516.\n",
            " 59084296. 69887792. 72012928. 67553096. 68339728. 61137932. 62400512.\n",
            " 74559088. 63560060. 71133968. 63259052. 65822160. 66208504. 74592752.\n",
            " 73982192. 78425408. 78470288. 76704320. 72125360. 74213144. 75084576.\n",
            " 70229632. 82530280. 87273136. 87712312. 78573856. 79036872. 78474480.\n",
            " 73150040. 67949120. 70151000. 84828704.]\n",
            "[ 1853.9435  2905.0237  2933.1697  3246.3188  3210.2273  3140.3916\n",
            "  4222.969   2712.301   3277.575   3154.625   1761.7349  1586.17\n",
            "  1166.3054  3234.1797  3166.781   3215.0242  3213.819   3243.681\n",
            "  2470.878   2626.486   2472.6199  2722.7542  3074.261   2896.2764\n",
            "  3371.8525 10095.338   7626.4062  7756.7456  8161.62    8211.855\n",
            "  8962.87    8757.911   6704.9253  7769.858   9000.548   9456.378\n",
            " 10040.429  12229.756  11356.127  11339.448  10748.713   9679.098\n",
            "  9793.319   9667.668   9634.932   9735.163   9561.943   9916.835\n",
            " 10135.192  10908.131  10591.215  11836.5205 10584.487  11576.398\n",
            " 10283.383  12227.227  10577.403  12568.897  10847.022  10571.786 ]\n",
            "[ 596187.9   802930.94  892734.8   882756.2   755254.4   678296.2\n",
            "  976088.1  1106366.4  1118738.9  1002096.44 1089560.1   986019.6\n",
            "  982755.3  1151859.   1252163.2  1488245.9  1182248.9  1427096.4\n",
            " 1364917.   1406452.9  1472144.1  1483635.1  1573579.4  1479457.9\n",
            " 1583883.4  1641807.   1583812.4  1454298.5  1396615.5  1676185.2\n",
            " 1703836.6  1607723.5  1694500.1  1490930.2  1478009.1  1765275.8\n",
            " 1466574.4  1643693.   1430489.5  1524024.4  1530859.2  1725161.2\n",
            " 1677762.6  1809419.1  1810062.   1747749.5  1639442.2  1718619.9\n",
            " 1671892.6  1519061.1  1817266.   1897393.9  2051652.6  1814249.9\n",
            " 1839360.   1774703.   1701459.1  1570954.2  1676518.6  1988091.1 ]\n",
            "[  924.24396  1028.8594    962.1212    872.0372    579.6678    323.7847\n",
            "   672.156     940.1953    813.5102    788.9549    802.1035    797.96063\n",
            "   761.9212   1959.865    2618.7175   2774.8123   2892.5288   3335.9126\n",
            "  3213.8794   3456.2458   3407.7202   3970.4417   3892.5627   5055.277\n",
            "  4955.1973   4933.4404   4947.93     4257.9526   3822.2578   4338.7935\n",
            "  4503.211    4528.952    4499.8906   4583.4175   5574.3574   4292.6523\n",
            "  3312.197    3240.7158   2935.3904   3281.9417   3749.3525   4299.064\n",
            "  4805.0464   4923.922    4572.4795   4465.074    5023.039    4987.8804\n",
            "  5734.449    7600.4      7601.7827  10222.04     8108.2744   8696.493\n",
            "  9923.566    8772.385    7787.5337   8398.175    7223.5244   8606.217  ]\n",
            "[1978898.5 2689620.8 2921113.8 2925954.  2490843.2 2211618.8 3231871.2\n",
            " 3607436.2 3678227.2 3264671.5 3472822.8 3167879.8 3127057.2 3870113.8\n",
            " 4208058.  5017929.5 4058018.2 4812300.  4556419.  4698964.5 4838038.\n",
            " 4935151.  5223583.5 4966052.5 5321927.  5561786.5 5302068.  4869787.5\n",
            " 4662796.5 5533957.5 5686930.5 5373256.  5593505.  4982230.5 5146499.\n",
            " 6119634.5 5146321.5 5715721.5 4949739.5 5236915.  5296370.5 5928169.\n",
            " 5853680.  6226482.  6253390.5 6036536.5 5710647.5 5896806.  5818225.5\n",
            " 5313190.5 6237938.  6636146.  6930994.  6182403.  6247285.5 6211550.5\n",
            " 5757702.  5432354.  5606757.5 6758350. ]\n",
            "[ 2416179.2  3385838.   3587923.2  3651831.5  3075108.   2763471.8\n",
            "  4003335.8  4534800.   4687390.5  4163769.5  4421693.5  4073513.\n",
            "  3969804.2  5033137.5  5448246.   6527425.5  5341697.   6265253.\n",
            "  5934215.5  6071580.5  6168711.   6384288.5  6885891.5  6617515.5\n",
            "  7236917.   7780849.5  7415298.   6778375.5  6568431.   7671672.5\n",
            "  7948020.   7431425.   7487794.   6708007.   7057314.5  8472890.\n",
            "  7342579.   8172127.   7305533.   7455851.   7488621.5  8457302.\n",
            "  8445906.   8892167.   8874649.   8709532.   8167145.   8385504.\n",
            "  8692580.   8180180.5  9660738.  10190552.   9934402.   8983057.\n",
            "  8900778.   9023687.   8325860.5  7727923.   7794303.5  9613586. ]\n",
            "[ 7013429.5 10095396.  10720952.  10943485.   9297221.   8519889.\n",
            " 12195679.  13790583.  14366565.  12742566.  13560135.  12495071.\n",
            " 12005003.  14778705.  16279685.  19325420.  15432645.  18112162.\n",
            " 17187972.  17614444.  17973714.  18197100.  19553738.  17913482.\n",
            " 19875328.  21567022.  20820416.  19081510.  18526264.  21343854.\n",
            " 22055138.  20515890.  21232896.  18562690.  19509466.  23769250.\n",
            " 20773830.  23038724.  20678446.  20742492.  20585366.  23525836.\n",
            " 23268814.  24628796.  24211034.  23756932.  21923816.  22834952.\n",
            " 24084282.  22620460.  27480014.  28541624.  28156652.  25426938.\n",
            " 24685452.  25000316.  23580988.  21690258.  22130170.  27511922. ]\n",
            "[ 6869802.5  9537448.  10316724.  10408119.   8856415.   7993326.\n",
            " 11531149.  13020683.  13374852.  11877838.  12743074.  11665600.\n",
            " 11397512.  13818229.  15111486.  17983700.  14405253.  17100926.\n",
            " 16291315.  16750562.  17237592.  17463376.  18636444.  17364448.\n",
            " 18958596.  20170710.  19402540.  17722442.  17131176.  20064656.\n",
            " 20663470.  19312214.  20128018.  17719968.  18219316.  21941994.\n",
            " 18801916.  20978646.  18547456.  19067660.  19000432.  21541372.\n",
            " 21190730.  22588464.  22462820.  21857696.  20267724.  21149772.\n",
            " 21488550.  19949496.  23941120.  24890012.  25493180.  22810144.\n",
            " 22563132.  22362656.  21159104.  19518130.  20294398.  24673016. ]\n",
            "[ 339050.84  353734.    387428.3   393154.03  337725.2   272280.03\n",
            "  404959.56  445033.94  424925.7   385960.78  421333.9   383518.1\n",
            "  409286.34  498517.8   453584.9   573570.7   501106.1   610533.2\n",
            "  602814.9   622813.8   631596.75  693061.06  746589.4   771688.75\n",
            "  825255.    885843.2   794806.1   712818.    717975.06  808637.75\n",
            "  875342.3   792948.94  766186.8   731873.7   817376.7   968647.25\n",
            "  874425.56  946075.2   831671.56  887628.1   875625.    961230.44\n",
            "  961769.6  1023893.44 1037175.7  1019433.4   908606.44  967377.94\n",
            "  946509.4   908696.1  1004086.94  962413.9   900677.6   907670.\n",
            "  832387.3   840386.5   779296.2   686918.06  654004.2   722862.5 ]\n",
            "[1081.8077   934.7924  1058.5095   849.7842   844.2512   765.1479\n",
            "  860.7347   880.92926  821.0633   935.94806  997.5432   928.63214\n",
            "  947.64764  806.48706  839.7642   826.88245  833.197   1334.4337\n",
            " 1110.7742  1158.4178  1323.6699  1295.1013  1152.199   1241.3245\n",
            " 1170.3848  1220.3657  1208.2162  1191.0692  1114.2988  1175.3367\n",
            " 1106.4907  1157.983   1235.3625  1216.9321  1463.0829  1277.2594\n",
            " 1214.8843  1108.457    985.82623 1163.9818  1211.7113  1233.8323\n",
            " 1298.5325  1388.7335  1372.952   1321.3618  1398.5049  1404.3439\n",
            " 1553.7733  2033.3779  2067.3308  2204.2073  2050.0178  2291.719\n",
            " 2318.5415  1950.8473  2123.184   2180.6985  2129.09    1926.3954 ]\n",
            "[ 436476.84  493839.8   533012.7   531675.75  448232.    357548.03\n",
            "  551567.5   610349.    590321.94  528191.1   559608.3   507904.1\n",
            "  540093.06  713951.    699273.06  865082.4   746979.94  897324.25\n",
            "  861659.4   892900.1   904088.9   985119.5  1040109.2  1083859.1\n",
            " 1120815.4  1129017.8  1025842.25  946722.44  913655.94 1063741.4\n",
            " 1123155.1  1059706.8  1051503.    990341.56 1108614.   1285194.8\n",
            " 1088833.1  1140751.4   961226.   1083401.9  1117179.5  1227864.\n",
            " 1246402.2  1312683.1  1327023.5  1277727.1  1209714.8  1226678.6\n",
            " 1185944.   1120366.1  1205908.9  1259475.1  1232100.9  1206880.\n",
            " 1184230.5  1193612.   1059789.8  1002124.06  971777.75 1095894.4 ]\n",
            "[ 971.9183  1098.6787  1174.1981  1115.1708  1011.60333  943.77246\n",
            " 1259.924   1293.6467  1346.8673  1280.6984  1274.0049  1192.3782\n",
            " 1208.8333  1382.1353  1406.2983  1632.3987  1364.596   1722.8652\n",
            " 1487.0333  1516.0453  1538.5496  1611.7139  1696.069   1596.7891\n",
            " 1623.5627  1781.3893  1663.6776  1786.6184  1736.4177  1919.7037\n",
            " 1978.1198  1948.1836  1925.3846  1752.5319  1920.6349  2355.4255\n",
            " 2124.0955  1996.7148  1649.5919  1974.2133  2112.3909  2311.628\n",
            " 2372.963   2351.903   2381.4746  2304.282   2577.4106  2655.8164\n",
            " 2625.284   2371.5444  2515.0068  3014.4443  2911.9543  2851.377\n",
            " 2783.7463  3153.0369  2806.653   3152.5786  2974.9333  3349.6426 ]\n",
            "[ 4975.8286  6064.5107  5583.4653  7464.2983  6155.898   5510.1953\n",
            "  8020.0474  7603.7993  8113.3086  6823.9463  6107.5464  5583.739\n",
            "  6116.6904  9972.9     7586.169  10806.668   9588.857  10025.333\n",
            "  8608.85    8483.2     7613.4434  9731.168  11953.626  13983.837\n",
            " 14659.616  16982.047  11838.194  10476.955  11561.581  14526.764\n",
            " 17515.594  15075.899  11563.545  12933.31   13716.194  22128.312\n",
            " 21215.133  25022.54   21614.502  21580.502  20640.559  22326.568\n",
            " 23233.555  23425.777  26894.848  25477.59   23578.684  24531.818\n",
            " 22671.477  15128.924  12374.256   8868.066   8935.189   6669.0234\n",
            "  4115.151  13137.569   5376.417   5476.679   4802.3027  5094.164 ]\n"
          ]
        }
      ],
      "source": [
        "for i in predictions:\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3O9yk7sSFSD",
        "outputId": "d0b09ddd-dde7-48b1-a88f-a183e0eb5af0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 20ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[3.9615819e+05, 6.0438300e+05, 5.9355381e+05, ..., 1.5373050e+06,\n",
              "        1.4640082e+06, 1.9288414e+06],\n",
              "       [6.8799344e+04, 6.7810023e+04, 7.1741352e+04, ..., 1.8203556e+05,\n",
              "        1.8698109e+05, 1.8690797e+05],\n",
              "       [1.7983794e+03, 1.7108405e+03, 1.9118197e+03, ..., 1.4953844e+03,\n",
              "        1.2543496e+03, 1.0293135e+03],\n",
              "       ...,\n",
              "       [2.9601389e+03, 3.3746091e+03, 3.9243660e+03, ..., 1.0790614e+04,\n",
              "        8.5025615e+03, 1.1290958e+04],\n",
              "       [4.2939315e+06, 6.3279470e+06, 6.6607365e+06, ..., 1.4171518e+07,\n",
              "        1.4409965e+07, 1.8125030e+07],\n",
              "       [4.6349371e+02, 4.6008066e+02, 4.2826163e+02, ..., 1.6972488e+03,\n",
              "        1.5505813e+03, 1.7160610e+03]], dtype=float32)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions2 = model.predict(X_test)\n",
        "predictions2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6xiO1N54IGr"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "oJukzB9aM7Xe"
      },
      "outputs": [],
      "source": [
        "#Write ig result tp file\n",
        "file = open('ig_train.csv','w')\n",
        "for item in predictions:\n",
        "\tfile.write(str(item)+\"\\n\")\n",
        "file.close()\n",
        "\n",
        "file2 = open('ig_test.csv','w')\n",
        "for item in predictions2:\n",
        "\tfile2.write(str(item)+\"\\n\")\n",
        "file2.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wj3gEPJnTdlr"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
